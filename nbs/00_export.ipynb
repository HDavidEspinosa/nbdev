{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp export\n",
    "#default_cls_lvl 3\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from nbdev.imports import *\n",
    "from fastcore.script import *\n",
    "from fastcore.foundation import *\n",
    "from keyword import iskeyword\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to modules\n",
    "\n",
    "> The functions that transform notebooks in a library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important function defined in this module is `notebooks2script`, so you may want to jump to it before scrolling though the rest, which explain the details behind the scenes of the conversion from notebooks to library. The main things to remember are:\n",
    "- put `# export` on each cell you want exported\n",
    "- put `# exports` on each cell you want exported with the source code shown in the docs \n",
    "- put `# exporti` on each cell you want exported without it being added to `__all__`, and without it showing up in the docs.\n",
    "- one cell should contain `# default_exp` followed by the name of the module (with points for submodules and without the py extension) everything should be exported in (if one specific cell needs to be exported in a different module, just indicate it after `#export`: `#export special.module`)\n",
    "- all left members of an equality, functions and classes will be exported and variables that are not private will be put in the `__all__` automatically\n",
    "- to add something to `__all__` if it's not picked automatically, write an exported cell with something like `#add2all \"my_name\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of `export`\n",
    "\n",
    "See [these examples](https://github.com/fastai/nbdev_export_demo/blob/master/demo.ipynb) on different ways to use `#export` to export code in notebooks to modules.  These include:\n",
    "\n",
    "- How to specify a default for exporting cells\n",
    "- How to hide code and not export it at all\n",
    "- How to export different cells to specific modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For bootstrapping `nbdev` we have a few basic foundations defined in <code>imports</code>, which we test a show here. First, a simple config file class, `Config` that read the content of your `settings.ini` file and make it accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"Config\" class=\"doc_header\"><code>Config</code><a href=\"https://github.com/fastai/fastcore/tree/master/fastcore/foundation.py#L254\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>Config</code>(**`cfg_name`**=*`'settings.ini'`*)\n",
       "\n",
       "Reading and writing `settings.ini`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Config, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_config(\"github\", \"nbdev\", user='fastai', path='..', tst_flags='tst', cfg_name='test_settings.ini', recursive='False')\n",
    "cfg = Config(cfg_name='test_settings.ini')\n",
    "test_eq(cfg.lib_name, 'nbdev')\n",
    "test_eq(cfg.git_url, \"https://github.com/fastai/nbdev/tree/master/\")\n",
    "# test_eq(cfg.path(\"lib_path\"), Path.cwd().parent/'nbdev')\n",
    "# test_eq(cfg.path(\"nbs_path\"), Path.cwd())\n",
    "# test_eq(cfg.path(\"doc_path\"), Path.cwd().parent/'docs')\n",
    "test_eq(cfg.custom_sidebar, 'False')\n",
    "test_eq(cfg.recursive, 'False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A jupyter notebook is a json file behind the scenes. We can just read it with the json module, which will return a nested dictionary of dictionaries/lists of dictionaries, but there are some small differences between reading the json and using the tools from `nbformat` so we'll use this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_nb(fname):\n",
    "    \"Read the notebook in `fname`.\"\n",
    "    with open(Path(fname),'r', encoding='utf8') as f: return nbformat.reads(f.read(), as_version=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fname` can be a string or a pathlib object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = read_nb('00_export.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root has four keys: `cells` contains the cells of the notebook, `metadata` some stuff around the version of python used to execute the notebook, `nbformat` and `nbformat_minor` the version of nbformat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cells', 'metadata', 'nbformat', 'nbformat_minor'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jupytext': {'split_at_heading': True},\n",
       " 'kernelspec': {'display_name': 'Python 3 (ipykernel)',\n",
       "  'language': 'python',\n",
       "  'name': 'python3'},\n",
       " 'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "  'file_extension': '.py',\n",
       "  'mimetype': 'text/x-python',\n",
       "  'name': 'python',\n",
       "  'nbconvert_exporter': 'python',\n",
       "  'pygments_lexer': 'ipython3',\n",
       "  'version': '3.9.6'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{test_nb['nbformat']}.{test_nb['nbformat_minor']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells key then contains a list of cells. Each one is a new dictionary that contains entries like the type (code or markdown), the source (what is written in the cell) and the output (for code cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': 1,\n",
       " 'metadata': {'hide_input': False},\n",
       " 'outputs': [],\n",
       " 'source': '#hide\\n#default_exp export\\n#default_cls_lvl 3\\nfrom nbdev.showdoc import show_doc'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb['cells'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are used to catch the flags used in the code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_re(cell, pat, code_only=True):\n",
    "    \"Check if `cell` contains a line with regex `pat`\"\n",
    "    if code_only and cell['cell_type'] != 'code': return\n",
    "    if isinstance(pat, str): pat = re.compile(pat, re.IGNORECASE | re.MULTILINE)\n",
    "    cell_source = cell['source'].replace('\\r', '') # Eliminates the \\r\\n bug\n",
    "    result = pat.search(cell_source)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pat` can be a string or a compiled regex. If `code_only=True`, this function ignores non-code cells, such as markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = test_nb['cells'][1].copy()\n",
    "assert check_re(cell, '#export') is not None\n",
    "assert check_re(cell, re.compile('#export')) is not None\n",
    "assert check_re(cell, '# bla') is None\n",
    "cell['cell_type'] = 'markdown'\n",
    "assert check_re(cell, '#export') is None\n",
    "assert check_re(cell, '#export', code_only=False) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_re_multi(cell, pats, code_only=True):\n",
    "    \"Check if `cell` contains a line matching any regex in `pats`, returning the first match found\"\n",
    "    return L(pats).map_first(partial(check_re, cell, code_only=code_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = test_nb['cells'][0].copy()\n",
    "cell['source'] = \"a b c\"\n",
    "assert check_re(cell, 'a') is not None\n",
    "assert check_re(cell, 'd') is None\n",
    "# show that searching with patterns ['d','b','a'] will match 'b'\n",
    "# i.e. 'd' is not found and we don't search for 'a'\n",
    "assert check_re_multi(cell, ['d','b','a']).span() == (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _mk_flag_re(body, n_params, comment):\n",
    "    \"Compiles a regex for finding nbdev flags\"\n",
    "    assert body!=True, 'magics no longer supported'\n",
    "    prefix = r\"\\s*\\#\\s*\"\n",
    "    param_group = \"\"\n",
    "    if n_params == -1: param_group = r\"[ \\t]+(.+)\"\n",
    "    if n_params == 1: param_group = r\"[ \\t]+(\\S+)\"\n",
    "    if n_params == (0,1): param_group = r\"(?:[ \\t]+(\\S+))?\"\n",
    "    return re.compile(rf\"\"\"\n",
    "# {comment}:\n",
    "^            # beginning of line (since re.MULTILINE is passed)\n",
    "{prefix}\n",
    "{body}\n",
    "{param_group}\n",
    "[ \\t]*       # any number of spaces and/or tabs\n",
    "$            # end of line (since re.MULTILINE is passed)\n",
    "\"\"\", re.MULTILINE | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a regex object that can be used to find nbdev flags in multiline text\n",
    "- `body` regex fragment to match one or more flags,\n",
    "- `n_params` number of flag parameters to match and catch (-1 for any number of params; `(0,1)` for 0 for 1 params),\n",
    "- `comment` explains what the compiled regex should do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "re_blank_test = _mk_flag_re('export[si]?', 0, \"test\")\n",
    "re_mod_test = _mk_flag_re('export[si]?', 1, \"test\")\n",
    "re_opt_test = _mk_flag_re('export[si]?', (0,1), \"test\")\n",
    "for f in ['export', 'exports', 'exporti']:\n",
    "    cell = nbformat.v4.new_code_cell(f'#{f}  \\n some code')\n",
    "    assert check_re(cell, re_blank_test) is not None\n",
    "    assert check_re(cell, re_mod_test) is None\n",
    "    assert check_re(cell, re_opt_test) is not None\n",
    "    test_eq(check_re(cell, re_opt_test).groups()[0], None)\n",
    "    cell.source = f'#{f} special.module \\n some code'\n",
    "    assert check_re(cell, re_blank_test) is None\n",
    "    assert check_re(cell, re_mod_test) is not None\n",
    "    test_eq(check_re(cell, re_mod_test).groups()[0], 'special.module')\n",
    "    assert check_re(cell, re_opt_test) is not None\n",
    "    test_eq(check_re(cell, re_opt_test).groups()[0], 'special.module')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_blank_export = _mk_flag_re(\"export[si]?\", 0,\n",
    "    \"Matches any line with #export, #exports or #exporti without any module name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_mod_export = _mk_flag_re(\"export[si]?\", 1,\n",
    "    \"Matches any line with #export, #exports or #exporti with a module name and catches it in group 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_internal_export = _mk_flag_re(\"exporti\", (0,1),\n",
    "    \"Matches any line with #exporti with or without a module name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _is_external_export(tst):\n",
    "    \"Check if a cell is an external or internal export. `tst` is an re match\"\n",
    "    return _re_internal_export.search(tst.string) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_export(cell, default):\n",
    "    \"Check if `cell` is to be exported and returns the name of the module to export it if provided\"\n",
    "    tst = check_re(cell, _re_blank_export)\n",
    "    if tst:\n",
    "        if default is None:\n",
    "            print(f\"No export destination, ignored:\\n{cell['source']}\")\n",
    "        return default, _is_external_export(tst)\n",
    "    tst = check_re(cell, _re_mod_export)\n",
    "    if tst: return os.path.sep.join(tst.groups()[0].split('.')), _is_external_export(tst)\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_export` returns;\n",
    "- a tuple of (\"module name\", \"external boolean\" (`False` for an internal export)) if `cell` is to be exported or \n",
    "- `None` if `cell` will not be exported.\n",
    "\n",
    "The cells to export are marked with `#export`/`#exporti`/`#exports`, potentially with a module name where we want it exported. The default module is given in a cell of the form `#default_exp bla` inside the notebook (usually at the top), though in this function, it needs the be passed (the final script will read the whole notebook to find it).\n",
    "- a cell marked with `#export`/`#exporti`/`#exports` will be exported to the default module\n",
    "- an exported cell marked with `special.module` appended will be exported in `special.module` (located in `lib_name/special/module.py`)\n",
    "- a cell marked with `#export` will have its signature added to the documentation\n",
    "- a cell marked with `#exports` will additionally have its source code added to the documentation\n",
    "- a cell marked with `#exporti` will not show up in the documentation, and will also not be added to `__all__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = test_nb['cells'][1].copy()\n",
    "test_eq(is_export(cell, 'export'), ('export', True))\n",
    "cell['source'] = \"# exports\"\n",
    "test_eq(is_export(cell, 'export'), ('export', True))\n",
    "cell['source'] = \"# exporti\"\n",
    "test_eq(is_export(cell, 'export'), ('export', False))\n",
    "cell['source'] = \"# export mod\"\n",
    "test_eq(is_export(cell, 'export'), ('mod', True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "cell['source'] = \"# export mod.file\"\n",
    "test_eq(is_export(cell, 'export'), (f'mod{os.path.sep}file', True))\n",
    "cell['source'] = \"# exporti mod.file\"\n",
    "test_eq(is_export(cell, 'export'), (f'mod{os.path.sep}file', False))\n",
    "cell['source'] = \"# expt mod.file\"\n",
    "assert is_export(cell, 'export') is None\n",
    "cell['source'] = \"# exportmod.file\"\n",
    "assert is_export(cell, 'export') is None\n",
    "cell['source'] = \"# exportsmod.file\"\n",
    "assert is_export(cell, 'export') is None\n",
    "cell['source'] = \"# exporti mod file\"\n",
    "assert is_export(cell, 'export') is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_default_exp = _mk_flag_re('default_exp', 1, \"Matches any line with #default_exp with a module name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_default_export(cells):\n",
    "    \"Find in `cells` the default export module.\"\n",
    "    res = L(cells).map_first(check_re, pat=_re_default_exp)\n",
    "    return res.groups()[0] if res else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stops at the first cell containing `# default_exp` (if there are several) and returns the value behind. Returns `None` if there are no cell with that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(find_default_export(test_nb['cells']), 'export')\n",
    "assert find_default_export(test_nb['cells'][2:]) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "mods = [f'mod{i}' for i in range(3)]\n",
    "cells = [{'cell_type': 'code', 'source': f'#default_exp {mod}'} for mod in mods]\n",
    "for i, mod in enumerate(mods): test_eq(mod, find_default_export(cells[i:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing all exported objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions make a list of everything that is exported to prepare a proper `__all__` for our exported module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_patch_func = re.compile(r\"\"\"\n",
    "# Catches any function decorated with @patch, its name in group 1 and the patched class in group 2\n",
    "@patch         # At any place in the cell, something that begins with @patch\n",
    "(?:\\s*@.*)*    # Any other decorator applied to the function\n",
    "\\s*def         # Any number of whitespace (including a new line probably) followed by def\n",
    "\\s+            # One whitespace or more\n",
    "([^\\(\\s]+)     # Catch a group composed of anything but whitespace or an opening parenthesis (name of the function)\n",
    "\\s*\\(          # Any number of whitespace followed by an opening parenthesis\n",
    "[^:]*          # Any number of character different of : (the name of the first arg that is type-annotated)\n",
    ":\\s*           # A column followed by any number of whitespace\n",
    "(?:            # Non-catching group with either\n",
    "([^,\\s\\(\\)]*)  #    a group composed of anything but a comma, a parenthesis or whitespace (name of the class)\n",
    "|              #  or\n",
    "(\\([^\\)]*\\)))  #    a group composed of something between parenthesis (tuple of classes)\n",
    "\\s*            # Any number of whitespace\n",
    "(?:,|\\))       # Non-catching group with either a comma or a closing parenthesis\n",
    "\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<re.Match object; span=(1, 42), match='@patch\\n@log_args(a=1)\\ndef func(obj:Class)'>,\n",
       " ('func', 'Class', None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = _re_patch_func.search(\"\"\"\n",
    "@patch\n",
    "@log_args(a=1)\n",
    "def func(obj:Class):\"\"\")\n",
    "tst, tst.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "tst = _re_patch_func.search(\"\"\"\n",
    "@patch\n",
    "def func(obj:Class):\"\"\")\n",
    "test_eq(tst.groups(), (\"func\", \"Class\", None))\n",
    "tst = _re_patch_func.search(\"\"\"\n",
    "@patch\n",
    "def func (obj:Class, a)\"\"\")\n",
    "test_eq(tst.groups(), (\"func\", \"Class\", None))\n",
    "tst = _re_patch_func.search(\"\"\"\n",
    "@patch\n",
    "def func (obj:(Class1, Class2), a)\"\"\")\n",
    "test_eq(tst.groups(), (\"func\", None, \"(Class1, Class2)\"))\n",
    "tst = _re_patch_func.search(\"\"\"\n",
    "@patch\n",
    "def func (obj:(Class1, Class2), a:int)->int:\"\"\")\n",
    "test_eq(tst.groups(), (\"func\", None, \"(Class1, Class2)\"))\n",
    "tst = _re_patch_func.search(\"\"\"\n",
    "@patch\n",
    "@log_args(but='a,b')\n",
    "@funcs_kwargs\n",
    "def func (obj:(Class1, Class2), a:int)->int:\"\"\")\n",
    "test_eq(tst.groups(), (\"func\", None, \"(Class1, Class2)\"))\n",
    "tst = _re_patch_func.search(\"\"\"\n",
    "@patch\n",
    "@contextmanager\n",
    "def func (obj:Class, a:int)->int:\"\"\")\n",
    "test_eq(tst.groups(), (\"func\", \"Class\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_typedispatch_func = re.compile(r\"\"\"\n",
    "# Catches any function decorated with @typedispatch\n",
    "(@typedispatch  # At any place in the cell, catch a group with something that begins with @typedispatch\n",
    "\\s*def          # Any number of whitespace (including a new line probably) followed by def\n",
    "\\s+             # One whitespace or more\n",
    "[^\\(]+          # Anything but whitespace or an opening parenthesis (name of the function)\n",
    "\\s*\\(           # Any number of whitespace followed by an opening parenthesis\n",
    "[^\\)]*          # Any number of character different of )\n",
    "\\)[\\s\\S]*:)     # A closing parenthesis followed by any number of characters and whitespace (type annotation) and :\n",
    "\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert _re_typedispatch_func.search(\"@typedispatch\\ndef func(a, b):\").groups() == ('@typedispatch\\ndef func(a, b):',)\n",
    "assert (_re_typedispatch_func.search(\"@typedispatch\\ndef func(a:str, b:bool)->int:\").groups() ==\n",
    "                                    ('@typedispatch\\ndef func(a:str, b:bool)->int:',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_class_func_def = re.compile(r\"\"\"\n",
    "# Catches any 0-indented function or class definition with its name in group 1\n",
    "^              # Beginning of a line (since re.MULTILINE is passed)\n",
    "(?:async\\sdef|def|class)  # Non-catching group for def or class\n",
    "\\s+            # One whitespace or more\n",
    "([^\\(\\s]+)     # Catching group with any character except an opening parenthesis or a whitespace (name)\n",
    "\\s*            # Any number of whitespace\n",
    "(?:\\(|:)       # Non-catching group with either an opening parenthesis or a : (classes don't need ())\n",
    "\"\"\", re.MULTILINE | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(_re_class_func_def.search(\"class Class:\").groups(), ('Class',))\n",
    "test_eq(_re_class_func_def.search(\"def func(a, b):\").groups(), ('func',))\n",
    "test_eq(_re_class_func_def.search(\"def func(a:str, b:bool)->int:\").groups(), ('func',))\n",
    "test_eq(_re_class_func_def.search(\"async def func(a, b):\").groups(), ('func',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_obj_def = re.compile(r\"\"\"\n",
    "# Catches any 0-indented object definition (bla = thing) with its name in group 1\n",
    "^                          # Beginning of a line (since re.MULTILINE is passed)\n",
    "([_a-zA-Z]+[a-zA-Z0-9_\\.]*)  # Catch a group which is a valid python variable name\n",
    "\\s*                        # Any number of whitespace\n",
    "(?::\\s*\\S.*|)=  # Non-catching group of either a colon followed by a type annotation, or nothing; followed by an =\n",
    "\"\"\", re.MULTILINE | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(_re_obj_def.search(\"a = 1\").groups(), ('a',))\n",
    "test_eq(_re_obj_def.search(\"a.b = 1\").groups(), ('a.b',))\n",
    "test_eq(_re_obj_def.search(\"_aA1=1\").groups(), ('_aA1',))\n",
    "test_eq(_re_obj_def.search(\"a : int =1\").groups(), ('a',))\n",
    "test_eq(_re_obj_def.search(\"a:f(':=')=1\").groups(), ('a',))\n",
    "assert _re_obj_def.search(\"@abc=2\") is None\n",
    "assert _re_obj_def.search(\"a a=2\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _not_private(n):\n",
    "    for t in n.split('.'):\n",
    "        if (t.startswith('_') and not t.startswith('__')) or t.startswith('@'): return False\n",
    "    return '\\\\' not in t and '^' not in t and '[' not in t and t != 'else'\n",
    "\n",
    "def export_names(code, func_only=False):\n",
    "    \"Find the names of the objects, functions or classes defined in `code` that are exported.\"\n",
    "    #Format monkey-patches with @patch\n",
    "    def _f(gps):\n",
    "        nm, cls, t = gps.groups()\n",
    "        if cls is not None: return f\"def {cls}.{nm}():\"\n",
    "        return '\\n'.join([f\"def {c}.{nm}():\" for c in re.split(', *', t[1:-1])])\n",
    "\n",
    "    code = _re_typedispatch_func.sub('', code)\n",
    "    code = _re_patch_func.sub(_f, code)\n",
    "    names = _re_class_func_def.findall(code)\n",
    "    if not func_only: names += _re_obj_def.findall(code)\n",
    "    return [n for n in names if _not_private(n) and not iskeyword(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function only picks the zero-indented objects on the left side of an =, functions or classes (we don't want the class methods for instance) and excludes private names (that begin with `_`) but no dunder names. It only returns func and class names (not the objects) when `func_only=True`. \n",
    "\n",
    "To work properly with fastai added python functionality, this function ignores function decorated with `@typedispatch` (since they are defined multiple times) and unwraps properly functions decorated with `@patch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(export_names(\"def my_func(x):\\n  pass\\nclass MyClass():\"), [\"my_func\", \"MyClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Indented funcs are ignored (funcs inside a class)\n",
    "test_eq(export_names(\"  def my_func(x):\\n  pass\\nclass MyClass():\"), [\"MyClass\"])\n",
    "\n",
    "#Private funcs are ignored, dunder are not\n",
    "test_eq(export_names(\"def _my_func():\\n  pass\\nclass MyClass():\"), [\"MyClass\"])\n",
    "test_eq(export_names(\"__version__ = 1:\\n  pass\\nclass MyClass():\"), [\"MyClass\", \"__version__\"])\n",
    "\n",
    "#trailing spaces\n",
    "test_eq(export_names(\"def my_func ():\\n  pass\\nclass MyClass():\"), [\"my_func\", \"MyClass\"])\n",
    "\n",
    "#class without parenthesis\n",
    "test_eq(export_names(\"def my_func ():\\n  pass\\nclass MyClass:\"), [\"my_func\", \"MyClass\"])\n",
    "\n",
    "#object and funcs\n",
    "test_eq(export_names(\"def my_func ():\\n  pass\\ndefault_bla=[]:\"), [\"my_func\", \"default_bla\"])\n",
    "test_eq(export_names(\"def my_func ():\\n  pass\\ndefault_bla=[]:\", func_only=True), [\"my_func\"])\n",
    "\n",
    "#Private objects are ignored\n",
    "test_eq(export_names(\"def my_func ():\\n  pass\\n_default_bla = []:\"), [\"my_func\"])\n",
    "\n",
    "#Objects with dots are privates if one part is private\n",
    "test_eq(export_names(\"def my_func ():\\n  pass\\ndefault.bla = []:\"), [\"my_func\", \"default.bla\"])\n",
    "test_eq(export_names(\"def my_func ():\\n  pass\\ndefault._bla = []:\"), [\"my_func\"])\n",
    "\n",
    "#Monkey-path with @patch are properly renamed\n",
    "test_eq(export_names(\"@patch\\ndef my_func(x:Class):\\n  pass\"), [\"Class.my_func\"])\n",
    "test_eq(export_names(\"@patch\\ndef my_func(x:Class):\\n  pass\", func_only=True), [\"Class.my_func\"])\n",
    "test_eq(export_names(\"some code\\n@patch\\ndef my_func(x:Class, y):\\n  pass\"), [\"Class.my_func\"])\n",
    "test_eq(export_names(\"some code\\n@patch\\ndef my_func(x:(Class1,Class2), y):\\n  pass\"), [\"Class1.my_func\", \"Class2.my_func\"])\n",
    "\n",
    "#Check delegates\n",
    "test_eq(export_names(\"@delegates(keep=True)\\nclass someClass:\\n  pass\"), [\"someClass\"])\n",
    "\n",
    "#Typedispatch decorated functions shouldn't be added\n",
    "test_eq(export_names(\"@patch\\ndef my_func(x:Class):\\n  pass\\n@typedispatch\\ndef func(x: TensorImage): pass\"), [\"Class.my_func\"])\n",
    "\n",
    "#try, except and other keywords should not be picked up (these can look like object def with type annotation)\n",
    "test_eq(export_names(\"try:\\n    a=1\\nexcept:\\n    b=2\"), [])\n",
    "test_eq(export_names(\"try:\\n    this_might_work\\nexcept:\\n    b=2\"), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_all_def   = re.compile(r\"\"\"\n",
    "# Catches a cell with defines \\_all\\_ = [\\*\\*] and get that \\*\\* in group 1\n",
    "^_all_   #  Beginning of line (since re.MULTILINE is passed)\n",
    "\\s*=\\s*  #  Any number of whitespace, =, any number of whitespace\n",
    "\\[       #  Opening [\n",
    "([^\\n\\]]*) #  Catching group with anything except a ] or newline\n",
    "\\]       #  Closing ]\n",
    "\"\"\", re.MULTILINE | re.VERBOSE)\n",
    "\n",
    "#Same with __all__\n",
    "_re__all__def = re.compile(r'^__all__\\s*=\\s*\\[([^\\]]*)\\]', re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extra_add(flags, code):\n",
    "    \"Catch adds to `__all__` required by a cell with `_all_=`\"\n",
    "    m = check_re({'source': code}, _re_all_def, False)\n",
    "    if m:\n",
    "        code = m.re.sub('#nbdev_' + 'comment \\g<0>', code)\n",
    "        code = re.sub(r'([^\\n]|^)\\n*$', r'\\1', code)\n",
    "    if not m: return [], code\n",
    "    def clean_quotes(s):\n",
    "        \"Return `s` enclosed in single quotes, removing double quotes if needed\"\n",
    "        if s.startswith(\"'\") and s.endswith(\"'\"): return s\n",
    "        if s.startswith('\"') and s.endswith('\"'): s = s[1:-1]\n",
    "        return f\"'{s}'\"\n",
    "    return [clean_quotes(s) for s in parse_line(m.group(1))], code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes objects are not picked to be automatically added to the `__all__` of the module so you will need to add them manually. To do so, create an exported cell with the following code `_all_ = [\"name\", \"name2\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "for code, expected in [\n",
    "        ['_all_ = [\"func\", \"func1\", \"func2\"]', \n",
    "         ([\"'func'\", \"'func1'\", \"'func2'\"],'#nbdev_comment _all_ = [\"func\", \"func1\", \"func2\"]')],\n",
    "        ['_all_=[func, func1, func2]', \n",
    "         ([\"'func'\", \"'func1'\", \"'func2'\"],'#nbdev_comment _all_=[func, func1, func2]')],\n",
    "        [\"_all_ = ['func', 'func1', 'func2']\", \n",
    "         ([\"'func'\", \"'func1'\", \"'func2'\"],\"#nbdev_comment _all_ = ['func', 'func1', 'func2']\")],\n",
    "        ['_all_ = [\"func\",   \"func1\" , \"func2\"]', \n",
    "         ([\"'func'\", \"'func1'\", \"'func2'\"],'#nbdev_comment _all_ = [\"func\",   \"func1\" , \"func2\"]')],\n",
    "        [\"_all_ = ['func','func1', 'func2']\\n\", \n",
    "         ([\"'func'\", \"'func1'\", \"'func2'\"],\"#nbdev_comment _all_ = ['func','func1', 'func2']\")],\n",
    "        [\"_all_ = ['func']\\n_all_ = ['func1', 'func2']\\n\", \n",
    "         ([\"'func'\"],\"#nbdev_comment _all_ = ['func']\\n#nbdev_comment _all_ = ['func1', 'func2']\")],\n",
    "        ['code\\n\\n_all_ = [\"func\", \"func1\", \"func2\"]', \n",
    "         ([\"'func'\", \"'func1'\", \"'func2'\"],'code\\n\\n#nbdev_comment _all_ = [\"func\", \"func1\", \"func2\"]')],\n",
    "        ['code\\n\\n_all_ = [func]\\nmore code', \n",
    "         ([\"'func'\"],'code\\n\\n#nbdev_comment _all_ = [func]\\nmore code')]]:\n",
    "    test_eq(extra_add('', code), expected)\n",
    "    \n",
    "# line breaks within the list of names means _all_ is ignored\n",
    "test_eq(extra_add('', \"_all_ = ['func',\\n'func1', 'func2']\\n\"), ([],\"_all_ = ['func',\\n'func1', 'func2']\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_from_future_import = re.compile(r\"^from[ \\t]+__future__[ \\t]+import.*$\", re.MULTILINE)\n",
    "\n",
    "def _from_future_import(fname, flags, code, to_dict=None):\n",
    "    \"Write `__future__` imports to `fname` and return `code` with `__future__` imports commented out\"\n",
    "    from_future_imports = _re_from_future_import.findall(code)\n",
    "    if from_future_imports: code = _re_from_future_import.sub('#nbdev' + '_comment \\g<0>', code)\n",
    "    else: from_future_imports = _re_from_future_import.findall(flags)\n",
    "    if not from_future_imports or to_dict is not None: return code\n",
    "    with open(fname, 'r', encoding='utf8') as f: text = f.read()\n",
    "    start = _re__all__def.search(text).start()\n",
    "    with open(fname, 'w', encoding='utf8') as f:\n",
    "        f.write('\\n'.join([text[:start], *from_future_imports, '\\n', text[start:]]))\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need a `from __future__ import` in your library, you can export your cell with special comments:\n",
    "\n",
    "```python\n",
    "#export\n",
    "from __future__ import annotations\n",
    "class ...\n",
    "```\n",
    "\n",
    "Notice that `#export` is after the `__future__` import. Because `__future__` imports must occur at the beginning of the file, nbdev allows `__future__` imports in the flags section of a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "txt = \"\"\"\n",
    "# AUTOHEADER ... File to edit: mod.ipynb (unless otherwise specified).\n",
    "\n",
    "__all__ = [my_file, MyClas]\n",
    "# Cell\n",
    "def valid_code(): pass\"\"\"\n",
    "expected_txt = \"\"\"\n",
    "# AUTOHEADER ... File to edit: mod.ipynb (unless otherwise specified).\n",
    "\n",
    "\n",
    "from  __future__ import  annotations    \n",
    "from __future__ import generator_stop\n",
    "\n",
    "\n",
    "__all__ = [my_file, MyClas]\n",
    "# Cell\n",
    "def valid_code(): pass\"\"\"\n",
    "flags=\"# export\"\n",
    "code = \"\"\"\n",
    "# comment\n",
    "from  __future__ import  annotations    \n",
    "valid_code = False # but _from_future_import will work anyway\n",
    "from __future__ import generator_stop\n",
    " from __future__ import not_zero_indented\n",
    "valid_code = True\n",
    "\"\"\"\n",
    "expected_code = \"\"\"\n",
    "# comment\n",
    "#nbdev_comment from  __future__ import  annotations    \n",
    "valid_code = False # but _from_future_import will work anyway\n",
    "#nbdev_comment from __future__ import generator_stop\n",
    " from __future__ import not_zero_indented\n",
    "valid_code = True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_from_future_import_test():\n",
    "    fname = 'test_from_future_import.txt'\n",
    "    with open(fname, 'w', encoding='utf8') as f: f.write(txt)\n",
    "\n",
    "    actual_code=_from_future_import(fname, flags, code, {})\n",
    "    test_eq(expected_code, actual_code)\n",
    "    with open(fname, 'r', encoding='utf8') as f: test_eq(f.read(), txt)\n",
    "\n",
    "    actual_code=_from_future_import(fname, flags, code)\n",
    "    test_eq(expected_code, actual_code)\n",
    "    with open(fname, 'r', encoding='utf8') as f: test_eq(f.read(), expected_txt)\n",
    "\n",
    "    os.remove(fname)\n",
    "\n",
    "_run_from_future_import_test()\n",
    "\n",
    "flags=\"\"\"from  __future__ import  annotations    \n",
    "from __future__ import generator_stop\n",
    "#export\"\"\"\n",
    "code = \"\"\n",
    "expected_code = \"\"\n",
    "fname = 'test_from_future_import.txt'\n",
    "\n",
    "_run_from_future_import_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _add2all(fname, names, line_width=120):\n",
    "    if len(names) == 0: return\n",
    "    with open(fname, 'r', encoding='utf8') as f: text = f.read()\n",
    "    tw = TextWrapper(width=120, initial_indent='', subsequent_indent=' '*11, break_long_words=False)\n",
    "    re_all = _re__all__def.search(text)\n",
    "    start,end = re_all.start(),re_all.end()\n",
    "    text_all = tw.wrap(f\"{text[start:end-1]}{'' if text[end-2]=='[' else ', '}{', '.join(names)}]\")\n",
    "    with open(fname, 'w', encoding='utf8') as f: f.write(text[:start] + '\\n'.join(text_all) + text[end:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fname = 'test_add.txt'\n",
    "with open(fname, 'w', encoding='utf8') as f: f.write(\"Bla\\n__all__ = [my_file, MyClas]\\nBli\")\n",
    "_add2all(fname, ['new_function'])\n",
    "with open(fname, 'r', encoding='utf8') as f: \n",
    "    test_eq(f.read(), \"Bla\\n__all__ = [my_file, MyClas, new_function]\\nBli\")\n",
    "_add2all(fname, [f'new_function{i}' for i in range(10)])\n",
    "with open(fname, 'r', encoding='utf8') as f: \n",
    "    test_eq(f.read(), \"\"\"Bla\n",
    "__all__ = [my_file, MyClas, new_function, new_function0, new_function1, new_function2, new_function3, new_function4,\n",
    "           new_function5, new_function6, new_function7, new_function8, new_function9]\n",
    "Bli\"\"\")\n",
    "os.remove(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def relative_import(name, fname):\n",
    "    \"Convert a module `name` to a name relative to `fname`\"\n",
    "    mods = name.split('.')\n",
    "    splits = str(fname).split(os.path.sep)\n",
    "    if mods[0] not in splits: return name\n",
    "    i=len(splits)-1\n",
    "    while i>0 and splits[i] != mods[0]: i-=1\n",
    "    splits = splits[i:]\n",
    "    while len(mods)>0 and splits[0] == mods[0]: splits,mods = splits[1:],mods[1:]\n",
    "    return '.' * (len(splits)) + '.'.join(mods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we say from \n",
    "``` python\n",
    "from lib_name.module.submodule import bla\n",
    "``` \n",
    "in a notebook, it needs to be converted to something like \n",
    "```\n",
    "from .module.submodule import bla\n",
    "```\n",
    "or \n",
    "```from .submodule import bla``` \n",
    "depending on where we are. This function deals with those imports renaming.\n",
    "\n",
    "Note that import of the form\n",
    "```python\n",
    "import lib_name.module\n",
    "```\n",
    "are left as is as the syntax `import module` does not work for relative imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(relative_import('nbdev.core', Path.cwd()/'nbdev'/'data.py'), '.core')\n",
    "test_eq(relative_import('nbdev.core', Path('nbdev')/'vision'/'data.py'), '..core')\n",
    "test_eq(relative_import('nbdev.vision.transform', Path('nbdev')/'vision'/'data.py'), '.transform')\n",
    "test_eq(relative_import('nbdev.notebook.core', Path('nbdev')/'data'/'external.py'), '..notebook.core')\n",
    "test_eq(relative_import('nbdev.vision', Path('nbdev')/'vision'/'learner.py'), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_import = ReLibName(r'^(\\s*)from (LIB_NAME\\.\\S*) import (.*)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _deal_import(code_lines, fname):\n",
    "    def _replace(m):\n",
    "        sp,mod,obj = m.groups()\n",
    "        return f\"{sp}from {relative_import(mod, fname)} import {obj}\"\n",
    "    return [_re_import.re.sub(_replace,line) for line in code_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "lines = [\"from nbdev.core import *\", \n",
    "         \"nothing to see\", \n",
    "         \"  from nbdev.vision import bla1, bla2\", \n",
    "         \"from nbdev.vision import models\",\n",
    "         \"import nbdev.vision\"]\n",
    "test_eq(_deal_import(lines, Path.cwd()/'nbdev'/'data.py'), [\n",
    "    \"from .core import *\", \n",
    "    \"nothing to see\", \n",
    "    \"  from .vision import bla1, bla2\", \n",
    "    \"from .vision import models\",\n",
    "    \"import nbdev.vision\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to build back a correspondence between functions and the notebooks they are defined in, we need to store an index. It's done in the private module <code>_nbdev</code> inside your library, and the following function are used to define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_index_custom = re.compile(r'def custom_doc_links\\(name\\):(.*)$', re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reset_nbdev_module():\n",
    "    \"Create a skeleton for <code>_nbdev</code>\"\n",
    "    fname = Config().path(\"lib_path\")/'_nbdev.py'\n",
    "    fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sep = '\\n'* (int(Config().get('cell_spacing', '1'))+1)\n",
    "    if fname.is_file():\n",
    "        with open(fname, 'r') as f: search = _re_index_custom.search(f.read())\n",
    "    else: search = None\n",
    "    prev_code = search.groups()[0] if search is not None else ' return None\\n'\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write(f\"# AUTOGENERATED BY NBDEV! DO NOT EDIT!\")\n",
    "        f.write('\\n\\n__all__ = [\"index\", \"modules\", \"custom_doc_links\", \"git_url\"]')\n",
    "        f.write('\\n\\nindex = {}')\n",
    "        f.write('\\n\\nmodules = []')\n",
    "        f.write(f'\\n\\ndoc_url = \"{Config().doc_host}{Config().doc_baseurl}\"')\n",
    "        f.write(f'\\n\\ngit_url = \"{Config().git_url}\"')\n",
    "        f.write(f'{sep}def custom_doc_links(name):{prev_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _EmptyModule():\n",
    "    def __init__(self):\n",
    "        self.index,self.modules = {},[]\n",
    "        self.doc_url,self.git_url = f\"{Config().doc_host}{Config().doc_baseurl}\",Config().git_url\n",
    "\n",
    "    def custom_doc_links(self, name): return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_nbdev_module():\n",
    "    \"Reads <code>_nbdev</code>\"\n",
    "    try:\n",
    "        spec = importlib.util.spec_from_file_location(f\"{Config().lib_name}._nbdev\", Config().path(\"lib_path\")/'_nbdev.py')\n",
    "        mod = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(mod)\n",
    "        return mod\n",
    "    except: return _EmptyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_index_idx = re.compile(r'index\\s*=\\s*{[^}]*}')\n",
    "_re_index_mod = re.compile(r'modules\\s*=\\s*\\[[^\\]]*\\]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_nbdev_module(mod):\n",
    "    \"Save `mod` inside <code>_nbdev</code>\"\n",
    "    fname = Config().path(\"lib_path\")/'_nbdev.py'\n",
    "    with open(fname, 'r') as f: code = f.read()\n",
    "    t = r',\\n         '.join([f'\"{k}\": \"{v}\"' for k,v in mod.index.items()])\n",
    "    code = _re_index_idx.sub(\"index = {\"+ t +\"}\", code)\n",
    "    t = r',\\n           '.join(['\"' + f.replace('\\\\','/') + '\"' for f in mod.modules])\n",
    "    code = _re_index_mod.sub(f\"modules = [{t}]\", code)\n",
    "    with open(fname, 'w') as f: f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "ind,ind_bak = Config().path(\"lib_path\")/'_nbdev.py',Config().path(\"lib_path\")/'_nbdev.bak'\n",
    "if ind.exists(): shutil.move(ind, ind_bak)\n",
    "try:\n",
    "    reset_nbdev_module()\n",
    "    mod = get_nbdev_module()\n",
    "    test_eq(mod.index, {})\n",
    "    test_eq(mod.modules, [])\n",
    "\n",
    "    mod.index = {'foo':'bar'}\n",
    "    mod.modules.append('lala.bla')\n",
    "    save_nbdev_module(mod)\n",
    "\n",
    "    mod = get_nbdev_module()\n",
    "    test_eq(mod.index, {'foo':'bar'})\n",
    "    test_eq(mod.modules, ['lala.bla'])\n",
    "finally:\n",
    "    if ind_bak.exists(): shutil.move(ind_bak, ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_flags_and_code(cell, return_type=list):\n",
    "    \"Splits the `source` of a cell into 2 parts and returns (flags, code)\"\n",
    "    source_str = cell['source'].replace('\\r', '')\n",
    "    code_lines = source_str.split('\\n')\n",
    "    split_pos = 0 if code_lines[0].strip().startswith('#') else -1\n",
    "    for i, line in enumerate(code_lines):\n",
    "        if not line.startswith('#') and line.strip() and not _re_from_future_import.match(line): break\n",
    "    split_pos+=1\n",
    "    res = code_lines[:split_pos], code_lines[split_pos:]\n",
    "    if return_type is list: return res\n",
    "    return tuple('\\n'.join(r) for r in res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`return_type` tells us if the tuple returned will contain `list`s of lines or `str`ings with line breaks. \n",
    "\n",
    "We treat the first comment line as a flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"split_flags_and_code example\" width=\"450\" align=\"left\" src=\"images/split_flags_and_code.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_split_flags_and_code(expected_flags, expected_code):\n",
    "    cell = nbformat.v4.new_code_cell('\\n'.join(expected_flags + expected_code))\n",
    "    test_eq((expected_flags, expected_code), split_flags_and_code(cell))\n",
    "    expected=('\\n'.join(expected_flags), '\\n'.join(expected_code))\n",
    "    test_eq(expected, split_flags_and_code(cell, str))\n",
    "    \n",
    "_test_split_flags_and_code([\n",
    "    '#export'],\n",
    "    ['# TODO: write this function',\n",
    "    'def func(x): pass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_mod_file(fname, nb_path, bare=False):\n",
    "    \"Create a module file for `fname`.\"\n",
    "    bare = str(Config().get('bare', bare)) == 'True'\n",
    "    fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = os.path.relpath(nb_path, Config().config_file.parent).replace('\\\\', '/')\n",
    "    with open(fname, 'w') as f:\n",
    "        if not bare: f.write(f\"# AUTOGENERATED! DO NOT EDIT! File to edit: {file_path} (unless otherwise specified).\")\n",
    "        f.write('\\n\\n__all__ = []')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new module filename is created each time a notebook has a cell marked with `#default_exp`. In your collection of notebooks, you should only have one notebook that creates a given module since they are re-created each time you do a library build (to ensure the library is clean). Note that any file you create manually will never be overwritten (unless it has the same name as one of the modules defined in a `#default_exp` cell) so you are responsible to clean up those yourself.\n",
    "\n",
    "`fname` is the notebook that contained the `#default_exp` cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_mod_files(files, to_dict=False, bare=False):\n",
    "    \"Create mod files for default exports found in `files`\"\n",
    "    modules = []\n",
    "    for f in sorted(files):\n",
    "        fname = Path(f)\n",
    "        nb = read_nb(fname)\n",
    "        default = find_default_export(nb['cells'])\n",
    "        if default is not None:\n",
    "            default = os.path.sep.join(default.split('.'))\n",
    "            modules.append(default)\n",
    "            if not to_dict:\n",
    "                create_mod_file(Config().path(\"lib_path\")/f'{default}.py', Config().path(\"nbs_path\")/f'{fname}', bare=bare)\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create module files for all `#default_export` flags found in `files` and return a list containing the names of modules created. \n",
    "\n",
    "Note: The number if modules returned will be less that the number of files passed in if files do not `#default_export`.\n",
    "\n",
    "By creating all module files before calling `_notebook2script`, the order of execution no longer matters - so you can now export to a notebook that is run \"later\".\n",
    "\n",
    "You might still have problems when\n",
    "- converting a subset of notebooks or\n",
    "- exporting to a module that does not have a `#default_export` yet\n",
    "\n",
    "in which case `_notebook2script` will print warnings like;\n",
    "```\n",
    "Warning: Exporting to \"core.py\" but this module is not part of this build\n",
    "```\n",
    "\n",
    "If you see a warning like this\n",
    "- and the module file (e.g. \"core.py\") does not exist, you'll see a `FileNotFoundError`\n",
    "- if the module file exists, the exported cell will be written - even if the exported cell is already in the module file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _notebook2script(fname, modules, silent=False, to_dict=None, bare=False):\n",
    "    \"Finds cells starting with `#export` and puts them into a module created by `create_mod_files`\"\n",
    "    bare = str(Config().get('bare', bare)) == 'True'\n",
    "    if os.environ.get('IN_TEST',0): return  # don't export if running tests\n",
    "    sep = '\\n'* (int(Config().get('cell_spacing', '1'))+1)\n",
    "    fname = Path(fname)\n",
    "    nb = read_nb(fname)\n",
    "    default = find_default_export(nb['cells'])\n",
    "    if default is not None:\n",
    "        default = os.path.sep.join(default.split('.'))\n",
    "    mod = get_nbdev_module()\n",
    "    exports = [is_export(c, default) for c in nb['cells']]\n",
    "    cells = [(i,c,e) for i,(c,e) in enumerate(zip(nb['cells'],exports)) if e is not None]\n",
    "    for i,c,(e,a) in cells:\n",
    "        if e not in modules: print(f'Warning: Exporting to \"{e}.py\" but this module is not part of this build')\n",
    "        fname_out = Config().path(\"lib_path\")/f'{e}.py'\n",
    "        if bare: orig = \"\\n\"\n",
    "        else: orig = (f'# {\"\" if a else \"Internal \"}C' if e==default else f'# Comes from {fname.name}, c') + 'ell\\n'\n",
    "        flag_lines,code_lines = split_flags_and_code(c)\n",
    "        code_lines = _deal_import(code_lines, fname_out)\n",
    "#         print(\"code_lines: \", end='')\n",
    "#         pprint(code_lines)\n",
    "        code = sep + orig + '\\n'.join(code_lines)\n",
    "#         print(\"code: \", end='')\n",
    "#         pprint(code)\n",
    "        names = export_names(code)\n",
    "        flags = '\\n'.join(flag_lines)\n",
    "        extra,code = extra_add(flags, code)\n",
    "        code = _from_future_import(fname_out, flags, code, to_dict)\n",
    "        if a:\n",
    "            if to_dict is None: _add2all(fname_out, [f\"'{f}'\" for f in names if '.' not in f and len(f) > 0] + extra)\n",
    "        mod.index.update({f: fname.name for f in names})\n",
    "        code = re.sub(r' +$', '', code, flags=re.MULTILINE)\n",
    "        if code != sep + orig[:-1]:\n",
    "            if to_dict is not None: to_dict[e].append((i, fname, code))\n",
    "            else:\n",
    "                with open(fname_out, 'a', encoding='utf8') as f: f.write(code)\n",
    "        if f'{e}.py' not in mod.modules: mod.modules.append(f'{e}.py')\n",
    "    save_nbdev_module(mod)\n",
    "\n",
    "    if not silent: print(f\"Converted {fname.name}.\")\n",
    "    return to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_export.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "if not os.environ.get('IN_TEST',0):\n",
    "    modules = create_mod_files(glob.glob('00_export.ipynb'))\n",
    "    _notebook2script('00_export.ipynb', modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "with open(Config().path(\"lib_path\")/('export.py')) as f: l = f.readline()\n",
    "test_eq(l, '# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_export.ipynb (unless otherwise specified).\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_init(path):\n",
    "    \"Add `__init__.py` in all subdirs of `path` containing python files if it's not there already\"\n",
    "    for p,d,f in os.walk(path):\n",
    "        for f_ in f:\n",
    "            if f_.endswith('.py'):\n",
    "                if not (Path(p)/'__init__.py').exists(): (Path(p)/'__init__.py').touch()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    os.makedirs(Path(d)/'a', exist_ok=True)\n",
    "    (Path(d)/'a'/'f.py').touch()\n",
    "    os.makedirs(Path(d)/'a/b', exist_ok=True)\n",
    "    (Path(d)/'a'/'b'/'f.py').touch()\n",
    "    add_init(d)\n",
    "    assert not (Path(d)/'__init__.py').exists()\n",
    "    for e in [Path(d)/'a', Path(d)/'a/b']:\n",
    "        assert (e/'__init__.py').exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_version = re.compile('^__version__\\s*=.*$', re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_version():\n",
    "    \"Add or update `__version__` in the main `__init__.py` of the library\"\n",
    "    fname = Config().path(\"lib_path\")/'__init__.py'\n",
    "    if not fname.exists(): fname.touch()\n",
    "    version = f'__version__ = \"{Config().version}\"'\n",
    "    with open(fname, 'r') as f: code = f.read()\n",
    "    if _re_version.search(code) is None: code = version + \"\\n\" + code\n",
    "    else: code = _re_version.sub(version, code)\n",
    "    with open(fname, 'w') as f: f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_baseurl = re.compile('^baseurl\\s*:.*$', re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_baseurl():\n",
    "    \"Add or update `baseurl` in `_config.yml` for the docs\"\n",
    "    fname = Config().path(\"doc_path\")/'_config.yml'\n",
    "    if not fname.exists(): return\n",
    "    with open(fname, 'r') as f: code = f.read()\n",
    "    if _re_baseurl.search(code) is None: code = code + f\"\\nbaseurl: {Config().doc_baseurl}\"\n",
    "    else: code = _re_baseurl.sub(f\"baseurl: {Config().doc_baseurl}\", code)\n",
    "    with open(fname, 'w') as f: f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nbglob(fname=None, recursive=None, extension='.ipynb', config_key='nbs_path') -> L:\n",
    "    \"Find all files in a directory matching an extension given a `config_key`. Ignores hidden directories and filenames starting with `_`.  If argument `recursive` is not set to `True` or `False`, this value is retreived from settings.ini with a default of `False`.\"\n",
    "    if recursive == None: recursive=Config().get('recursive', 'False').lower() == 'true'\n",
    "    fname = Config().path(config_key) if fname is None else Path(fname)\n",
    "    if fname.is_dir(): fname = f'{fname.absolute()}/**/*{extension}' if recursive else f'{fname.absolute()}/*{extension}'\n",
    "    fls = L(glob.glob(str(fname), recursive=recursive)).filter(lambda x: '/.' not in x).map(Path)\n",
    "    return fls.filter(lambda x: not x.name.startswith('_') and x.name.endswith(extension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "with tempfile.TemporaryDirectory() as d:\n",
    "    os.makedirs(Path(d)/'a', exist_ok=True)\n",
    "    (Path(d)/'a'/'a.ipynb').touch()\n",
    "    (Path(d)/'a'/'fake_a.ipynb').touch()\n",
    "    os.makedirs(Path(d)/'a/b', exist_ok=True)\n",
    "    (Path(d)/'a'/'b'/'fake_b.ipynb').touch()\n",
    "    os.makedirs(Path(d)/'a/b/c', exist_ok=True)\n",
    "    (Path(d)/'a'/'b'/'c'/'fake_c.ipynb').touch()\n",
    "    (Path(d)/'a'/'b'/'c'/'foo_c.ipynb').touch()\n",
    "    \n",
    "    if sys.platform != \"win32\":\n",
    "        assert len(nbglob(str(Path(f'{str(d)}/**/foo*')), recursive=True)) == 1\n",
    "    assert len(nbglob(d, recursive=True)) == 5\n",
    "    assert len(nbglob(d, recursive=False)) == 0\n",
    "    assert len(nbglob(str(Path(f'{d}/a')), recursive=False)) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "if sys.platform != \"win32\":\n",
    "    assert len(nbglob('*')) > 1\n",
    "    assert len(nbglob('*')) >  len(nbglob('0*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not nbglob().filter(lambda x: '.ipynb_checkpoints' in str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fnames = nbglob()\n",
    "test_eq(len(fnames) > 0, True)\n",
    "\n",
    "fnames = nbglob(fnames[0])\n",
    "test_eq(len(fnames), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally you can pass a `config_key` to dictate which directory you are pointing to. By default it's `nbs_path` as without any parameters passed in, it will check for notebooks. To have it instead find library files simply pass in `lib_path` instead.\n",
    "\n",
    "> Note: it will only search for paths in `Config().path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fnames = nbglob(extension='.py', config_key='lib_path')\n",
    "test_eq(len(fnames) > 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def notebook2script(fname=None, silent=False, to_dict=False, bare=False):\n",
    "    \"Convert notebooks matching `fname` to modules\"\n",
    "    # initial checks\n",
    "    if os.environ.get('IN_TEST',0): return  # don't export if running tests\n",
    "    if fname is None:\n",
    "        reset_nbdev_module()\n",
    "        update_version()\n",
    "        update_baseurl()\n",
    "    files = nbglob(fname=fname)\n",
    "    d = collections.defaultdict(list) if to_dict else None\n",
    "    modules = create_mod_files(files, to_dict, bare=bare)\n",
    "    for f in sorted(files): d = _notebook2script(f, modules, silent=silent, to_dict=d, bare=bare)\n",
    "    if to_dict: return d\n",
    "    else: add_init(Config().path(\"lib_path\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_lines: ['from pathlib import Path',\n",
      " 'from pprint import pprint',\n",
      " 'from dataclasses import dataclass, astuple, field',\n",
      " 'from datetime import datetime',\n",
      " 'from typing import *',\n",
      " 'from fastcore import test as ft',\n",
      " '',\n",
      " 'import pandas as pd',\n",
      " 'import numpy as np',\n",
      " 'import csv',\n",
      " 'import json',\n",
      " '',\n",
      " 'import sc2reader',\n",
      " '',\n",
      " 'from sc2readertest import *']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Internal Cell\\n'\n",
      " 'from pathlib import Path\\n'\n",
      " 'from pprint import pprint\\n'\n",
      " 'from dataclasses import dataclass, astuple, field\\n'\n",
      " 'from datetime import datetime\\n'\n",
      " 'from typing import *\\n'\n",
      " 'from fastcore import test as ft\\n'\n",
      " '\\n'\n",
      " 'import pandas as pd\\n'\n",
      " 'import numpy as np\\n'\n",
      " 'import csv\\n'\n",
      " 'import json\\n'\n",
      " '\\n'\n",
      " 'import sc2reader\\n'\n",
      " '\\n'\n",
      " 'from sc2readertest import *')\n",
      "code_lines: [\"data_path = Path(Path.cwd()/'data') if Path('data').exists() else \"\n",
      " \"Path('../data')\",\n",
      " '',\n",
      " \"with open(data_path/'unit_names.csv') as f:\",\n",
      " '    file_reader = csv.reader(f)',\n",
      " '    unit_names = next(file_reader)',\n",
      " '    ',\n",
      " \"with open(data_path/'changes_names.csv') as f:\",\n",
      " '    file_reader = csv.reader(f)',\n",
      " '    change_names = next(file_reader)',\n",
      " '    ',\n",
      " \"with open(data_path/'army_list.json') as f:\",\n",
      " '    race_armies = json.load(f)',\n",
      " '',\n",
      " \"with open(data_path/'buildings_list.json') as f:\",\n",
      " '    race_buildings = json.load(f)',\n",
      " '',\n",
      " \"with open(data_path/'upgrades.json') as f:\",\n",
      " '    race_upgrades = json.load(f)',\n",
      " '']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Internal Cell\\n'\n",
      " \"data_path = Path(Path.cwd()/'data') if Path('data').exists() else \"\n",
      " \"Path('../data')\\n\"\n",
      " '\\n'\n",
      " \"with open(data_path/'unit_names.csv') as f:\\n\"\n",
      " '    file_reader = csv.reader(f)\\n'\n",
      " '    unit_names = next(file_reader)\\n'\n",
      " '    \\n'\n",
      " \"with open(data_path/'changes_names.csv') as f:\\n\"\n",
      " '    file_reader = csv.reader(f)\\n'\n",
      " '    change_names = next(file_reader)\\n'\n",
      " '    \\n'\n",
      " \"with open(data_path/'army_list.json') as f:\\n\"\n",
      " '    race_armies = json.load(f)\\n'\n",
      " '\\n'\n",
      " \"with open(data_path/'buildings_list.json') as f:\\n\"\n",
      " '    race_buildings = json.load(f)\\n'\n",
      " '\\n'\n",
      " \"with open(data_path/'upgrades.json') as f:\\n\"\n",
      " '    race_upgrades = json.load(f)\\n')\n",
      "code_lines: ['def list_player_upgrades(rpl: sc2reader.resources.Replay, pid: int) -> '\n",
      " 'dict[str, float]:',\n",
      " '    \"\"\"Lists the times at wich the player completed their updates',\n",
      " '    \"\"\"',\n",
      " '    player_race = rpl.player[pid].play_race',\n",
      " '',\n",
      " '    upg_events = {upg_event.upgrade_type_name: '\n",
      " 'calc_realtime_index(upg_event.second, rpl)',\n",
      " '        for upg_event in rpl.events ',\n",
      " '        if isinstance(upg_event, '\n",
      " 'sc2reader.events.tracker.UpgradeCompleteEvent) ',\n",
      " '        and upg_event.pid == pid',\n",
      " '        and upg_event.upgrade_type_name in race_upgrades[player_race]}',\n",
      " '',\n",
      " '    return {upgrade_name: upg_events.get(upgrade_name, 0) for upgrade_name '\n",
      " 'in race_upgrades[player_race]}',\n",
      " '']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def list_player_upgrades(rpl: sc2reader.resources.Replay, pid: int) -> '\n",
      " 'dict[str, float]:\\n'\n",
      " '    \"\"\"Lists the times at wich the player completed their updates\\n'\n",
      " '    \"\"\"\\n'\n",
      " '    player_race = rpl.player[pid].play_race\\n'\n",
      " '\\n'\n",
      " '    upg_events = {upg_event.upgrade_type_name: '\n",
      " 'calc_realtime_index(upg_event.second, rpl)\\n'\n",
      " '        for upg_event in rpl.events \\n'\n",
      " '        if isinstance(upg_event, '\n",
      " 'sc2reader.events.tracker.UpgradeCompleteEvent) \\n'\n",
      " '        and upg_event.pid == pid\\n'\n",
      " '        and upg_event.upgrade_type_name in race_upgrades[player_race]}\\n'\n",
      " '\\n'\n",
      " '    return {upgrade_name: upg_events.get(upgrade_name, 0) for upgrade_name '\n",
      " 'in race_upgrades[player_race]}\\n')\n",
      "Converted 03_build_parser.ipynb.\n",
      "defaultdict(<class 'list'>,\n",
      "            {'build_parser': [(4,\n",
      "                               Path('../tests/03_build_parser.ipynb'),\n",
      "                               '\\n'\n",
      "                               '\\n'\n",
      "                               '# Internal Cell\\n'\n",
      "                               'from pathlib import Path\\n'\n",
      "                               'from pprint import pprint\\n'\n",
      "                               'from dataclasses import dataclass, astuple, '\n",
      "                               'field\\n'\n",
      "                               'from datetime import datetime\\n'\n",
      "                               'from typing import *\\n'\n",
      "                               'from fastcore import test as ft\\n'\n",
      "                               '\\n'\n",
      "                               'import pandas as pd\\n'\n",
      "                               'import numpy as np\\n'\n",
      "                               'import csv\\n'\n",
      "                               'import json\\n'\n",
      "                               '\\n'\n",
      "                               'import sc2reader\\n'\n",
      "                               '\\n'\n",
      "                               'from sc2readertest import *'),\n",
      "                              (5,\n",
      "                               Path('../tests/03_build_parser.ipynb'),\n",
      "                               '\\n'\n",
      "                               '\\n'\n",
      "                               '# Internal Cell\\n'\n",
      "                               \"data_path = Path(Path.cwd()/'data') if \"\n",
      "                               \"Path('data').exists() else Path('../data')\\n\"\n",
      "                               '\\n'\n",
      "                               \"with open(data_path/'unit_names.csv') as f:\\n\"\n",
      "                               '    file_reader = csv.reader(f)\\n'\n",
      "                               '    unit_names = next(file_reader)\\n'\n",
      "                               '\\n'\n",
      "                               \"with open(data_path/'changes_names.csv') as \"\n",
      "                               'f:\\n'\n",
      "                               '    file_reader = csv.reader(f)\\n'\n",
      "                               '    change_names = next(file_reader)\\n'\n",
      "                               '\\n'\n",
      "                               \"with open(data_path/'army_list.json') as f:\\n\"\n",
      "                               '    race_armies = json.load(f)\\n'\n",
      "                               '\\n'\n",
      "                               \"with open(data_path/'buildings_list.json') as \"\n",
      "                               'f:\\n'\n",
      "                               '    race_buildings = json.load(f)\\n'\n",
      "                               '\\n'\n",
      "                               \"with open(data_path/'upgrades.json') as f:\\n\"\n",
      "                               '    race_upgrades = json.load(f)\\n'),\n",
      "                              (11,\n",
      "                               Path('../tests/03_build_parser.ipynb'),\n",
      "                               '\\n'\n",
      "                               '\\n'\n",
      "                               '# Cell\\n'\n",
      "                               'def list_player_upgrades(rpl: '\n",
      "                               'sc2reader.resources.Replay, pid: int) -> '\n",
      "                               'dict[str, float]:\\n'\n",
      "                               '    \"\"\"Lists the times at wich the player '\n",
      "                               'completed their updates\\n'\n",
      "                               '    \"\"\"\\n'\n",
      "                               '    player_race = rpl.player[pid].play_race\\n'\n",
      "                               '\\n'\n",
      "                               '    upg_events = {upg_event.upgrade_type_name: '\n",
      "                               'calc_realtime_index(upg_event.second, rpl)\\n'\n",
      "                               '        for upg_event in rpl.events\\n'\n",
      "                               '        if isinstance(upg_event, '\n",
      "                               'sc2reader.events.tracker.UpgradeCompleteEvent)\\n'\n",
      "                               '        and upg_event.pid == pid\\n'\n",
      "                               '        and upg_event.upgrade_type_name in '\n",
      "                               'race_upgrades[player_race]}\\n'\n",
      "                               '\\n'\n",
      "                               '    return {upgrade_name: '\n",
      "                               'upg_events.get(upgrade_name, 0) for '\n",
      "                               'upgrade_name in '\n",
      "                               'race_upgrades[player_race]}\\n')]})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "tst_file = Path('../tests/03_build_parser.ipynb')\n",
    "assert tst_file.is_file()\n",
    "\n",
    "build_test = notebook2script('../tests/03_build_parser.ipynb', to_dict=True)\n",
    "pprint(build_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_vsc_test.ipynb.\n",
      "defaultdict(<class 'list'>,\n",
      "            {'vsc_test': [(3,\n",
      "                           Path('../tests/00_vsc_test.ipynb'),\n",
      "                           '\\n\\n# Cell\\n\\r\\nimport fastcore.test as fct'),\n",
      "                          (5,\n",
      "                           Path('../tests/00_vsc_test.ipynb'),\n",
      "                           '\\n'\n",
      "                           '\\n'\n",
      "                           '# Internal Cell\\n'\n",
      "                           '\\r\\n'\n",
      "                           '#This cell should be exported but not included in '\n",
      "                           '__all__\\r\\n'\n",
      "                           '\\r\\n'\n",
      "                           'def test_funct_1(x, y):\\r\\n'\n",
      "                           '    print(\"Test_1\")\\r\\n'\n",
      "                           '    return x + y'),\n",
      "                          (7,\n",
      "                           Path('../tests/00_vsc_test.ipynb'),\n",
      "                           '\\n'\n",
      "                           '\\n'\n",
      "                           '# Cell\\n'\n",
      "                           '\\r\\n'\n",
      "                           'def test_exp_funct(x, y):\\r\\n'\n",
      "                           \"    '''The function adds x and y.\\r\\n\"\n",
      "                           '    It returns the result + 1\\r\\n'\n",
      "                           \"    '''\\r\\n\"\n",
      "                           \"    print('TEST 2')\\r\\n\"\n",
      "                           '    return test_funct_1(x, y) + 1\\r\\n'\n",
      "                           '\\r\\n')]})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "tst_file = Path('../tests/00_vsc_test.ipynb')\n",
    "assert tst_file.is_file()\n",
    "\n",
    "build_test = notebook2script('../tests/00_vsc_test.ipynb', to_dict=True)\n",
    "pprint(build_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds cells starting with `#export` and puts them into the appropriate module. If `fname` is not specified, this will convert all notebook not beginning with an underscore in the `nb_folder` defined in `setting.ini`. Otherwise `fname` can be a single filename or a glob expression.\n",
    "\n",
    "`silent` makes the command not print any statement and `to_dict` is used internally to convert the library to a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DocsTestClass:\n",
    "    \"for tests only\"\n",
    "    def test(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#exporti\n",
    "#for tests only\n",
    "def update_lib_with_exporti_testfn(): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_lines: ['from .imports import *',\n",
      " 'from fastcore.script import *',\n",
      " 'from fastcore.foundation import *',\n",
      " 'from keyword import iskeyword',\n",
      " 'import nbformat']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'from .imports import *\\n'\n",
      " 'from fastcore.script import *\\n'\n",
      " 'from fastcore.foundation import *\\n'\n",
      " 'from keyword import iskeyword\\n'\n",
      " 'import nbformat')\n",
      "code_lines: ['def read_nb(fname):',\n",
      " '    \"Read the notebook in `fname`.\"',\n",
      " \"    with open(Path(fname),'r', encoding='utf8') as f: return \"\n",
      " 'nbformat.reads(f.read(), as_version=4)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def read_nb(fname):\\n'\n",
      " '    \"Read the notebook in `fname`.\"\\n'\n",
      " \"    with open(Path(fname),'r', encoding='utf8') as f: return \"\n",
      " 'nbformat.reads(f.read(), as_version=4)')\n",
      "code_lines: ['def check_re(cell, pat, code_only=True):',\n",
      " '    \"Check if `cell` contains a line with regex `pat`\"',\n",
      " \"    if code_only and cell['cell_type'] != 'code': return\",\n",
      " '    if isinstance(pat, str): pat = re.compile(pat, re.IGNORECASE | '\n",
      " 're.MULTILINE)',\n",
      " \"    cell_source = cell['source'].replace('\\\\r', '') # Eliminates the \\\\r\\\\n \"\n",
      " 'bug',\n",
      " '    result = pat.search(cell_source)',\n",
      " '    return result']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def check_re(cell, pat, code_only=True):\\n'\n",
      " '    \"Check if `cell` contains a line with regex `pat`\"\\n'\n",
      " \"    if code_only and cell['cell_type'] != 'code': return\\n\"\n",
      " '    if isinstance(pat, str): pat = re.compile(pat, re.IGNORECASE | '\n",
      " 're.MULTILINE)\\n'\n",
      " \"    cell_source = cell['source'].replace('\\\\r', '') # Eliminates the \\\\r\\\\n \"\n",
      " 'bug\\n'\n",
      " '    result = pat.search(cell_source)\\n'\n",
      " '    return result')\n",
      "code_lines: ['def check_re_multi(cell, pats, code_only=True):',\n",
      " '    \"Check if `cell` contains a line matching any regex in `pats`, returning '\n",
      " 'the first match found\"',\n",
      " '    return L(pats).map_first(partial(check_re, cell, code_only=code_only))']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def check_re_multi(cell, pats, code_only=True):\\n'\n",
      " '    \"Check if `cell` contains a line matching any regex in `pats`, returning '\n",
      " 'the first match found\"\\n'\n",
      " '    return L(pats).map_first(partial(check_re, cell, code_only=code_only))')\n",
      "code_lines: ['def _mk_flag_re(body, n_params, comment):',\n",
      " '    \"Compiles a regex for finding nbdev flags\"',\n",
      " \"    assert body!=True, 'magics no longer supported'\",\n",
      " '    prefix = r\"\\\\s*\\\\#\\\\s*\"',\n",
      " '    param_group = \"\"',\n",
      " '    if n_params == -1: param_group = r\"[ \\\\t]+(.+)\"',\n",
      " '    if n_params == 1: param_group = r\"[ \\\\t]+(\\\\S+)\"',\n",
      " '    if n_params == (0,1): param_group = r\"(?:[ \\\\t]+(\\\\S+))?\"',\n",
      " '    return re.compile(rf\"\"\"',\n",
      " '# {comment}:',\n",
      " '^            # beginning of line (since re.MULTILINE is passed)',\n",
      " '{prefix}',\n",
      " '{body}',\n",
      " '{param_group}',\n",
      " '[ \\\\t]*       # any number of spaces and/or tabs',\n",
      " '$            # end of line (since re.MULTILINE is passed)',\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _mk_flag_re(body, n_params, comment):\\n'\n",
      " '    \"Compiles a regex for finding nbdev flags\"\\n'\n",
      " \"    assert body!=True, 'magics no longer supported'\\n\"\n",
      " '    prefix = r\"\\\\s*\\\\#\\\\s*\"\\n'\n",
      " '    param_group = \"\"\\n'\n",
      " '    if n_params == -1: param_group = r\"[ \\\\t]+(.+)\"\\n'\n",
      " '    if n_params == 1: param_group = r\"[ \\\\t]+(\\\\S+)\"\\n'\n",
      " '    if n_params == (0,1): param_group = r\"(?:[ \\\\t]+(\\\\S+))?\"\\n'\n",
      " '    return re.compile(rf\"\"\"\\n'\n",
      " '# {comment}:\\n'\n",
      " '^            # beginning of line (since re.MULTILINE is passed)\\n'\n",
      " '{prefix}\\n'\n",
      " '{body}\\n'\n",
      " '{param_group}\\n'\n",
      " '[ \\\\t]*       # any number of spaces and/or tabs\\n'\n",
      " '$            # end of line (since re.MULTILINE is passed)\\n'\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)')\n",
      "code_lines: ['_re_blank_export = _mk_flag_re(\"export[si]?\", 0,',\n",
      " '    \"Matches any line with #export, #exports or #exporti without any module '\n",
      " 'name\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_blank_export = _mk_flag_re(\"export[si]?\", 0,\\n'\n",
      " '    \"Matches any line with #export, #exports or #exporti without any module '\n",
      " 'name\")')\n",
      "code_lines: ['_re_mod_export = _mk_flag_re(\"export[si]?\", 1,',\n",
      " '    \"Matches any line with #export, #exports or #exporti with a module name '\n",
      " 'and catches it in group 1\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_mod_export = _mk_flag_re(\"export[si]?\", 1,\\n'\n",
      " '    \"Matches any line with #export, #exports or #exporti with a module name '\n",
      " 'and catches it in group 1\")')\n",
      "code_lines: ['_re_internal_export = _mk_flag_re(\"exporti\", (0,1),',\n",
      " '    \"Matches any line with #exporti with or without a module name\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_internal_export = _mk_flag_re(\"exporti\", (0,1),\\n'\n",
      " '    \"Matches any line with #exporti with or without a module name\")')\n",
      "code_lines: ['def _is_external_export(tst):',\n",
      " '    \"Check if a cell is an external or internal export. `tst` is an re '\n",
      " 'match\"',\n",
      " '    return _re_internal_export.search(tst.string) is None']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Internal Cell\\n'\n",
      " 'def _is_external_export(tst):\\n'\n",
      " '    \"Check if a cell is an external or internal export. `tst` is an re '\n",
      " 'match\"\\n'\n",
      " '    return _re_internal_export.search(tst.string) is None')\n",
      "code_lines: ['def is_export(cell, default):',\n",
      " '    \"Check if `cell` is to be exported and returns the name of the module to '\n",
      " 'export it if provided\"',\n",
      " '    tst = check_re(cell, _re_blank_export)',\n",
      " '    if tst:',\n",
      " '        if default is None:',\n",
      " '            print(f\"No export destination, ignored:\\\\n{cell[\\'source\\']}\")',\n",
      " '        return default, _is_external_export(tst)',\n",
      " '    tst = check_re(cell, _re_mod_export)',\n",
      " \"    if tst: return os.path.sep.join(tst.groups()[0].split('.')), \"\n",
      " '_is_external_export(tst)',\n",
      " '    else: return None']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def is_export(cell, default):\\n'\n",
      " '    \"Check if `cell` is to be exported and returns the name of the module to '\n",
      " 'export it if provided\"\\n'\n",
      " '    tst = check_re(cell, _re_blank_export)\\n'\n",
      " '    if tst:\\n'\n",
      " '        if default is None:\\n'\n",
      " '            print(f\"No export destination, ignored:\\\\n{cell[\\'source\\']}\")\\n'\n",
      " '        return default, _is_external_export(tst)\\n'\n",
      " '    tst = check_re(cell, _re_mod_export)\\n'\n",
      " \"    if tst: return os.path.sep.join(tst.groups()[0].split('.')), \"\n",
      " '_is_external_export(tst)\\n'\n",
      " '    else: return None')\n",
      "code_lines: ['_re_default_exp = _mk_flag_re(\\'default_exp\\', 1, \"Matches any line with '\n",
      " '#default_exp with a module name\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_default_exp = _mk_flag_re(\\'default_exp\\', 1, \"Matches any line with '\n",
      " '#default_exp with a module name\")')\n",
      "code_lines: ['def find_default_export(cells):',\n",
      " '    \"Find in `cells` the default export module.\"',\n",
      " '    res = L(cells).map_first(check_re, pat=_re_default_exp)',\n",
      " '    return res.groups()[0] if res else None']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def find_default_export(cells):\\n'\n",
      " '    \"Find in `cells` the default export module.\"\\n'\n",
      " '    res = L(cells).map_first(check_re, pat=_re_default_exp)\\n'\n",
      " '    return res.groups()[0] if res else None')\n",
      "code_lines: ['_re_patch_func = re.compile(r\"\"\"',\n",
      " '# Catches any function decorated with @patch, its name in group 1 and the '\n",
      " 'patched class in group 2',\n",
      " '@patch         # At any place in the cell, something that begins with @patch',\n",
      " '(?:\\\\s*@.*)*    # Any other decorator applied to the function',\n",
      " '\\\\s*def         # Any number of whitespace (including a new line probably) '\n",
      " 'followed by def',\n",
      " '\\\\s+            # One whitespace or more',\n",
      " '([^\\\\(\\\\s]+)     # Catch a group composed of anything but whitespace or an '\n",
      " 'opening parenthesis (name of the function)',\n",
      " '\\\\s*\\\\(          # Any number of whitespace followed by an opening '\n",
      " 'parenthesis',\n",
      " '[^:]*          # Any number of character different of : (the name of the '\n",
      " 'first arg that is type-annotated)',\n",
      " ':\\\\s*           # A column followed by any number of whitespace',\n",
      " '(?:            # Non-catching group with either',\n",
      " '([^,\\\\s\\\\(\\\\)]*)  #    a group composed of anything but a comma, a '\n",
      " 'parenthesis or whitespace (name of the class)',\n",
      " '|              #  or',\n",
      " '(\\\\([^\\\\)]*\\\\)))  #    a group composed of something between parenthesis '\n",
      " '(tuple of classes)',\n",
      " '\\\\s*            # Any number of whitespace',\n",
      " '(?:,|\\\\))       # Non-catching group with either a comma or a closing '\n",
      " 'parenthesis',\n",
      " '\"\"\", re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_patch_func = re.compile(r\"\"\"\\n'\n",
      " '# Catches any function decorated with @patch, its name in group 1 and the '\n",
      " 'patched class in group 2\\n'\n",
      " '@patch         # At any place in the cell, something that begins with '\n",
      " '@patch\\n'\n",
      " '(?:\\\\s*@.*)*    # Any other decorator applied to the function\\n'\n",
      " '\\\\s*def         # Any number of whitespace (including a new line probably) '\n",
      " 'followed by def\\n'\n",
      " '\\\\s+            # One whitespace or more\\n'\n",
      " '([^\\\\(\\\\s]+)     # Catch a group composed of anything but whitespace or an '\n",
      " 'opening parenthesis (name of the function)\\n'\n",
      " '\\\\s*\\\\(          # Any number of whitespace followed by an opening '\n",
      " 'parenthesis\\n'\n",
      " '[^:]*          # Any number of character different of : (the name of the '\n",
      " 'first arg that is type-annotated)\\n'\n",
      " ':\\\\s*           # A column followed by any number of whitespace\\n'\n",
      " '(?:            # Non-catching group with either\\n'\n",
      " '([^,\\\\s\\\\(\\\\)]*)  #    a group composed of anything but a comma, a '\n",
      " 'parenthesis or whitespace (name of the class)\\n'\n",
      " '|              #  or\\n'\n",
      " '(\\\\([^\\\\)]*\\\\)))  #    a group composed of something between parenthesis '\n",
      " '(tuple of classes)\\n'\n",
      " '\\\\s*            # Any number of whitespace\\n'\n",
      " '(?:,|\\\\))       # Non-catching group with either a comma or a closing '\n",
      " 'parenthesis\\n'\n",
      " '\"\"\", re.VERBOSE)')\n",
      "code_lines: ['_re_typedispatch_func = re.compile(r\"\"\"',\n",
      " '# Catches any function decorated with @typedispatch',\n",
      " '(@typedispatch  # At any place in the cell, catch a group with something '\n",
      " 'that begins with @typedispatch',\n",
      " '\\\\s*def          # Any number of whitespace (including a new line probably) '\n",
      " 'followed by def',\n",
      " '\\\\s+             # One whitespace or more',\n",
      " '[^\\\\(]+          # Anything but whitespace or an opening parenthesis (name '\n",
      " 'of the function)',\n",
      " '\\\\s*\\\\(           # Any number of whitespace followed by an opening '\n",
      " 'parenthesis',\n",
      " '[^\\\\)]*          # Any number of character different of )',\n",
      " '\\\\)[\\\\s\\\\S]*:)     # A closing parenthesis followed by any number of '\n",
      " 'characters and whitespace (type annotation) and :',\n",
      " '\"\"\", re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_typedispatch_func = re.compile(r\"\"\"\\n'\n",
      " '# Catches any function decorated with @typedispatch\\n'\n",
      " '(@typedispatch  # At any place in the cell, catch a group with something '\n",
      " 'that begins with @typedispatch\\n'\n",
      " '\\\\s*def          # Any number of whitespace (including a new line probably) '\n",
      " 'followed by def\\n'\n",
      " '\\\\s+             # One whitespace or more\\n'\n",
      " '[^\\\\(]+          # Anything but whitespace or an opening parenthesis (name '\n",
      " 'of the function)\\n'\n",
      " '\\\\s*\\\\(           # Any number of whitespace followed by an opening '\n",
      " 'parenthesis\\n'\n",
      " '[^\\\\)]*          # Any number of character different of )\\n'\n",
      " '\\\\)[\\\\s\\\\S]*:)     # A closing parenthesis followed by any number of '\n",
      " 'characters and whitespace (type annotation) and :\\n'\n",
      " '\"\"\", re.VERBOSE)')\n",
      "code_lines: ['_re_class_func_def = re.compile(r\"\"\"',\n",
      " '# Catches any 0-indented function or class definition with its name in group '\n",
      " '1',\n",
      " '^              # Beginning of a line (since re.MULTILINE is passed)',\n",
      " '(?:async\\\\sdef|def|class)  # Non-catching group for def or class',\n",
      " '\\\\s+            # One whitespace or more',\n",
      " '([^\\\\(\\\\s]+)     # Catching group with any character except an opening '\n",
      " 'parenthesis or a whitespace (name)',\n",
      " '\\\\s*            # Any number of whitespace',\n",
      " '(?:\\\\(|:)       # Non-catching group with either an opening parenthesis or a '\n",
      " \": (classes don't need ())\",\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_class_func_def = re.compile(r\"\"\"\\n'\n",
      " '# Catches any 0-indented function or class definition with its name in group '\n",
      " '1\\n'\n",
      " '^              # Beginning of a line (since re.MULTILINE is passed)\\n'\n",
      " '(?:async\\\\sdef|def|class)  # Non-catching group for def or class\\n'\n",
      " '\\\\s+            # One whitespace or more\\n'\n",
      " '([^\\\\(\\\\s]+)     # Catching group with any character except an opening '\n",
      " 'parenthesis or a whitespace (name)\\n'\n",
      " '\\\\s*            # Any number of whitespace\\n'\n",
      " '(?:\\\\(|:)       # Non-catching group with either an opening parenthesis or a '\n",
      " \": (classes don't need ())\\n\"\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)')\n",
      "code_lines: ['_re_obj_def = re.compile(r\"\"\"',\n",
      " '# Catches any 0-indented object definition (bla = thing) with its name in '\n",
      " 'group 1',\n",
      " '^                          # Beginning of a line (since re.MULTILINE is '\n",
      " 'passed)',\n",
      " '([_a-zA-Z]+[a-zA-Z0-9_\\\\.]*)  # Catch a group which is a valid python '\n",
      " 'variable name',\n",
      " '\\\\s*                        # Any number of whitespace',\n",
      " '(?::\\\\s*\\\\S.*|)=  # Non-catching group of either a colon followed by a type '\n",
      " 'annotation, or nothing; followed by an =',\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_obj_def = re.compile(r\"\"\"\\n'\n",
      " '# Catches any 0-indented object definition (bla = thing) with its name in '\n",
      " 'group 1\\n'\n",
      " '^                          # Beginning of a line (since re.MULTILINE is '\n",
      " 'passed)\\n'\n",
      " '([_a-zA-Z]+[a-zA-Z0-9_\\\\.]*)  # Catch a group which is a valid python '\n",
      " 'variable name\\n'\n",
      " '\\\\s*                        # Any number of whitespace\\n'\n",
      " '(?::\\\\s*\\\\S.*|)=  # Non-catching group of either a colon followed by a type '\n",
      " 'annotation, or nothing; followed by an =\\n'\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)')\n",
      "code_lines: ['def _not_private(n):',\n",
      " \"    for t in n.split('.'):\",\n",
      " \"        if (t.startswith('_') and not t.startswith('__')) or \"\n",
      " \"t.startswith('@'): return False\",\n",
      " \"    return '\\\\\\\\' not in t and '^' not in t and '[' not in t and t != 'else'\",\n",
      " '',\n",
      " 'def export_names(code, func_only=False):',\n",
      " '    \"Find the names of the objects, functions or classes defined in `code` '\n",
      " 'that are exported.\"',\n",
      " '    #Format monkey-patches with @patch',\n",
      " '    def _f(gps):',\n",
      " '        nm, cls, t = gps.groups()',\n",
      " '        if cls is not None: return f\"def {cls}.{nm}():\"',\n",
      " '        return \\'\\\\n\\'.join([f\"def {c}.{nm}():\" for c in re.split(\\', *\\', '\n",
      " 't[1:-1])])',\n",
      " '',\n",
      " \"    code = _re_typedispatch_func.sub('', code)\",\n",
      " '    code = _re_patch_func.sub(_f, code)',\n",
      " '    names = _re_class_func_def.findall(code)',\n",
      " '    if not func_only: names += _re_obj_def.findall(code)',\n",
      " '    return [n for n in names if _not_private(n) and not iskeyword(n)]']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _not_private(n):\\n'\n",
      " \"    for t in n.split('.'):\\n\"\n",
      " \"        if (t.startswith('_') and not t.startswith('__')) or \"\n",
      " \"t.startswith('@'): return False\\n\"\n",
      " \"    return '\\\\\\\\' not in t and '^' not in t and '[' not in t and t != \"\n",
      " \"'else'\\n\"\n",
      " '\\n'\n",
      " 'def export_names(code, func_only=False):\\n'\n",
      " '    \"Find the names of the objects, functions or classes defined in `code` '\n",
      " 'that are exported.\"\\n'\n",
      " '    #Format monkey-patches with @patch\\n'\n",
      " '    def _f(gps):\\n'\n",
      " '        nm, cls, t = gps.groups()\\n'\n",
      " '        if cls is not None: return f\"def {cls}.{nm}():\"\\n'\n",
      " '        return \\'\\\\n\\'.join([f\"def {c}.{nm}():\" for c in re.split(\\', *\\', '\n",
      " 't[1:-1])])\\n'\n",
      " '\\n'\n",
      " \"    code = _re_typedispatch_func.sub('', code)\\n\"\n",
      " '    code = _re_patch_func.sub(_f, code)\\n'\n",
      " '    names = _re_class_func_def.findall(code)\\n'\n",
      " '    if not func_only: names += _re_obj_def.findall(code)\\n'\n",
      " '    return [n for n in names if _not_private(n) and not iskeyword(n)]')\n",
      "code_lines: ['_re_all_def   = re.compile(r\"\"\"',\n",
      " '# Catches a cell with defines \\\\_all\\\\_ = [\\\\*\\\\*] and get that \\\\*\\\\* in '\n",
      " 'group 1',\n",
      " '^_all_   #  Beginning of line (since re.MULTILINE is passed)',\n",
      " '\\\\s*=\\\\s*  #  Any number of whitespace, =, any number of whitespace',\n",
      " '\\\\[       #  Opening [',\n",
      " '([^\\\\n\\\\]]*) #  Catching group with anything except a ] or newline',\n",
      " '\\\\]       #  Closing ]',\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)',\n",
      " '',\n",
      " '#Same with __all__',\n",
      " \"_re__all__def = re.compile(r'^__all__\\\\s*=\\\\s*\\\\[([^\\\\]]*)\\\\]', \"\n",
      " 're.MULTILINE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_all_def   = re.compile(r\"\"\"\\n'\n",
      " '# Catches a cell with defines \\\\_all\\\\_ = [\\\\*\\\\*] and get that \\\\*\\\\* in '\n",
      " 'group 1\\n'\n",
      " '^_all_   #  Beginning of line (since re.MULTILINE is passed)\\n'\n",
      " '\\\\s*=\\\\s*  #  Any number of whitespace, =, any number of whitespace\\n'\n",
      " '\\\\[       #  Opening [\\n'\n",
      " '([^\\\\n\\\\]]*) #  Catching group with anything except a ] or newline\\n'\n",
      " '\\\\]       #  Closing ]\\n'\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)\\n'\n",
      " '\\n'\n",
      " '#Same with __all__\\n'\n",
      " \"_re__all__def = re.compile(r'^__all__\\\\s*=\\\\s*\\\\[([^\\\\]]*)\\\\]', \"\n",
      " 're.MULTILINE)')\n",
      "code_lines: ['def extra_add(flags, code):',\n",
      " '    \"Catch adds to `__all__` required by a cell with `_all_=`\"',\n",
      " \"    m = check_re({'source': code}, _re_all_def, False)\",\n",
      " '    if m:',\n",
      " \"        code = m.re.sub('#nbdev_' + 'comment \\\\g<0>', code)\",\n",
      " \"        code = re.sub(r'([^\\\\n]|^)\\\\n*$', r'\\\\1', code)\",\n",
      " '    if not m: return [], code',\n",
      " '    def clean_quotes(s):',\n",
      " '        \"Return `s` enclosed in single quotes, removing double quotes if '\n",
      " 'needed\"',\n",
      " '        if s.startswith(\"\\'\") and s.endswith(\"\\'\"): return s',\n",
      " '        if s.startswith(\\'\"\\') and s.endswith(\\'\"\\'): s = s[1:-1]',\n",
      " '        return f\"\\'{s}\\'\"',\n",
      " '    return [clean_quotes(s) for s in parse_line(m.group(1))], code']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def extra_add(flags, code):\\n'\n",
      " '    \"Catch adds to `__all__` required by a cell with `_all_=`\"\\n'\n",
      " \"    m = check_re({'source': code}, _re_all_def, False)\\n\"\n",
      " '    if m:\\n'\n",
      " \"        code = m.re.sub('#nbdev_' + 'comment \\\\g<0>', code)\\n\"\n",
      " \"        code = re.sub(r'([^\\\\n]|^)\\\\n*$', r'\\\\1', code)\\n\"\n",
      " '    if not m: return [], code\\n'\n",
      " '    def clean_quotes(s):\\n'\n",
      " '        \"Return `s` enclosed in single quotes, removing double quotes if '\n",
      " 'needed\"\\n'\n",
      " '        if s.startswith(\"\\'\") and s.endswith(\"\\'\"): return s\\n'\n",
      " '        if s.startswith(\\'\"\\') and s.endswith(\\'\"\\'): s = s[1:-1]\\n'\n",
      " '        return f\"\\'{s}\\'\"\\n'\n",
      " '    return [clean_quotes(s) for s in parse_line(m.group(1))], code')\n",
      "code_lines: ['_re_from_future_import = re.compile(r\"^from[ \\\\t]+__future__[ '\n",
      " '\\\\t]+import.*$\", re.MULTILINE)',\n",
      " '',\n",
      " 'def _from_future_import(fname, flags, code, to_dict=None):',\n",
      " '    \"Write `__future__` imports to `fname` and return `code` with '\n",
      " '`__future__` imports commented out\"',\n",
      " '    from_future_imports = _re_from_future_import.findall(code)',\n",
      " \"    if from_future_imports: code = _re_from_future_import.sub('#nbdev' + \"\n",
      " \"'_comment \\\\g<0>', code)\",\n",
      " '    else: from_future_imports = _re_from_future_import.findall(flags)',\n",
      " '    if not from_future_imports or to_dict is not None: return code',\n",
      " \"    with open(fname, 'r', encoding='utf8') as f: text = f.read()\",\n",
      " '    start = _re__all__def.search(text).start()',\n",
      " \"    with open(fname, 'w', encoding='utf8') as f:\",\n",
      " \"        f.write('\\\\n'.join([text[:start], *from_future_imports, '\\\\n', \"\n",
      " 'text[start:]]))',\n",
      " '    return code']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_from_future_import = re.compile(r\"^from[ \\\\t]+__future__[ '\n",
      " '\\\\t]+import.*$\", re.MULTILINE)\\n'\n",
      " '\\n'\n",
      " 'def _from_future_import(fname, flags, code, to_dict=None):\\n'\n",
      " '    \"Write `__future__` imports to `fname` and return `code` with '\n",
      " '`__future__` imports commented out\"\\n'\n",
      " '    from_future_imports = _re_from_future_import.findall(code)\\n'\n",
      " \"    if from_future_imports: code = _re_from_future_import.sub('#nbdev' + \"\n",
      " \"'_comment \\\\g<0>', code)\\n\"\n",
      " '    else: from_future_imports = _re_from_future_import.findall(flags)\\n'\n",
      " '    if not from_future_imports or to_dict is not None: return code\\n'\n",
      " \"    with open(fname, 'r', encoding='utf8') as f: text = f.read()\\n\"\n",
      " '    start = _re__all__def.search(text).start()\\n'\n",
      " \"    with open(fname, 'w', encoding='utf8') as f:\\n\"\n",
      " \"        f.write('\\\\n'.join([text[:start], *from_future_imports, '\\\\n', \"\n",
      " 'text[start:]]))\\n'\n",
      " '    return code')\n",
      "code_lines: ['def _add2all(fname, names, line_width=120):',\n",
      " '    if len(names) == 0: return',\n",
      " \"    with open(fname, 'r', encoding='utf8') as f: text = f.read()\",\n",
      " \"    tw = TextWrapper(width=120, initial_indent='', subsequent_indent=' '*11, \"\n",
      " 'break_long_words=False)',\n",
      " '    re_all = _re__all__def.search(text)',\n",
      " '    start,end = re_all.start(),re_all.end()',\n",
      " '    text_all = tw.wrap(f\"{text[start:end-1]}{\\'\\' if text[end-2]==\\'[\\' else '\n",
      " '\\', \\'}{\\', \\'.join(names)}]\")',\n",
      " \"    with open(fname, 'w', encoding='utf8') as f: f.write(text[:start] + \"\n",
      " \"'\\\\n'.join(text_all) + text[end:])\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _add2all(fname, names, line_width=120):\\n'\n",
      " '    if len(names) == 0: return\\n'\n",
      " \"    with open(fname, 'r', encoding='utf8') as f: text = f.read()\\n\"\n",
      " \"    tw = TextWrapper(width=120, initial_indent='', subsequent_indent=' '*11, \"\n",
      " 'break_long_words=False)\\n'\n",
      " '    re_all = _re__all__def.search(text)\\n'\n",
      " '    start,end = re_all.start(),re_all.end()\\n'\n",
      " '    text_all = tw.wrap(f\"{text[start:end-1]}{\\'\\' if text[end-2]==\\'[\\' else '\n",
      " '\\', \\'}{\\', \\'.join(names)}]\")\\n'\n",
      " \"    with open(fname, 'w', encoding='utf8') as f: f.write(text[:start] + \"\n",
      " \"'\\\\n'.join(text_all) + text[end:])\")\n",
      "code_lines: ['def relative_import(name, fname):',\n",
      " '    \"Convert a module `name` to a name relative to `fname`\"',\n",
      " \"    mods = name.split('.')\",\n",
      " '    splits = str(fname).split(os.path.sep)',\n",
      " '    if mods[0] not in splits: return name',\n",
      " '    i=len(splits)-1',\n",
      " '    while i>0 and splits[i] != mods[0]: i-=1',\n",
      " '    splits = splits[i:]',\n",
      " '    while len(mods)>0 and splits[0] == mods[0]: splits,mods = '\n",
      " 'splits[1:],mods[1:]',\n",
      " \"    return '.' * (len(splits)) + '.'.join(mods)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def relative_import(name, fname):\\n'\n",
      " '    \"Convert a module `name` to a name relative to `fname`\"\\n'\n",
      " \"    mods = name.split('.')\\n\"\n",
      " '    splits = str(fname).split(os.path.sep)\\n'\n",
      " '    if mods[0] not in splits: return name\\n'\n",
      " '    i=len(splits)-1\\n'\n",
      " '    while i>0 and splits[i] != mods[0]: i-=1\\n'\n",
      " '    splits = splits[i:]\\n'\n",
      " '    while len(mods)>0 and splits[0] == mods[0]: splits,mods = '\n",
      " 'splits[1:],mods[1:]\\n'\n",
      " \"    return '.' * (len(splits)) + '.'.join(mods)\")\n",
      "code_lines: [\"_re_import = ReLibName(r'^(\\\\s*)from (LIB_NAME\\\\.\\\\S*) import (.*)$')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_re_import = ReLibName(r'^(\\\\s*)from (LIB_NAME\\\\.\\\\S*) import (.*)$')\")\n",
      "code_lines: ['def _deal_import(code_lines, fname):',\n",
      " '    def _replace(m):',\n",
      " '        sp,mod,obj = m.groups()',\n",
      " '        return f\"{sp}from {relative_import(mod, fname)} import {obj}\"',\n",
      " '    return [_re_import.re.sub(_replace,line) for line in code_lines]']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _deal_import(code_lines, fname):\\n'\n",
      " '    def _replace(m):\\n'\n",
      " '        sp,mod,obj = m.groups()\\n'\n",
      " '        return f\"{sp}from {relative_import(mod, fname)} import {obj}\"\\n'\n",
      " '    return [_re_import.re.sub(_replace,line) for line in code_lines]')\n",
      "code_lines: [\"_re_index_custom = re.compile(r'def custom_doc_links\\\\(name\\\\):(.*)$', \"\n",
      " 're.DOTALL)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_re_index_custom = re.compile(r'def custom_doc_links\\\\(name\\\\):(.*)$', \"\n",
      " 're.DOTALL)')\n",
      "code_lines: ['def reset_nbdev_module():',\n",
      " '    \"Create a skeleton for <code>_nbdev</code>\"',\n",
      " '    fname = Config().path(\"lib_path\")/\\'_nbdev.py\\'',\n",
      " '    fname.parent.mkdir(parents=True, exist_ok=True)',\n",
      " \"    sep = '\\\\n'* (int(Config().get('cell_spacing', '1'))+1)\",\n",
      " '    if fname.is_file():',\n",
      " \"        with open(fname, 'r') as f: search = \"\n",
      " '_re_index_custom.search(f.read())',\n",
      " '    else: search = None',\n",
      " \"    prev_code = search.groups()[0] if search is not None else ' return \"\n",
      " \"None\\\\n'\",\n",
      " \"    with open(fname, 'w') as f:\",\n",
      " '        f.write(f\"# AUTOGENERATED BY NBDEV! DO NOT EDIT!\")',\n",
      " '        f.write(\\'\\\\n\\\\n__all__ = [\"index\", \"modules\", \"custom_doc_links\", '\n",
      " '\"git_url\"]\\')',\n",
      " \"        f.write('\\\\n\\\\nindex = {}')\",\n",
      " \"        f.write('\\\\n\\\\nmodules = []')\",\n",
      " \"        f.write(f'\\\\n\\\\ndoc_url = \"\n",
      " '\"{Config().doc_host}{Config().doc_baseurl}\"\\')',\n",
      " '        f.write(f\\'\\\\n\\\\ngit_url = \"{Config().git_url}\"\\')',\n",
      " \"        f.write(f'{sep}def custom_doc_links(name):{prev_code}')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def reset_nbdev_module():\\n'\n",
      " '    \"Create a skeleton for <code>_nbdev</code>\"\\n'\n",
      " '    fname = Config().path(\"lib_path\")/\\'_nbdev.py\\'\\n'\n",
      " '    fname.parent.mkdir(parents=True, exist_ok=True)\\n'\n",
      " \"    sep = '\\\\n'* (int(Config().get('cell_spacing', '1'))+1)\\n\"\n",
      " '    if fname.is_file():\\n'\n",
      " \"        with open(fname, 'r') as f: search = \"\n",
      " '_re_index_custom.search(f.read())\\n'\n",
      " '    else: search = None\\n'\n",
      " \"    prev_code = search.groups()[0] if search is not None else ' return \"\n",
      " \"None\\\\n'\\n\"\n",
      " \"    with open(fname, 'w') as f:\\n\"\n",
      " '        f.write(f\"# AUTOGENERATED BY NBDEV! DO NOT EDIT!\")\\n'\n",
      " '        f.write(\\'\\\\n\\\\n__all__ = [\"index\", \"modules\", \"custom_doc_links\", '\n",
      " '\"git_url\"]\\')\\n'\n",
      " \"        f.write('\\\\n\\\\nindex = {}')\\n\"\n",
      " \"        f.write('\\\\n\\\\nmodules = []')\\n\"\n",
      " \"        f.write(f'\\\\n\\\\ndoc_url = \"\n",
      " '\"{Config().doc_host}{Config().doc_baseurl}\"\\')\\n'\n",
      " '        f.write(f\\'\\\\n\\\\ngit_url = \"{Config().git_url}\"\\')\\n'\n",
      " \"        f.write(f'{sep}def custom_doc_links(name):{prev_code}')\")\n",
      "code_lines: ['class _EmptyModule():',\n",
      " '    def __init__(self):',\n",
      " '        self.index,self.modules = {},[]',\n",
      " '        self.doc_url,self.git_url = '\n",
      " 'f\"{Config().doc_host}{Config().doc_baseurl}\",Config().git_url',\n",
      " '',\n",
      " '    def custom_doc_links(self, name): return None']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'class _EmptyModule():\\n'\n",
      " '    def __init__(self):\\n'\n",
      " '        self.index,self.modules = {},[]\\n'\n",
      " '        self.doc_url,self.git_url = '\n",
      " 'f\"{Config().doc_host}{Config().doc_baseurl}\",Config().git_url\\n'\n",
      " '\\n'\n",
      " '    def custom_doc_links(self, name): return None')\n",
      "code_lines: ['def get_nbdev_module():',\n",
      " '    \"Reads <code>_nbdev</code>\"',\n",
      " '    try:',\n",
      " '        spec = '\n",
      " 'importlib.util.spec_from_file_location(f\"{Config().lib_name}._nbdev\", '\n",
      " 'Config().path(\"lib_path\")/\\'_nbdev.py\\')',\n",
      " '        mod = importlib.util.module_from_spec(spec)',\n",
      " '        spec.loader.exec_module(mod)',\n",
      " '        return mod',\n",
      " '    except: return _EmptyModule()']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def get_nbdev_module():\\n'\n",
      " '    \"Reads <code>_nbdev</code>\"\\n'\n",
      " '    try:\\n'\n",
      " '        spec = '\n",
      " 'importlib.util.spec_from_file_location(f\"{Config().lib_name}._nbdev\", '\n",
      " 'Config().path(\"lib_path\")/\\'_nbdev.py\\')\\n'\n",
      " '        mod = importlib.util.module_from_spec(spec)\\n'\n",
      " '        spec.loader.exec_module(mod)\\n'\n",
      " '        return mod\\n'\n",
      " '    except: return _EmptyModule()')\n",
      "code_lines: [\"_re_index_idx = re.compile(r'index\\\\s*=\\\\s*{[^}]*}')\",\n",
      " \"_re_index_mod = re.compile(r'modules\\\\s*=\\\\s*\\\\[[^\\\\]]*\\\\]')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_re_index_idx = re.compile(r'index\\\\s*=\\\\s*{[^}]*}')\\n\"\n",
      " \"_re_index_mod = re.compile(r'modules\\\\s*=\\\\s*\\\\[[^\\\\]]*\\\\]')\")\n",
      "code_lines: ['def save_nbdev_module(mod):',\n",
      " '    \"Save `mod` inside <code>_nbdev</code>\"',\n",
      " '    fname = Config().path(\"lib_path\")/\\'_nbdev.py\\'',\n",
      " \"    with open(fname, 'r') as f: code = f.read()\",\n",
      " '    t = r\\',\\\\n         \\'.join([f\\'\"{k}\": \"{v}\"\\' for k,v in '\n",
      " 'mod.index.items()])',\n",
      " '    code = _re_index_idx.sub(\"index = {\"+ t +\"}\", code)',\n",
      " '    t = r\\',\\\\n           \\'.join([\\'\"\\' + f.replace(\\'\\\\\\\\\\',\\'/\\') + \\'\"\\' '\n",
      " 'for f in mod.modules])',\n",
      " '    code = _re_index_mod.sub(f\"modules = [{t}]\", code)',\n",
      " \"    with open(fname, 'w') as f: f.write(code)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def save_nbdev_module(mod):\\n'\n",
      " '    \"Save `mod` inside <code>_nbdev</code>\"\\n'\n",
      " '    fname = Config().path(\"lib_path\")/\\'_nbdev.py\\'\\n'\n",
      " \"    with open(fname, 'r') as f: code = f.read()\\n\"\n",
      " '    t = r\\',\\\\n         \\'.join([f\\'\"{k}\": \"{v}\"\\' for k,v in '\n",
      " 'mod.index.items()])\\n'\n",
      " '    code = _re_index_idx.sub(\"index = {\"+ t +\"}\", code)\\n'\n",
      " '    t = r\\',\\\\n           \\'.join([\\'\"\\' + f.replace(\\'\\\\\\\\\\',\\'/\\') + \\'\"\\' '\n",
      " 'for f in mod.modules])\\n'\n",
      " '    code = _re_index_mod.sub(f\"modules = [{t}]\", code)\\n'\n",
      " \"    with open(fname, 'w') as f: f.write(code)\")\n",
      "code_lines: ['def split_flags_and_code(cell, return_type=list):',\n",
      " '    \"Splits the `source` of a cell into 2 parts and returns (flags, code)\"',\n",
      " \"    source_str = cell['source'].replace('\\\\r', '')\",\n",
      " \"    code_lines = source_str.split('\\\\n')\",\n",
      " \"    split_pos = 0 if code_lines[0].strip().startswith('#') else -1\",\n",
      " '    for i, line in enumerate(code_lines):',\n",
      " \"        if not line.startswith('#') and line.strip() and not \"\n",
      " '_re_from_future_import.match(line): break',\n",
      " '    split_pos+=1',\n",
      " '    res = code_lines[:split_pos], code_lines[split_pos:]',\n",
      " '    if return_type is list: return res',\n",
      " \"    return tuple('\\\\n'.join(r) for r in res)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def split_flags_and_code(cell, return_type=list):\\n'\n",
      " '    \"Splits the `source` of a cell into 2 parts and returns (flags, code)\"\\n'\n",
      " \"    source_str = cell['source'].replace('\\\\r', '')\\n\"\n",
      " \"    code_lines = source_str.split('\\\\n')\\n\"\n",
      " \"    split_pos = 0 if code_lines[0].strip().startswith('#') else -1\\n\"\n",
      " '    for i, line in enumerate(code_lines):\\n'\n",
      " \"        if not line.startswith('#') and line.strip() and not \"\n",
      " '_re_from_future_import.match(line): break\\n'\n",
      " '    split_pos+=1\\n'\n",
      " '    res = code_lines[:split_pos], code_lines[split_pos:]\\n'\n",
      " '    if return_type is list: return res\\n'\n",
      " \"    return tuple('\\\\n'.join(r) for r in res)\")\n",
      "code_lines: ['def create_mod_file(fname, nb_path, bare=False):',\n",
      " '    \"Create a module file for `fname`.\"',\n",
      " \"    bare = str(Config().get('bare', bare)) == 'True'\",\n",
      " '    fname.parent.mkdir(parents=True, exist_ok=True)',\n",
      " '    file_path = os.path.relpath(nb_path, '\n",
      " \"Config().config_file.parent).replace('\\\\\\\\', '/')\",\n",
      " \"    with open(fname, 'w') as f:\",\n",
      " '        if not bare: f.write(f\"# AUTOGENERATED! DO NOT EDIT! File to edit: '\n",
      " '{file_path} (unless otherwise specified).\")',\n",
      " \"        f.write('\\\\n\\\\n__all__ = []')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def create_mod_file(fname, nb_path, bare=False):\\n'\n",
      " '    \"Create a module file for `fname`.\"\\n'\n",
      " \"    bare = str(Config().get('bare', bare)) == 'True'\\n\"\n",
      " '    fname.parent.mkdir(parents=True, exist_ok=True)\\n'\n",
      " '    file_path = os.path.relpath(nb_path, '\n",
      " \"Config().config_file.parent).replace('\\\\\\\\', '/')\\n\"\n",
      " \"    with open(fname, 'w') as f:\\n\"\n",
      " '        if not bare: f.write(f\"# AUTOGENERATED! DO NOT EDIT! File to edit: '\n",
      " '{file_path} (unless otherwise specified).\")\\n'\n",
      " \"        f.write('\\\\n\\\\n__all__ = []')\")\n",
      "code_lines: ['def create_mod_files(files, to_dict=False, bare=False):',\n",
      " '    \"Create mod files for default exports found in `files`\"',\n",
      " '    modules = []',\n",
      " '    for f in sorted(files):',\n",
      " '        fname = Path(f)',\n",
      " '        nb = read_nb(fname)',\n",
      " \"        default = find_default_export(nb['cells'])\",\n",
      " '        if default is not None:',\n",
      " \"            default = os.path.sep.join(default.split('.'))\",\n",
      " '            modules.append(default)',\n",
      " '            if not to_dict:',\n",
      " '                create_mod_file(Config().path(\"lib_path\")/f\\'{default}.py\\', '\n",
      " 'Config().path(\"nbs_path\")/f\\'{fname}\\', bare=bare)',\n",
      " '    return modules']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def create_mod_files(files, to_dict=False, bare=False):\\n'\n",
      " '    \"Create mod files for default exports found in `files`\"\\n'\n",
      " '    modules = []\\n'\n",
      " '    for f in sorted(files):\\n'\n",
      " '        fname = Path(f)\\n'\n",
      " '        nb = read_nb(fname)\\n'\n",
      " \"        default = find_default_export(nb['cells'])\\n\"\n",
      " '        if default is not None:\\n'\n",
      " \"            default = os.path.sep.join(default.split('.'))\\n\"\n",
      " '            modules.append(default)\\n'\n",
      " '            if not to_dict:\\n'\n",
      " '                create_mod_file(Config().path(\"lib_path\")/f\\'{default}.py\\', '\n",
      " 'Config().path(\"nbs_path\")/f\\'{fname}\\', bare=bare)\\n'\n",
      " '    return modules')\n",
      "code_lines: ['def _notebook2script(fname, modules, silent=False, to_dict=None, '\n",
      " 'bare=False):',\n",
      " '    \"Finds cells starting with `#export` and puts them into a module created '\n",
      " 'by `create_mod_files`\"',\n",
      " \"    bare = str(Config().get('bare', bare)) == 'True'\",\n",
      " \"    if os.environ.get('IN_TEST',0): return  # don't export if running tests\",\n",
      " \"    sep = '\\\\n'* (int(Config().get('cell_spacing', '1'))+1)\",\n",
      " '    fname = Path(fname)',\n",
      " '    nb = read_nb(fname)',\n",
      " \"    default = find_default_export(nb['cells'])\",\n",
      " '    if default is not None:',\n",
      " \"        default = os.path.sep.join(default.split('.'))\",\n",
      " '    mod = get_nbdev_module()',\n",
      " \"    exports = [is_export(c, default) for c in nb['cells']]\",\n",
      " \"    cells = [(i,c,e) for i,(c,e) in enumerate(zip(nb['cells'],exports)) if e \"\n",
      " 'is not None]',\n",
      " '    for i,c,(e,a) in cells:',\n",
      " '        if e not in modules: print(f\\'Warning: Exporting to \"{e}.py\" but '\n",
      " \"this module is not part of this build')\",\n",
      " '        fname_out = Config().path(\"lib_path\")/f\\'{e}.py\\'',\n",
      " '        if bare: orig = \"\\\\n\"',\n",
      " '        else: orig = (f\\'# {\"\" if a else \"Internal \"}C\\' if e==default else '\n",
      " \"f'# Comes from {fname.name}, c') + 'ell\\\\n'\",\n",
      " '        flag_lines,code_lines = split_flags_and_code(c)',\n",
      " '        code_lines = _deal_import(code_lines, fname_out)',\n",
      " '        print(\"code_lines: \", end=\\'\\')',\n",
      " '        pprint(code_lines)',\n",
      " \"        code = sep + orig + '\\\\n'.join(code_lines)\",\n",
      " '        print(\"code: \", end=\\'\\')',\n",
      " '        pprint(code)',\n",
      " '        names = export_names(code)',\n",
      " \"        flags = '\\\\n'.join(flag_lines)\",\n",
      " '        extra,code = extra_add(flags, code)',\n",
      " '        code = _from_future_import(fname_out, flags, code, to_dict)',\n",
      " '        if a:',\n",
      " '            if to_dict is None: _add2all(fname_out, [f\"\\'{f}\\'\" for f in '\n",
      " \"names if '.' not in f and len(f) > 0] + extra)\",\n",
      " '        mod.index.update({f: fname.name for f in names})',\n",
      " \"        code = re.sub(r' +$', '', code, flags=re.MULTILINE)\",\n",
      " '        if code != sep + orig[:-1]:',\n",
      " '            if to_dict is not None: to_dict[e].append((i, fname, code))',\n",
      " '            else:',\n",
      " \"                with open(fname_out, 'a', encoding='utf8') as f: \"\n",
      " 'f.write(code)',\n",
      " \"        if f'{e}.py' not in mod.modules: mod.modules.append(f'{e}.py')\",\n",
      " '    save_nbdev_module(mod)',\n",
      " '',\n",
      " '    if not silent: print(f\"Converted {fname.name}.\")',\n",
      " '    return to_dict']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _notebook2script(fname, modules, silent=False, to_dict=None, '\n",
      " 'bare=False):\\n'\n",
      " '    \"Finds cells starting with `#export` and puts them into a module created '\n",
      " 'by `create_mod_files`\"\\n'\n",
      " \"    bare = str(Config().get('bare', bare)) == 'True'\\n\"\n",
      " \"    if os.environ.get('IN_TEST',0): return  # don't export if running tests\\n\"\n",
      " \"    sep = '\\\\n'* (int(Config().get('cell_spacing', '1'))+1)\\n\"\n",
      " '    fname = Path(fname)\\n'\n",
      " '    nb = read_nb(fname)\\n'\n",
      " \"    default = find_default_export(nb['cells'])\\n\"\n",
      " '    if default is not None:\\n'\n",
      " \"        default = os.path.sep.join(default.split('.'))\\n\"\n",
      " '    mod = get_nbdev_module()\\n'\n",
      " \"    exports = [is_export(c, default) for c in nb['cells']]\\n\"\n",
      " \"    cells = [(i,c,e) for i,(c,e) in enumerate(zip(nb['cells'],exports)) if e \"\n",
      " 'is not None]\\n'\n",
      " '    for i,c,(e,a) in cells:\\n'\n",
      " '        if e not in modules: print(f\\'Warning: Exporting to \"{e}.py\" but '\n",
      " \"this module is not part of this build')\\n\"\n",
      " '        fname_out = Config().path(\"lib_path\")/f\\'{e}.py\\'\\n'\n",
      " '        if bare: orig = \"\\\\n\"\\n'\n",
      " '        else: orig = (f\\'# {\"\" if a else \"Internal \"}C\\' if e==default else '\n",
      " \"f'# Comes from {fname.name}, c') + 'ell\\\\n'\\n\"\n",
      " '        flag_lines,code_lines = split_flags_and_code(c)\\n'\n",
      " '        code_lines = _deal_import(code_lines, fname_out)\\n'\n",
      " '        print(\"code_lines: \", end=\\'\\')\\n'\n",
      " '        pprint(code_lines)\\n'\n",
      " \"        code = sep + orig + '\\\\n'.join(code_lines)\\n\"\n",
      " '        print(\"code: \", end=\\'\\')\\n'\n",
      " '        pprint(code)\\n'\n",
      " '        names = export_names(code)\\n'\n",
      " \"        flags = '\\\\n'.join(flag_lines)\\n\"\n",
      " '        extra,code = extra_add(flags, code)\\n'\n",
      " '        code = _from_future_import(fname_out, flags, code, to_dict)\\n'\n",
      " '        if a:\\n'\n",
      " '            if to_dict is None: _add2all(fname_out, [f\"\\'{f}\\'\" for f in '\n",
      " \"names if '.' not in f and len(f) > 0] + extra)\\n\"\n",
      " '        mod.index.update({f: fname.name for f in names})\\n'\n",
      " \"        code = re.sub(r' +$', '', code, flags=re.MULTILINE)\\n\"\n",
      " '        if code != sep + orig[:-1]:\\n'\n",
      " '            if to_dict is not None: to_dict[e].append((i, fname, code))\\n'\n",
      " '            else:\\n'\n",
      " \"                with open(fname_out, 'a', encoding='utf8') as f: \"\n",
      " 'f.write(code)\\n'\n",
      " \"        if f'{e}.py' not in mod.modules: mod.modules.append(f'{e}.py')\\n\"\n",
      " '    save_nbdev_module(mod)\\n'\n",
      " '\\n'\n",
      " '    if not silent: print(f\"Converted {fname.name}.\")\\n'\n",
      " '    return to_dict')\n",
      "code_lines: ['def add_init(path):',\n",
      " '    \"Add `__init__.py` in all subdirs of `path` containing python files if '\n",
      " 'it\\'s not there already\"',\n",
      " '    for p,d,f in os.walk(path):',\n",
      " '        for f_ in f:',\n",
      " \"            if f_.endswith('.py'):\",\n",
      " \"                if not (Path(p)/'__init__.py').exists(): \"\n",
      " \"(Path(p)/'__init__.py').touch()\",\n",
      " '                break']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def add_init(path):\\n'\n",
      " '    \"Add `__init__.py` in all subdirs of `path` containing python files if '\n",
      " 'it\\'s not there already\"\\n'\n",
      " '    for p,d,f in os.walk(path):\\n'\n",
      " '        for f_ in f:\\n'\n",
      " \"            if f_.endswith('.py'):\\n\"\n",
      " \"                if not (Path(p)/'__init__.py').exists(): \"\n",
      " \"(Path(p)/'__init__.py').touch()\\n\"\n",
      " '                break')\n",
      "code_lines: [\"_re_version = re.compile('^__version__\\\\s*=.*$', re.MULTILINE)\"]\n",
      "code: \"\\n\\n# Cell\\n_re_version = re.compile('^__version__\\\\s*=.*$', re.MULTILINE)\"\n",
      "code_lines: ['def update_version():',\n",
      " '    \"Add or update `__version__` in the main `__init__.py` of the library\"',\n",
      " '    fname = Config().path(\"lib_path\")/\\'__init__.py\\'',\n",
      " '    if not fname.exists(): fname.touch()',\n",
      " '    version = f\\'__version__ = \"{Config().version}\"\\'',\n",
      " \"    with open(fname, 'r') as f: code = f.read()\",\n",
      " '    if _re_version.search(code) is None: code = version + \"\\\\n\" + code',\n",
      " '    else: code = _re_version.sub(version, code)',\n",
      " \"    with open(fname, 'w') as f: f.write(code)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def update_version():\\n'\n",
      " '    \"Add or update `__version__` in the main `__init__.py` of the library\"\\n'\n",
      " '    fname = Config().path(\"lib_path\")/\\'__init__.py\\'\\n'\n",
      " '    if not fname.exists(): fname.touch()\\n'\n",
      " '    version = f\\'__version__ = \"{Config().version}\"\\'\\n'\n",
      " \"    with open(fname, 'r') as f: code = f.read()\\n\"\n",
      " '    if _re_version.search(code) is None: code = version + \"\\\\n\" + code\\n'\n",
      " '    else: code = _re_version.sub(version, code)\\n'\n",
      " \"    with open(fname, 'w') as f: f.write(code)\")\n",
      "code_lines: [\"_re_baseurl = re.compile('^baseurl\\\\s*:.*$', re.MULTILINE)\"]\n",
      "code: \"\\n\\n# Cell\\n_re_baseurl = re.compile('^baseurl\\\\s*:.*$', re.MULTILINE)\"\n",
      "code_lines: ['def update_baseurl():',\n",
      " '    \"Add or update `baseurl` in `_config.yml` for the docs\"',\n",
      " '    fname = Config().path(\"doc_path\")/\\'_config.yml\\'',\n",
      " '    if not fname.exists(): return',\n",
      " \"    with open(fname, 'r') as f: code = f.read()\",\n",
      " '    if _re_baseurl.search(code) is None: code = code + f\"\\\\nbaseurl: '\n",
      " '{Config().doc_baseurl}\"',\n",
      " '    else: code = _re_baseurl.sub(f\"baseurl: {Config().doc_baseurl}\", code)',\n",
      " \"    with open(fname, 'w') as f: f.write(code)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def update_baseurl():\\n'\n",
      " '    \"Add or update `baseurl` in `_config.yml` for the docs\"\\n'\n",
      " '    fname = Config().path(\"doc_path\")/\\'_config.yml\\'\\n'\n",
      " '    if not fname.exists(): return\\n'\n",
      " \"    with open(fname, 'r') as f: code = f.read()\\n\"\n",
      " '    if _re_baseurl.search(code) is None: code = code + f\"\\\\nbaseurl: '\n",
      " '{Config().doc_baseurl}\"\\n'\n",
      " '    else: code = _re_baseurl.sub(f\"baseurl: {Config().doc_baseurl}\", code)\\n'\n",
      " \"    with open(fname, 'w') as f: f.write(code)\")\n",
      "code_lines: [\"def nbglob(fname=None, recursive=None, extension='.ipynb', \"\n",
      " \"config_key='nbs_path') -> L:\",\n",
      " '    \"Find all files in a directory matching an extension given a '\n",
      " '`config_key`. Ignores hidden directories and filenames starting with `_`.  '\n",
      " 'If argument `recursive` is not set to `True` or `False`, this value is '\n",
      " 'retreived from settings.ini with a default of `False`.\"',\n",
      " \"    if recursive == None: recursive=Config().get('recursive', \"\n",
      " \"'False').lower() == 'true'\",\n",
      " '    fname = Config().path(config_key) if fname is None else Path(fname)',\n",
      " \"    if fname.is_dir(): fname = f'{fname.absolute()}/**/*{extension}' if \"\n",
      " \"recursive else f'{fname.absolute()}/*{extension}'\",\n",
      " '    fls = L(glob.glob(str(fname), recursive=recursive)).filter(lambda x: '\n",
      " \"'/.' not in x).map(Path)\",\n",
      " \"    return fls.filter(lambda x: not x.name.startswith('_') and \"\n",
      " 'x.name.endswith(extension))']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"def nbglob(fname=None, recursive=None, extension='.ipynb', \"\n",
      " \"config_key='nbs_path') -> L:\\n\"\n",
      " '    \"Find all files in a directory matching an extension given a '\n",
      " '`config_key`. Ignores hidden directories and filenames starting with `_`.  '\n",
      " 'If argument `recursive` is not set to `True` or `False`, this value is '\n",
      " 'retreived from settings.ini with a default of `False`.\"\\n'\n",
      " \"    if recursive == None: recursive=Config().get('recursive', \"\n",
      " \"'False').lower() == 'true'\\n\"\n",
      " '    fname = Config().path(config_key) if fname is None else Path(fname)\\n'\n",
      " \"    if fname.is_dir(): fname = f'{fname.absolute()}/**/*{extension}' if \"\n",
      " \"recursive else f'{fname.absolute()}/*{extension}'\\n\"\n",
      " '    fls = L(glob.glob(str(fname), recursive=recursive)).filter(lambda x: '\n",
      " \"'/.' not in x).map(Path)\\n\"\n",
      " \"    return fls.filter(lambda x: not x.name.startswith('_') and \"\n",
      " 'x.name.endswith(extension))')\n",
      "code_lines: ['def notebook2script(fname=None, silent=False, to_dict=False, bare=False):',\n",
      " '    \"Convert notebooks matching `fname` to modules\"',\n",
      " '    # initial checks',\n",
      " \"    if os.environ.get('IN_TEST',0): return  # don't export if running tests\",\n",
      " '    if fname is None:',\n",
      " '        reset_nbdev_module()',\n",
      " '        update_version()',\n",
      " '        update_baseurl()',\n",
      " '    files = nbglob(fname=fname)',\n",
      " '    d = collections.defaultdict(list) if to_dict else None',\n",
      " '    modules = create_mod_files(files, to_dict, bare=bare)',\n",
      " '    for f in sorted(files): d = _notebook2script(f, modules, silent=silent, '\n",
      " 'to_dict=d, bare=bare)',\n",
      " '    if to_dict: return d',\n",
      " '    else: add_init(Config().path(\"lib_path\"))']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def notebook2script(fname=None, silent=False, to_dict=False, bare=False):\\n'\n",
      " '    \"Convert notebooks matching `fname` to modules\"\\n'\n",
      " '    # initial checks\\n'\n",
      " \"    if os.environ.get('IN_TEST',0): return  # don't export if running tests\\n\"\n",
      " '    if fname is None:\\n'\n",
      " '        reset_nbdev_module()\\n'\n",
      " '        update_version()\\n'\n",
      " '        update_baseurl()\\n'\n",
      " '    files = nbglob(fname=fname)\\n'\n",
      " '    d = collections.defaultdict(list) if to_dict else None\\n'\n",
      " '    modules = create_mod_files(files, to_dict, bare=bare)\\n'\n",
      " '    for f in sorted(files): d = _notebook2script(f, modules, silent=silent, '\n",
      " 'to_dict=d, bare=bare)\\n'\n",
      " '    if to_dict: return d\\n'\n",
      " '    else: add_init(Config().path(\"lib_path\"))')\n",
      "code_lines: ['class DocsTestClass:', '    \"for tests only\"', '    def test(): pass']\n",
      "code: '\\n\\n# Cell\\nclass DocsTestClass:\\n    \"for tests only\"\\n    def test(): pass'\n",
      "code_lines: ['#exporti', '#for tests only', 'def update_lib_with_exporti_testfn(): pass']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Internal Cell\\n'\n",
      " '#exporti\\n'\n",
      " '#for tests only\\n'\n",
      " 'def update_lib_with_exporti_testfn(): pass')\n",
      "Converted 00_export.ipynb.\n",
      "code_lines: ['from .imports import *',\n",
      " 'from .export import *',\n",
      " 'from fastcore.script import *',\n",
      " 'import nbformat',\n",
      " 'from nbformat.sign import NotebookNotary']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'from .imports import *\\n'\n",
      " 'from .export import *\\n'\n",
      " 'from fastcore.script import *\\n'\n",
      " 'import nbformat\\n'\n",
      " 'from nbformat.sign import NotebookNotary')\n",
      "code_lines: ['def _get_property_name(p):',\n",
      " '    \"Get the name of property `p`\"',\n",
      " \"    if hasattr(p, 'fget'):\",\n",
      " \"        return p.fget.func.__qualname__ if hasattr(p.fget, 'func') else \"\n",
      " 'p.fget.__qualname__',\n",
      " \"    else: return next(iter(re.findall(r'\\\\'(.*)\\\\'', \"\n",
      " \"str(p)))).split('.')[-1]\",\n",
      " '',\n",
      " 'def get_name(obj):',\n",
      " '    \"Get the name of `obj`\"',\n",
      " \"    if hasattr(obj, '__name__'):       return obj.__name__\",\n",
      " \"    elif getattr(obj, '_name', False): return obj._name\",\n",
      " \"    elif hasattr(obj,'__origin__'):    return \"\n",
      " \"str(obj.__origin__).split('.')[-1] #for types\",\n",
      " '    elif type(obj)==property:          return _get_property_name(obj)',\n",
      " \"    else:                              return str(obj).split('.')[-1]\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _get_property_name(p):\\n'\n",
      " '    \"Get the name of property `p`\"\\n'\n",
      " \"    if hasattr(p, 'fget'):\\n\"\n",
      " \"        return p.fget.func.__qualname__ if hasattr(p.fget, 'func') else \"\n",
      " 'p.fget.__qualname__\\n'\n",
      " \"    else: return next(iter(re.findall(r'\\\\'(.*)\\\\'', \"\n",
      " \"str(p)))).split('.')[-1]\\n\"\n",
      " '\\n'\n",
      " 'def get_name(obj):\\n'\n",
      " '    \"Get the name of `obj`\"\\n'\n",
      " \"    if hasattr(obj, '__name__'):       return obj.__name__\\n\"\n",
      " \"    elif getattr(obj, '_name', False): return obj._name\\n\"\n",
      " \"    elif hasattr(obj,'__origin__'):    return \"\n",
      " \"str(obj.__origin__).split('.')[-1] #for types\\n\"\n",
      " '    elif type(obj)==property:          return _get_property_name(obj)\\n'\n",
      " \"    else:                              return str(obj).split('.')[-1]\")\n",
      "code_lines: ['def qual_name(obj):',\n",
      " '    \"Get the qualified name of `obj`\"',\n",
      " \"    if hasattr(obj,'__qualname__'): return obj.__qualname__\",\n",
      " '    if inspect.ismethod(obj):       return '\n",
      " 'f\"{get_name(obj.__self__)}.{get_name(fn)}\"',\n",
      " '    return get_name(obj)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def qual_name(obj):\\n'\n",
      " '    \"Get the qualified name of `obj`\"\\n'\n",
      " \"    if hasattr(obj,'__qualname__'): return obj.__qualname__\\n\"\n",
      " '    if inspect.ismethod(obj):       return '\n",
      " 'f\"{get_name(obj.__self__)}.{get_name(fn)}\"\\n'\n",
      " '    return get_name(obj)')\n",
      "code_lines: ['def source_nb(func, is_name=None, return_all=False, mod=None):',\n",
      " '    \"Return the name of the notebook where `func` was defined\"',\n",
      " '    is_name = is_name or isinstance(func, str)',\n",
      " '    if mod is None: mod = get_nbdev_module()',\n",
      " '    index = mod.index',\n",
      " '    name = func if is_name else qual_name(func)',\n",
      " '    while len(name) > 0:',\n",
      " '        if name in index: return (name,index[name]) if return_all else '\n",
      " 'index[name]',\n",
      " \"        name = '.'.join(name.split('.')[:-1])\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def source_nb(func, is_name=None, return_all=False, mod=None):\\n'\n",
      " '    \"Return the name of the notebook where `func` was defined\"\\n'\n",
      " '    is_name = is_name or isinstance(func, str)\\n'\n",
      " '    if mod is None: mod = get_nbdev_module()\\n'\n",
      " '    index = mod.index\\n'\n",
      " '    name = func if is_name else qual_name(func)\\n'\n",
      " '    while len(name) > 0:\\n'\n",
      " '        if name in index: return (name,index[name]) if return_all else '\n",
      " 'index[name]\\n'\n",
      " \"        name = '.'.join(name.split('.')[:-1])\")\n",
      "code_lines: [\"_re_cell = re.compile(r'^# Cell|^# Internal Cell|^# Comes from\\\\s+(\\\\S+), \"\n",
      " \"cell')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_re_cell = re.compile(r'^# Cell|^# Internal Cell|^# Comes from\\\\s+(\\\\S+), \"\n",
      " \"cell')\")\n",
      "code_lines: ['def _split(code):',\n",
      " \"    lines = code.split('\\\\n')\",\n",
      " '    nbs_path = '\n",
      " 'Config().path(\"nbs_path\").relative_to(Config().config_file.parent)',\n",
      " \"    prefix = '' if nbs_path == Path('.') else f'{nbs_path}/'\",\n",
      " \"    default_nb = re.search(f'File to edit: {prefix}(\\\\\\\\S+)\\\\\\\\s+', \"\n",
      " 'lines[0]).groups()[0]',\n",
      " '    s,res = 1,[]',\n",
      " '    while _re_cell.search(lines[s]) is None: s += 1',\n",
      " '    e = s+1',\n",
      " '    while e < len(lines):',\n",
      " '        while e < len(lines) and _re_cell.search(lines[e]) is None: e += 1',\n",
      " '        grps = _re_cell.search(lines[s]).groups()',\n",
      " '        nb = grps[0] or default_nb',\n",
      " '        content = lines[s+1:e]',\n",
      " \"        while len(content) > 1 and content[-1] == '': content = content[:-1]\",\n",
      " \"        res.append((nb, '\\\\n'.join(content)))\",\n",
      " '        s,e = e,e+1',\n",
      " '    return res']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _split(code):\\n'\n",
      " \"    lines = code.split('\\\\n')\\n\"\n",
      " '    nbs_path = '\n",
      " 'Config().path(\"nbs_path\").relative_to(Config().config_file.parent)\\n'\n",
      " \"    prefix = '' if nbs_path == Path('.') else f'{nbs_path}/'\\n\"\n",
      " \"    default_nb = re.search(f'File to edit: {prefix}(\\\\\\\\S+)\\\\\\\\s+', \"\n",
      " 'lines[0]).groups()[0]\\n'\n",
      " '    s,res = 1,[]\\n'\n",
      " '    while _re_cell.search(lines[s]) is None: s += 1\\n'\n",
      " '    e = s+1\\n'\n",
      " '    while e < len(lines):\\n'\n",
      " '        while e < len(lines) and _re_cell.search(lines[e]) is None: e += 1\\n'\n",
      " '        grps = _re_cell.search(lines[s]).groups()\\n'\n",
      " '        nb = grps[0] or default_nb\\n'\n",
      " '        content = lines[s+1:e]\\n'\n",
      " \"        while len(content) > 1 and content[-1] == '': content = \"\n",
      " 'content[:-1]\\n'\n",
      " \"        res.append((nb, '\\\\n'.join(content)))\\n\"\n",
      " '        s,e = e,e+1\\n'\n",
      " '    return res')\n",
      "code_lines: ['def relimport2name(name, mod_name):',\n",
      " '    \"Unwarps a relative import in `name` according to `mod_name`\"',\n",
      " '    mod_name = str(Path(mod_name))',\n",
      " \"    if mod_name.endswith('.py'): mod_name = mod_name[:-3]\",\n",
      " '    mods = mod_name.split(os.path.sep)',\n",
      " '    i = last_index(Config().lib_name, mods)',\n",
      " '    mods = mods[i:]',\n",
      " \"    if name=='.': return '.'.join(mods[:-1])\",\n",
      " '    i = 0',\n",
      " \"    while name[i] == '.': i += 1\",\n",
      " \"    return '.'.join(mods[:-i] + [name[i:]])\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def relimport2name(name, mod_name):\\n'\n",
      " '    \"Unwarps a relative import in `name` according to `mod_name`\"\\n'\n",
      " '    mod_name = str(Path(mod_name))\\n'\n",
      " \"    if mod_name.endswith('.py'): mod_name = mod_name[:-3]\\n\"\n",
      " '    mods = mod_name.split(os.path.sep)\\n'\n",
      " '    i = last_index(Config().lib_name, mods)\\n'\n",
      " '    mods = mods[i:]\\n'\n",
      " \"    if name=='.': return '.'.join(mods[:-1])\\n\"\n",
      " '    i = 0\\n'\n",
      " \"    while name[i] == '.': i += 1\\n\"\n",
      " \"    return '.'.join(mods[:-i] + [name[i:]])\")\n",
      "code_lines: ['#Catches any from .bla import something and catches .bla in group 1, the '\n",
      " 'imported thing(s) in group 2.',\n",
      " '_re_loc_import = '\n",
      " \"re.compile(r'(\\\\s*)from(\\\\s+)(\\\\.\\\\S*)(\\\\s+)import(\\\\s+)(.*)$')\",\n",
      " \"_re_loc_import1 = re.compile(r'(\\\\s*)import(\\\\s+)(\\\\.\\\\S*)(.*)$')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '#Catches any from .bla import something and catches .bla in group 1, the '\n",
      " 'imported thing(s) in group 2.\\n'\n",
      " '_re_loc_import = '\n",
      " \"re.compile(r'(\\\\s*)from(\\\\s+)(\\\\.\\\\S*)(\\\\s+)import(\\\\s+)(.*)$')\\n\"\n",
      " \"_re_loc_import1 = re.compile(r'(\\\\s*)import(\\\\s+)(\\\\.\\\\S*)(.*)$')\")\n",
      "code_lines: ['def _deal_loc_import(code, fname):',\n",
      " '    def _replace(m):',\n",
      " '        s1,s2,mod,s3,s4,obj = m.groups()',\n",
      " '        return f\"{s1}from{s2}{relimport2name(mod, '\n",
      " 'fname)}{s3}import{s4}{obj}\"',\n",
      " '    def _replace1(m):',\n",
      " '        s1,s2,mod,end = m.groups()',\n",
      " '        return f\"{s1}import{s2}{relimport2name(mod, fname)}{end}\"',\n",
      " \"    return '\\\\n'.join([_re_loc_import1.sub(_replace1, \"\n",
      " \"_re_loc_import.sub(_replace,line)) for line in code.split('\\\\n')])\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _deal_loc_import(code, fname):\\n'\n",
      " '    def _replace(m):\\n'\n",
      " '        s1,s2,mod,s3,s4,obj = m.groups()\\n'\n",
      " '        return f\"{s1}from{s2}{relimport2name(mod, '\n",
      " 'fname)}{s3}import{s4}{obj}\"\\n'\n",
      " '    def _replace1(m):\\n'\n",
      " '        s1,s2,mod,end = m.groups()\\n'\n",
      " '        return f\"{s1}import{s2}{relimport2name(mod, fname)}{end}\"\\n'\n",
      " \"    return '\\\\n'.join([_re_loc_import1.sub(_replace1, \"\n",
      " \"_re_loc_import.sub(_replace,line)) for line in code.split('\\\\n')])\")\n",
      "code_lines: ['def _script2notebook(fname, dic, silent=False):',\n",
      " '    \"Put the content of `fname` back in the notebooks it came from.\"',\n",
      " \"    if os.environ.get('IN_TEST',0): return  # don't export if running tests\",\n",
      " '    fname = Path(fname)',\n",
      " \"    with open(fname, encoding='utf8') as f: code = f.read()\",\n",
      " '    splits = _split(code)',\n",
      " '    rel_name = '\n",
      " 'fname.absolute().resolve().relative_to(Config().path(\"lib_path\"))',\n",
      " \"    key = str(rel_name.with_suffix(''))\",\n",
      " '    assert len(splits)==len(dic[key]), f\\'\"{rel_name}\" exported from '\n",
      " \"notebooks should have {len(dic[key])} cells but has {len(splits)}.'\",\n",
      " '    assert all([c1[0]==c2[1]] for c1,c2 in zip(splits, dic[key]))',\n",
      " '    splits = [(c2[0],c1[0],c1[1]) for c1,c2 in zip(splits, dic[key])]',\n",
      " '    nb_fnames = {Config().path(\"nbs_path\")/s[1] for s in splits}',\n",
      " '    for nb_fname in nb_fnames:',\n",
      " '        nb = read_nb(nb_fname)',\n",
      " '        for i,f,c in splits:',\n",
      " '            c = _deal_loc_import(c, str(fname))',\n",
      " '            if f == nb_fname.name:',\n",
      " \"                flags = split_flags_and_code(nb['cells'][i], str)[0]\",\n",
      " \"                nb['cells'][i]['source'] = flags + '\\\\n' + c.replace('', '')\",\n",
      " '        NotebookNotary().sign(nb)',\n",
      " '        nbformat.write(nb, str(nb_fname), version=4)',\n",
      " '',\n",
      " '    if not silent: print(f\"Converted {rel_name}.\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _script2notebook(fname, dic, silent=False):\\n'\n",
      " '    \"Put the content of `fname` back in the notebooks it came from.\"\\n'\n",
      " \"    if os.environ.get('IN_TEST',0): return  # don't export if running tests\\n\"\n",
      " '    fname = Path(fname)\\n'\n",
      " \"    with open(fname, encoding='utf8') as f: code = f.read()\\n\"\n",
      " '    splits = _split(code)\\n'\n",
      " '    rel_name = '\n",
      " 'fname.absolute().resolve().relative_to(Config().path(\"lib_path\"))\\n'\n",
      " \"    key = str(rel_name.with_suffix(''))\\n\"\n",
      " '    assert len(splits)==len(dic[key]), f\\'\"{rel_name}\" exported from '\n",
      " \"notebooks should have {len(dic[key])} cells but has {len(splits)}.'\\n\"\n",
      " '    assert all([c1[0]==c2[1]] for c1,c2 in zip(splits, dic[key]))\\n'\n",
      " '    splits = [(c2[0],c1[0],c1[1]) for c1,c2 in zip(splits, dic[key])]\\n'\n",
      " '    nb_fnames = {Config().path(\"nbs_path\")/s[1] for s in splits}\\n'\n",
      " '    for nb_fname in nb_fnames:\\n'\n",
      " '        nb = read_nb(nb_fname)\\n'\n",
      " '        for i,f,c in splits:\\n'\n",
      " '            c = _deal_loc_import(c, str(fname))\\n'\n",
      " '            if f == nb_fname.name:\\n'\n",
      " \"                flags = split_flags_and_code(nb['cells'][i], str)[0]\\n\"\n",
      " \"                nb['cells'][i]['source'] = flags + '\\\\n' + c.replace('', \"\n",
      " \"'')\\n\"\n",
      " '        NotebookNotary().sign(nb)\\n'\n",
      " '        nbformat.write(nb, str(nb_fname), version=4)\\n'\n",
      " '\\n'\n",
      " '    if not silent: print(f\"Converted {rel_name}.\")')\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_update_lib(fname:Param(\"A python filename or glob to convert\", '\n",
      " 'str)=None,',\n",
      " '                     silent:Param(\"Don\\'t print results\", bool_arg)=False):',\n",
      " '    \"Propagates any change in the modules matching `fname` to the notebooks '\n",
      " 'that created them\"',\n",
      " \"    if fname and fname.endswith('.ipynb'): raise \"\n",
      " 'ValueError(\"`nbdev_update_lib` operates on .py files.  If you wish to '\n",
      " 'convert notebooks instead, see `nbdev_build_lib`.\")',\n",
      " \"    if os.environ.get('IN_TEST',0): return\",\n",
      " '    dic = notebook2script(silent=True, to_dict=True)',\n",
      " '    exported = get_nbdev_module().modules',\n",
      " '    ',\n",
      " \"    files = nbglob(fname, extension='.py', config_key='lib_path')\",\n",
      " '    files = files.filter(lambda x: '\n",
      " 'str(x.relative_to(Config().path(\"lib_path\"))) in exported)',\n",
      " '    files.map(partial(_script2notebook, dic=dic, silent=silent))']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_update_lib(fname:Param(\"A python filename or glob to convert\", '\n",
      " 'str)=None,\\n'\n",
      " '                     silent:Param(\"Don\\'t print results\", bool_arg)=False):\\n'\n",
      " '    \"Propagates any change in the modules matching `fname` to the notebooks '\n",
      " 'that created them\"\\n'\n",
      " \"    if fname and fname.endswith('.ipynb'): raise \"\n",
      " 'ValueError(\"`nbdev_update_lib` operates on .py files.  If you wish to '\n",
      " 'convert notebooks instead, see `nbdev_build_lib`.\")\\n'\n",
      " \"    if os.environ.get('IN_TEST',0): return\\n\"\n",
      " '    dic = notebook2script(silent=True, to_dict=True)\\n'\n",
      " '    exported = get_nbdev_module().modules\\n'\n",
      " '    \\n'\n",
      " \"    files = nbglob(fname, extension='.py', config_key='lib_path')\\n\"\n",
      " '    files = files.filter(lambda x: '\n",
      " 'str(x.relative_to(Config().path(\"lib_path\"))) in exported)\\n'\n",
      " '    files.map(partial(_script2notebook, dic=dic, silent=silent))')\n",
      "code_lines: ['import subprocess', 'from distutils.dir_util import copy_tree']\n",
      "code: '\\n\\n# Cell\\nimport subprocess\\nfrom distutils.dir_util import copy_tree'\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_diff_nbs():',\n",
      " '    \"Prints the diff between an export of the library in notebooks and the '\n",
      " 'actual modules\"',\n",
      " '    cfg = Config()',\n",
      " '    lib_folder = cfg.path(\"lib_path\")',\n",
      " '    with tempfile.TemporaryDirectory() as d1, tempfile.TemporaryDirectory() '\n",
      " 'as d2:',\n",
      " '        copy_tree(cfg.path(\"lib_path\"), d1)',\n",
      " '        notebook2script(silent=True)',\n",
      " '        copy_tree(cfg.path(\"lib_path\"), d2)',\n",
      " '        shutil.rmtree(cfg.path(\"lib_path\"))',\n",
      " '        shutil.copytree(d1, str(cfg.path(\"lib_path\")))',\n",
      " '        for d in [d1, d2]:',\n",
      " \"            if (Path(d)/'__pycache__').exists(): \"\n",
      " \"shutil.rmtree(Path(d)/'__pycache__')\",\n",
      " \"        res = subprocess.run(['diff', '-ru', d1, d2], \"\n",
      " 'stdout=subprocess.PIPE)',\n",
      " \"        print(res.stdout.decode('utf-8'))\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_diff_nbs():\\n'\n",
      " '    \"Prints the diff between an export of the library in notebooks and the '\n",
      " 'actual modules\"\\n'\n",
      " '    cfg = Config()\\n'\n",
      " '    lib_folder = cfg.path(\"lib_path\")\\n'\n",
      " '    with tempfile.TemporaryDirectory() as d1, tempfile.TemporaryDirectory() '\n",
      " 'as d2:\\n'\n",
      " '        copy_tree(cfg.path(\"lib_path\"), d1)\\n'\n",
      " '        notebook2script(silent=True)\\n'\n",
      " '        copy_tree(cfg.path(\"lib_path\"), d2)\\n'\n",
      " '        shutil.rmtree(cfg.path(\"lib_path\"))\\n'\n",
      " '        shutil.copytree(d1, str(cfg.path(\"lib_path\")))\\n'\n",
      " '        for d in [d1, d2]:\\n'\n",
      " \"            if (Path(d)/'__pycache__').exists(): \"\n",
      " \"shutil.rmtree(Path(d)/'__pycache__')\\n\"\n",
      " \"        res = subprocess.run(['diff', '-ru', d1, d2], \"\n",
      " 'stdout=subprocess.PIPE)\\n'\n",
      " \"        print(res.stdout.decode('utf-8'))\")\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_trust_nbs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,',\n",
      " '                    force_all:Param(\"Trust even notebooks that haven\\'t '\n",
      " 'changed\", bool)=False):',\n",
      " '    \"Trust notebooks matching `fname`\"',\n",
      " '    check_fname = Config().path(\"nbs_path\")/\".last_checked\"',\n",
      " '    last_checked = os.path.getmtime(check_fname) if check_fname.exists() '\n",
      " 'else None',\n",
      " '    files = nbglob(fname)',\n",
      " '    for fn in files:',\n",
      " '        if last_checked and not force_all:',\n",
      " '            last_changed = os.path.getmtime(fn)',\n",
      " '            if last_changed < last_checked: continue',\n",
      " '        nb = read_nb(fn)',\n",
      " '        if not NotebookNotary().check_signature(nb): '\n",
      " 'NotebookNotary().sign(nb)',\n",
      " '    check_fname.touch(exist_ok=True)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_trust_nbs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,\\n'\n",
      " '                    force_all:Param(\"Trust even notebooks that haven\\'t '\n",
      " 'changed\", bool)=False):\\n'\n",
      " '    \"Trust notebooks matching `fname`\"\\n'\n",
      " '    check_fname = Config().path(\"nbs_path\")/\".last_checked\"\\n'\n",
      " '    last_checked = os.path.getmtime(check_fname) if check_fname.exists() '\n",
      " 'else None\\n'\n",
      " '    files = nbglob(fname)\\n'\n",
      " '    for fn in files:\\n'\n",
      " '        if last_checked and not force_all:\\n'\n",
      " '            last_changed = os.path.getmtime(fn)\\n'\n",
      " '            if last_changed < last_checked: continue\\n'\n",
      " '        nb = read_nb(fn)\\n'\n",
      " '        if not NotebookNotary().check_signature(nb): '\n",
      " 'NotebookNotary().sign(nb)\\n'\n",
      " '    check_fname.touch(exist_ok=True)')\n",
      "Converted 01_sync.ipynb.\n",
      "code_lines: ['from .imports import *',\n",
      " 'from .export import *',\n",
      " 'from .sync import *',\n",
      " 'from nbconvert import HTMLExporter',\n",
      " 'from fastcore.utils import IN_NOTEBOOK',\n",
      " '',\n",
      " 'if IN_NOTEBOOK:',\n",
      " '    from IPython.display import Markdown,display',\n",
      " '    from IPython.core import page']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'from .imports import *\\n'\n",
      " 'from .export import *\\n'\n",
      " 'from .sync import *\\n'\n",
      " 'from nbconvert import HTMLExporter\\n'\n",
      " 'from fastcore.utils import IN_NOTEBOOK\\n'\n",
      " '\\n'\n",
      " 'if IN_NOTEBOOK:\\n'\n",
      " '    from IPython.display import Markdown,display\\n'\n",
      " '    from IPython.core import page')\n",
      "code_lines: ['def is_enum(cls):',\n",
      " '    \"Check if `cls` is an enum or another type of class\"',\n",
      " '    return type(cls) in (enum.Enum, enum.EnumMeta)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def is_enum(cls):\\n'\n",
      " '    \"Check if `cls` is an enum or another type of class\"\\n'\n",
      " '    return type(cls) in (enum.Enum, enum.EnumMeta)')\n",
      "code_lines: ['def is_lib_module(name):',\n",
      " '    \"Test if `name` is a library module.\"',\n",
      " \"    if name.startswith('_'): return False\",\n",
      " '    try:',\n",
      " \"        _ = importlib.import_module(f'{Config().lib_name}.{name}')\",\n",
      " '        return True',\n",
      " '    except: return False']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def is_lib_module(name):\\n'\n",
      " '    \"Test if `name` is a library module.\"\\n'\n",
      " \"    if name.startswith('_'): return False\\n\"\n",
      " '    try:\\n'\n",
      " \"        _ = importlib.import_module(f'{Config().lib_name}.{name}')\\n\"\n",
      " '        return True\\n'\n",
      " '    except: return False')\n",
      "code_lines: [\"re_digits_first = re.compile('^[0-9]+[a-z]*_')\"]\n",
      "code: \"\\n\\n# Cell\\nre_digits_first = re.compile('^[0-9]+[a-z]*_')\"\n",
      "code_lines: ['def try_external_doc_link(name, packages):',\n",
      " '    \"Try to find a doc link for `name` in `packages`\"',\n",
      " '    for p in packages:',\n",
      " '        try:',\n",
      " '            mod = importlib.import_module(f\"{p}._nbdev\")',\n",
      " '            try_pack = source_nb(name, is_name=True, mod=mod)',\n",
      " '            if try_pack:',\n",
      " \"                page = re_digits_first.sub('', try_pack).replace('.ipynb', \"\n",
      " \"'')\",\n",
      " \"                return f'{mod.doc_url}{page}#{name}'\",\n",
      " '        except ModuleNotFoundError: return None']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def try_external_doc_link(name, packages):\\n'\n",
      " '    \"Try to find a doc link for `name` in `packages`\"\\n'\n",
      " '    for p in packages:\\n'\n",
      " '        try:\\n'\n",
      " '            mod = importlib.import_module(f\"{p}._nbdev\")\\n'\n",
      " '            try_pack = source_nb(name, is_name=True, mod=mod)\\n'\n",
      " '            if try_pack:\\n'\n",
      " \"                page = re_digits_first.sub('', try_pack).replace('.ipynb', \"\n",
      " \"'')\\n\"\n",
      " \"                return f'{mod.doc_url}{page}#{name}'\\n\"\n",
      " '        except ModuleNotFoundError: return None')\n",
      "code_lines: ['def is_doc_name(name):',\n",
      " '    \"Test if `name` corresponds to a notebook that could be converted to a '\n",
      " 'doc page\"',\n",
      " '    for f in Config().path(\"nbs_path\").glob(f\\'*{name}.ipynb\\'):',\n",
      " \"        if re_digits_first.sub('', f.name) == f'{name}.ipynb': return True\",\n",
      " '    return False']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def is_doc_name(name):\\n'\n",
      " '    \"Test if `name` corresponds to a notebook that could be converted to a '\n",
      " 'doc page\"\\n'\n",
      " '    for f in Config().path(\"nbs_path\").glob(f\\'*{name}.ipynb\\'):\\n'\n",
      " \"        if re_digits_first.sub('', f.name) == f'{name}.ipynb': return True\\n\"\n",
      " '    return False')\n",
      "code_lines: ['def doc_link(name, include_bt=True):',\n",
      " '    \"Create link to documentation for `name`.\"',\n",
      " \"    cname = f'`{name}`' if include_bt else name\",\n",
      " '    try:',\n",
      " '        #Link to modules',\n",
      " '        if is_lib_module(name) and is_doc_name(name): return '\n",
      " 'f\"[{cname}]({Config().doc_baseurl}{name}.html)\"',\n",
      " '        #Link to local functions',\n",
      " '        try_local = source_nb(name, is_name=True)',\n",
      " '        if try_local:',\n",
      " \"            page = re_digits_first.sub('', try_local).replace('.ipynb', '')\",\n",
      " \"            return f'[{cname}]({Config().doc_baseurl}{page}.html#{name})'\",\n",
      " '        ##Custom links',\n",
      " '        mod = get_nbdev_module()',\n",
      " '        link = mod.custom_doc_links(name)',\n",
      " \"        return f'[{cname}]({link})' if link is not None else cname\",\n",
      " '    except: return cname']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def doc_link(name, include_bt=True):\\n'\n",
      " '    \"Create link to documentation for `name`.\"\\n'\n",
      " \"    cname = f'`{name}`' if include_bt else name\\n\"\n",
      " '    try:\\n'\n",
      " '        #Link to modules\\n'\n",
      " '        if is_lib_module(name) and is_doc_name(name): return '\n",
      " 'f\"[{cname}]({Config().doc_baseurl}{name}.html)\"\\n'\n",
      " '        #Link to local functions\\n'\n",
      " '        try_local = source_nb(name, is_name=True)\\n'\n",
      " '        if try_local:\\n'\n",
      " \"            page = re_digits_first.sub('', try_local).replace('.ipynb', '')\\n\"\n",
      " \"            return f'[{cname}]({Config().doc_baseurl}{page}.html#{name})'\\n\"\n",
      " '        ##Custom links\\n'\n",
      " '        mod = get_nbdev_module()\\n'\n",
      " '        link = mod.custom_doc_links(name)\\n'\n",
      " \"        return f'[{cname}]({link})' if link is not None else cname\\n\"\n",
      " '    except: return cname')\n",
      "code_lines: ['_re_backticks = re.compile(r\"\"\"',\n",
      " '# Catches any link of the form \\\\[`obj`\\\\](old_link) or just `obj`,',\n",
      " '#   to either update old links or add the link to the docs of obj',\n",
      " '\\\\[`      #     Opening [ and `',\n",
      " '([^`]*)  #     Catching group with anything but a `',\n",
      " '`\\\\]      #     ` then closing ]',\n",
      " '(?:      #     Beginning of non-catching group',\n",
      " '\\\\(       #       Opening (',\n",
      " '[^)]*    #       Anything but a closing )',\n",
      " '\\\\)       #       Closing )',\n",
      " ')        #     End of non-catching group',\n",
      " '|        # OR',\n",
      " '`        #     Opening `',\n",
      " '([^`]*)  #       Anything but a `',\n",
      " '`        #     Closing `',\n",
      " '\"\"\", re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_backticks = re.compile(r\"\"\"\\n'\n",
      " '# Catches any link of the form \\\\[`obj`\\\\](old_link) or just `obj`,\\n'\n",
      " '#   to either update old links or add the link to the docs of obj\\n'\n",
      " '\\\\[`      #     Opening [ and `\\n'\n",
      " '([^`]*)  #     Catching group with anything but a `\\n'\n",
      " '`\\\\]      #     ` then closing ]\\n'\n",
      " '(?:      #     Beginning of non-catching group\\n'\n",
      " '\\\\(       #       Opening (\\n'\n",
      " '[^)]*    #       Anything but a closing )\\n'\n",
      " '\\\\)       #       Closing )\\n'\n",
      " ')        #     End of non-catching group\\n'\n",
      " '|        # OR\\n'\n",
      " '`        #     Opening `\\n'\n",
      " '([^`]*)  #       Anything but a `\\n'\n",
      " '`        #     Closing `\\n'\n",
      " '\"\"\", re.VERBOSE)')\n",
      "code_lines: ['def add_doc_links(text, elt=None):',\n",
      " '    \"Search for doc links for any item between backticks in `text` and '\n",
      " 'insert them\"',\n",
      " '    def _replace_link(m): ',\n",
      " '        try: ',\n",
      " '            if m.group(2) in inspect.signature(elt).parameters: return '\n",
      " \"f'`{m.group(2)}`'\",\n",
      " '        except: pass',\n",
      " '        return doc_link(m.group(1) or m.group(2))',\n",
      " '    return _re_backticks.sub(_replace_link, text)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def add_doc_links(text, elt=None):\\n'\n",
      " '    \"Search for doc links for any item between backticks in `text` and '\n",
      " 'insert them\"\\n'\n",
      " '    def _replace_link(m): \\n'\n",
      " '        try: \\n'\n",
      " '            if m.group(2) in inspect.signature(elt).parameters: return '\n",
      " \"f'`{m.group(2)}`'\\n\"\n",
      " '        except: pass\\n'\n",
      " '        return doc_link(m.group(1) or m.group(2))\\n'\n",
      " '    return _re_backticks.sub(_replace_link, text)')\n",
      "code_lines: ['def _is_type_dispatch(x): return type(x).__name__ == \"TypeDispatch\"',\n",
      " 'def _unwrapped_type_dispatch_func(x): return x.first() if '\n",
      " '_is_type_dispatch(x) else x',\n",
      " '',\n",
      " 'def _is_property(x): return type(x)==property',\n",
      " \"def _has_property_getter(x): return _is_property(x) and hasattr(x, 'fget') \"\n",
      " \"and hasattr(x.fget, 'func')\",\n",
      " 'def _property_getter(x): return x.fget.func if _has_property_getter(x) else '\n",
      " 'x',\n",
      " '',\n",
      " 'def _unwrapped_func(x):',\n",
      " '    x = _unwrapped_type_dispatch_func(x)',\n",
      " '    x = _property_getter(x)',\n",
      " '    return x']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _is_type_dispatch(x): return type(x).__name__ == \"TypeDispatch\"\\n'\n",
      " 'def _unwrapped_type_dispatch_func(x): return x.first() if '\n",
      " '_is_type_dispatch(x) else x\\n'\n",
      " '\\n'\n",
      " 'def _is_property(x): return type(x)==property\\n'\n",
      " \"def _has_property_getter(x): return _is_property(x) and hasattr(x, 'fget') \"\n",
      " \"and hasattr(x.fget, 'func')\\n\"\n",
      " 'def _property_getter(x): return x.fget.func if _has_property_getter(x) else '\n",
      " 'x\\n'\n",
      " '\\n'\n",
      " 'def _unwrapped_func(x):\\n'\n",
      " '    x = _unwrapped_type_dispatch_func(x)\\n'\n",
      " '    x = _property_getter(x)\\n'\n",
      " '    return x')\n",
      "code_lines: ['def get_source_link(func):',\n",
      " '    \"Return link to `func` in source code\"',\n",
      " '    func = _unwrapped_func(func)',\n",
      " '    try: line = inspect.getsourcelines(func)[1]',\n",
      " \"    except Exception: return ''\",\n",
      " '    mod = inspect.getmodule(func)',\n",
      " \"    module = mod.__name__.replace('.', '/') + '.py'\",\n",
      " '    try:',\n",
      " \"        nbdev_mod = importlib.import_module(mod.__package__.split('.')[0] + \"\n",
      " \"'._nbdev')\",\n",
      " '        return f\"{nbdev_mod.git_url}{module}#L{line}\"',\n",
      " '    except: return f\"{module}#L{line}\"']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def get_source_link(func):\\n'\n",
      " '    \"Return link to `func` in source code\"\\n'\n",
      " '    func = _unwrapped_func(func)\\n'\n",
      " '    try: line = inspect.getsourcelines(func)[1]\\n'\n",
      " \"    except Exception: return ''\\n\"\n",
      " '    mod = inspect.getmodule(func)\\n'\n",
      " \"    module = mod.__name__.replace('.', '/') + '.py'\\n\"\n",
      " '    try:\\n'\n",
      " \"        nbdev_mod = importlib.import_module(mod.__package__.split('.')[0] + \"\n",
      " \"'._nbdev')\\n\"\n",
      " '        return f\"{nbdev_mod.git_url}{module}#L{line}\"\\n'\n",
      " '    except: return f\"{module}#L{line}\"')\n",
      "code_lines: ['_re_header = re.compile(r\"\"\"',\n",
      " '# Catches any header in markdown with the title in group 1',\n",
      " '^\\\\s*  # Beginning of text followed by any number of whitespace',\n",
      " '\\\\#+   # One # or more',\n",
      " '\\\\s*   # Any number of whitespace',\n",
      " '(.*)  # Catching group with anything',\n",
      " '$     # End of text',\n",
      " '\"\"\", re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_header = re.compile(r\"\"\"\\n'\n",
      " '# Catches any header in markdown with the title in group 1\\n'\n",
      " '^\\\\s*  # Beginning of text followed by any number of whitespace\\n'\n",
      " '\\\\#+   # One # or more\\n'\n",
      " '\\\\s*   # Any number of whitespace\\n'\n",
      " '(.*)  # Catching group with anything\\n'\n",
      " '$     # End of text\\n'\n",
      " '\"\"\", re.VERBOSE)')\n",
      "code_lines: ['def colab_link(path):',\n",
      " '    \"Get a link to the notebook at `path` on Colab\"',\n",
      " '    cfg = Config()',\n",
      " '    res = '\n",
      " 'f\\'https://colab.research.google.com/github/{cfg.user}/{cfg.lib_name}/blob/{cfg.branch}/{cfg.path(\"nbs_path\").name}/{path}.ipynb\\'',\n",
      " \"    display(Markdown(f'[Open `{path}` in Colab]({res})'))\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def colab_link(path):\\n'\n",
      " '    \"Get a link to the notebook at `path` on Colab\"\\n'\n",
      " '    cfg = Config()\\n'\n",
      " '    res = '\n",
      " 'f\\'https://colab.research.google.com/github/{cfg.user}/{cfg.lib_name}/blob/{cfg.branch}/{cfg.path(\"nbs_path\").name}/{path}.ipynb\\'\\n'\n",
      " \"    display(Markdown(f'[Open `{path}` in Colab]({res})'))\")\n",
      "code_lines: ['def get_nb_source_link(func, local=False, is_name=None):',\n",
      " '    \"Return a link to the notebook where `func` is defined.\"',\n",
      " '    func = _unwrapped_type_dispatch_func(func)',\n",
      " \"    pref = '' if local else Config().git_url.replace('github.com', \"\n",
      " '\\'nbviewer.jupyter.org/github\\')+ Config().path(\"nbs_path\").name+\\'/\\'',\n",
      " '    is_name = is_name or isinstance(func, str)',\n",
      " '    src = source_nb(func, is_name=is_name, return_all=True)',\n",
      " \"    if src is None: return '' if is_name else get_source_link(func)\",\n",
      " '    find_name,nb_name = src',\n",
      " '    nb = read_nb(nb_name)',\n",
      " '    pat = '\n",
      " \"re.compile(f'^{find_name}\\\\s+=|^(def|class)\\\\s+{find_name}\\\\s*\\\\(', \"\n",
      " 're.MULTILINE)',\n",
      " \"    if len(find_name.split('.')) == 2:\",\n",
      " \"        clas,func = find_name.split('.')\",\n",
      " '        pat2 = '\n",
      " \"re.compile(f'@patch\\\\s*\\\\ndef\\\\s+{func}\\\\s*\\\\([^:]*:\\\\s*{clas}\\\\s*(?:,|\\\\))')\",\n",
      " '    else: pat2 = None',\n",
      " \"    for i,cell in enumerate(nb['cells']):\",\n",
      " \"        if cell['cell_type'] == 'code':\",\n",
      " \"            if re.search(pat, cell['source']):  break\",\n",
      " \"            if pat2 is not None and re.search(pat2, cell['source']): break\",\n",
      " \"    if re.search(pat, cell['source']) is None and (pat2 is not None and \"\n",
      " \"re.search(pat2, cell['source']) is None):\",\n",
      " \"        return '' if is_name else get_function_source(func)\",\n",
      " \"    header_pat = re.compile(r'^\\\\s*#+\\\\s*(.*)$')\",\n",
      " '    while i >= 0:',\n",
      " \"        cell = nb['cells'][i]\",\n",
      " \"        if cell['cell_type'] == 'markdown' and \"\n",
      " \"_re_header.search(cell['source']):\",\n",
      " \"            title = _re_header.search(cell['source']).groups()[0]\",\n",
      " \"            anchor = '-'.join([s for s in title.split(' ') if len(s) > 0])\",\n",
      " \"            return f'{pref}{nb_name}#{anchor}'\",\n",
      " '        i-=1',\n",
      " \"    return f'{pref}{nb_name}'\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def get_nb_source_link(func, local=False, is_name=None):\\n'\n",
      " '    \"Return a link to the notebook where `func` is defined.\"\\n'\n",
      " '    func = _unwrapped_type_dispatch_func(func)\\n'\n",
      " \"    pref = '' if local else Config().git_url.replace('github.com', \"\n",
      " '\\'nbviewer.jupyter.org/github\\')+ Config().path(\"nbs_path\").name+\\'/\\'\\n'\n",
      " '    is_name = is_name or isinstance(func, str)\\n'\n",
      " '    src = source_nb(func, is_name=is_name, return_all=True)\\n'\n",
      " \"    if src is None: return '' if is_name else get_source_link(func)\\n\"\n",
      " '    find_name,nb_name = src\\n'\n",
      " '    nb = read_nb(nb_name)\\n'\n",
      " '    pat = '\n",
      " \"re.compile(f'^{find_name}\\\\s+=|^(def|class)\\\\s+{find_name}\\\\s*\\\\(', \"\n",
      " 're.MULTILINE)\\n'\n",
      " \"    if len(find_name.split('.')) == 2:\\n\"\n",
      " \"        clas,func = find_name.split('.')\\n\"\n",
      " '        pat2 = '\n",
      " \"re.compile(f'@patch\\\\s*\\\\ndef\\\\s+{func}\\\\s*\\\\([^:]*:\\\\s*{clas}\\\\s*(?:,|\\\\))')\\n\"\n",
      " '    else: pat2 = None\\n'\n",
      " \"    for i,cell in enumerate(nb['cells']):\\n\"\n",
      " \"        if cell['cell_type'] == 'code':\\n\"\n",
      " \"            if re.search(pat, cell['source']):  break\\n\"\n",
      " \"            if pat2 is not None and re.search(pat2, cell['source']): break\\n\"\n",
      " \"    if re.search(pat, cell['source']) is None and (pat2 is not None and \"\n",
      " \"re.search(pat2, cell['source']) is None):\\n\"\n",
      " \"        return '' if is_name else get_function_source(func)\\n\"\n",
      " \"    header_pat = re.compile(r'^\\\\s*#+\\\\s*(.*)$')\\n\"\n",
      " '    while i >= 0:\\n'\n",
      " \"        cell = nb['cells'][i]\\n\"\n",
      " \"        if cell['cell_type'] == 'markdown' and \"\n",
      " \"_re_header.search(cell['source']):\\n\"\n",
      " \"            title = _re_header.search(cell['source']).groups()[0]\\n\"\n",
      " \"            anchor = '-'.join([s for s in title.split(' ') if len(s) > 0])\\n\"\n",
      " \"            return f'{pref}{nb_name}#{anchor}'\\n\"\n",
      " '        i-=1\\n'\n",
      " \"    return f'{pref}{nb_name}'\")\n",
      "code_lines: ['def nb_source_link(func, is_name=None, disp=True, local=True):',\n",
      " '    \"Show a relative link to the notebook where `func` is defined\"',\n",
      " '    is_name = is_name or isinstance(func, str)',\n",
      " '    func_name = func if is_name else qual_name(func)',\n",
      " '    link = get_nb_source_link(func, local=local, is_name=is_name)',\n",
      " \"    text = func_name if local else f'{func_name} (GitHub)'\",\n",
      " \"    if disp: display(Markdown(f'[{text}]({link})'))\",\n",
      " '    else: return link']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def nb_source_link(func, is_name=None, disp=True, local=True):\\n'\n",
      " '    \"Show a relative link to the notebook where `func` is defined\"\\n'\n",
      " '    is_name = is_name or isinstance(func, str)\\n'\n",
      " '    func_name = func if is_name else qual_name(func)\\n'\n",
      " '    link = get_nb_source_link(func, local=local, is_name=is_name)\\n'\n",
      " \"    text = func_name if local else f'{func_name} (GitHub)'\\n\"\n",
      " \"    if disp: display(Markdown(f'[{text}]({link})'))\\n\"\n",
      " '    else: return link')\n",
      "code_lines: ['from fastcore.script import Param']\n",
      "code: '\\n\\n# Cell\\nfrom fastcore.script import Param'\n",
      "code_lines: ['def type_repr(t):',\n",
      " '    \"Representation of type `t` (in a type annotation)\"',\n",
      " '    if (isinstance(t, Param)): return f\\'\"{t.help}\"\\'',\n",
      " \"    if getattr(t, '__args__', None):\",\n",
      " '        args = t.__args__',\n",
      " '        if len(args)==2 and args[1] == type(None):',\n",
      " \"            return f'`Optional`\\\\[{type_repr(args[0])}\\\\]'\",\n",
      " \"        reprs = ', '.join([type_repr(o) for o in args])\",\n",
      " \"        return f'{doc_link(get_name(t))}\\\\[{reprs}\\\\]'\",\n",
      " '    else: return doc_link(get_name(t))']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def type_repr(t):\\n'\n",
      " '    \"Representation of type `t` (in a type annotation)\"\\n'\n",
      " '    if (isinstance(t, Param)): return f\\'\"{t.help}\"\\'\\n'\n",
      " \"    if getattr(t, '__args__', None):\\n\"\n",
      " '        args = t.__args__\\n'\n",
      " '        if len(args)==2 and args[1] == type(None):\\n'\n",
      " \"            return f'`Optional`\\\\[{type_repr(args[0])}\\\\]'\\n\"\n",
      " \"        reprs = ', '.join([type_repr(o) for o in args])\\n\"\n",
      " \"        return f'{doc_link(get_name(t))}\\\\[{reprs}\\\\]'\\n\"\n",
      " '    else: return doc_link(get_name(t))')\n",
      "code_lines: [\"_arg_prefixes = {inspect._VAR_POSITIONAL: '\\\\*', \"\n",
      " \"inspect._VAR_KEYWORD:'\\\\*\\\\*'}\",\n",
      " '',\n",
      " 'def format_param(p):',\n",
      " '    \"Formats function param to `param:Type=val` with font weights: '\n",
      " 'param=bold, val=italic\"',\n",
      " \"    arg_prefix = _arg_prefixes.get(p.kind, '') # asterisk prefix for *args \"\n",
      " 'and **kwargs',\n",
      " '    res = f\"**{arg_prefix}`{p.name}`**\"',\n",
      " \"    if hasattr(p, 'annotation') and p.annotation != p.empty: res += \"\n",
      " \"f':{type_repr(p.annotation)}'\",\n",
      " '    if p.default != p.empty:',\n",
      " \"        default = getattr(p.default, 'func', p.default) #For partials\",\n",
      " \"        if hasattr(default,'__name__'): default = getattr(default, \"\n",
      " \"'__name__')\",\n",
      " '        else: default = repr(default)',\n",
      " '        if is_enum(default.__class__):                  #Enum have a crappy '\n",
      " 'repr',\n",
      " \"            res += f'=*`{default.__class__.__name__}.{default.name}`*'\",\n",
      " \"        else: res += f'=*`{default}`*'\",\n",
      " '    return res']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_arg_prefixes = {inspect._VAR_POSITIONAL: '\\\\*', \"\n",
      " \"inspect._VAR_KEYWORD:'\\\\*\\\\*'}\\n\"\n",
      " '\\n'\n",
      " 'def format_param(p):\\n'\n",
      " '    \"Formats function param to `param:Type=val` with font weights: '\n",
      " 'param=bold, val=italic\"\\n'\n",
      " \"    arg_prefix = _arg_prefixes.get(p.kind, '') # asterisk prefix for *args \"\n",
      " 'and **kwargs\\n'\n",
      " '    res = f\"**{arg_prefix}`{p.name}`**\"\\n'\n",
      " \"    if hasattr(p, 'annotation') and p.annotation != p.empty: res += \"\n",
      " \"f':{type_repr(p.annotation)}'\\n\"\n",
      " '    if p.default != p.empty:\\n'\n",
      " \"        default = getattr(p.default, 'func', p.default) #For partials\\n\"\n",
      " \"        if hasattr(default,'__name__'): default = getattr(default, \"\n",
      " \"'__name__')\\n\"\n",
      " '        else: default = repr(default)\\n'\n",
      " '        if is_enum(default.__class__):                  #Enum have a crappy '\n",
      " 'repr\\n'\n",
      " \"            res += f'=*`{default.__class__.__name__}.{default.name}`*'\\n\"\n",
      " \"        else: res += f'=*`{default}`*'\\n\"\n",
      " '    return res')\n",
      "code_lines: ['def _format_enum_doc(enum, full_name):',\n",
      " '    \"Formatted `enum` definition to show in documentation\"',\n",
      " \"    vals = ', '.join(enum.__members__.keys())\",\n",
      " \"    return f'<code>{full_name}</code>',f'<code>Enum</code> = [{vals}]'\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _format_enum_doc(enum, full_name):\\n'\n",
      " '    \"Formatted `enum` definition to show in documentation\"\\n'\n",
      " \"    vals = ', '.join(enum.__members__.keys())\\n\"\n",
      " \"    return f'<code>{full_name}</code>',f'<code>Enum</code> = [{vals}]'\")\n",
      "code_lines: ['def _escape_chars(s):',\n",
      " \"    return s.replace('_', '\\\\_')\",\n",
      " '',\n",
      " 'def _format_func_doc(func, full_name=None):',\n",
      " '    \"Formatted `func` definition to show in documentation\"',\n",
      " '    try:',\n",
      " '        sig = inspect.signature(func)',\n",
      " '        fmt_params = [format_param(param) for name,param',\n",
      " \"                  in sig.parameters.items() if name not in ('self','cls')]\",\n",
      " '    except: fmt_params = []',\n",
      " \"    name = f'<code>{full_name or func.__name__}</code>'\",\n",
      " '    arg_str = f\"({\\', \\'.join(fmt_params)})\"',\n",
      " '    f_name = f\"<code>class</code> {name}\" if inspect.isclass(func) else name',\n",
      " \"    return f'{f_name}',f'{name}{arg_str}'\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _escape_chars(s):\\n'\n",
      " \"    return s.replace('_', '\\\\_')\\n\"\n",
      " '\\n'\n",
      " 'def _format_func_doc(func, full_name=None):\\n'\n",
      " '    \"Formatted `func` definition to show in documentation\"\\n'\n",
      " '    try:\\n'\n",
      " '        sig = inspect.signature(func)\\n'\n",
      " '        fmt_params = [format_param(param) for name,param\\n'\n",
      " \"                  in sig.parameters.items() if name not in ('self','cls')]\\n\"\n",
      " '    except: fmt_params = []\\n'\n",
      " \"    name = f'<code>{full_name or func.__name__}</code>'\\n\"\n",
      " '    arg_str = f\"({\\', \\'.join(fmt_params)})\"\\n'\n",
      " '    f_name = f\"<code>class</code> {name}\" if inspect.isclass(func) else '\n",
      " 'name\\n'\n",
      " \"    return f'{f_name}',f'{name}{arg_str}'\")\n",
      "code_lines: ['def _format_cls_doc(cls, full_name):',\n",
      " '    \"Formatted `cls` definition to show in documentation\"',\n",
      " '    parent_class = inspect.getclasstree([cls])[-1][0][1][0]',\n",
      " '    name,args = _format_func_doc(cls, full_name)',\n",
      " \"    if parent_class != object: args += f' :: \"\n",
      " \"{doc_link(get_name(parent_class))}'\",\n",
      " '    return name,args']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _format_cls_doc(cls, full_name):\\n'\n",
      " '    \"Formatted `cls` definition to show in documentation\"\\n'\n",
      " '    parent_class = inspect.getclasstree([cls])[-1][0][1][0]\\n'\n",
      " '    name,args = _format_func_doc(cls, full_name)\\n'\n",
      " \"    if parent_class != object: args += f' :: \"\n",
      " \"{doc_link(get_name(parent_class))}'\\n\"\n",
      " '    return name,args')\n",
      "code_lines: ['def show_doc(elt, doc_string=True, name=None, title_level=None, disp=True, '\n",
      " 'default_cls_level=2):',\n",
      " '    \"Show documentation for element `elt`. Supported types: class, function, '\n",
      " 'and enum.\"',\n",
      " \"    elt = getattr(elt, '__func__', elt)\",\n",
      " '    qname = name or qual_name(elt)',\n",
      " '    if inspect.isclass(elt):',\n",
      " '        if is_enum(elt): name,args = _format_enum_doc(elt, qname)',\n",
      " '        else:            name,args = _format_cls_doc (elt, qname)',\n",
      " '    elif callable(elt):  name,args = _format_func_doc(elt, qname)',\n",
      " '    else:                name,args = f\"<code>{qname}</code>\", \\'\\'',\n",
      " '    link = get_source_link(elt)',\n",
      " '    source_link = f\\'<a href=\"{link}\" class=\"source_link\" '\n",
      " 'style=\"float:right\">[source]</a>\\'',\n",
      " '    title_level = title_level or (default_cls_level if inspect.isclass(elt) '\n",
      " 'else 4)',\n",
      " '    doc =  f\\'<h{title_level} id=\"{qname}\" '\n",
      " 'class=\"doc_header\">{name}{source_link}</h{title_level}>\\'',\n",
      " \"    doc += f'\\\\n\\\\n> {args}\\\\n\\\\n' if len(args) > 0 else '\\\\n\\\\n'\",\n",
      " '    if doc_string and inspect.getdoc(elt):',\n",
      " '        s = inspect.getdoc(elt)',\n",
      " '        # show_doc is used by doc so should not rely on Config',\n",
      " \"        try: monospace = (Config().get('monospace_docstrings') == 'True')\",\n",
      " '        except: monospace = False',\n",
      " \"        # doc links don't work inside markdown pre/code blocks\",\n",
      " \"        s = f'```\\\\n{s}\\\\n```' if monospace else add_doc_links(s, elt)\",\n",
      " '        doc += s',\n",
      " '    if disp: display(Markdown(doc))',\n",
      " '    else: return doc']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def show_doc(elt, doc_string=True, name=None, title_level=None, disp=True, '\n",
      " 'default_cls_level=2):\\n'\n",
      " '    \"Show documentation for element `elt`. Supported types: class, function, '\n",
      " 'and enum.\"\\n'\n",
      " \"    elt = getattr(elt, '__func__', elt)\\n\"\n",
      " '    qname = name or qual_name(elt)\\n'\n",
      " '    if inspect.isclass(elt):\\n'\n",
      " '        if is_enum(elt): name,args = _format_enum_doc(elt, qname)\\n'\n",
      " '        else:            name,args = _format_cls_doc (elt, qname)\\n'\n",
      " '    elif callable(elt):  name,args = _format_func_doc(elt, qname)\\n'\n",
      " '    else:                name,args = f\"<code>{qname}</code>\", \\'\\'\\n'\n",
      " '    link = get_source_link(elt)\\n'\n",
      " '    source_link = f\\'<a href=\"{link}\" class=\"source_link\" '\n",
      " 'style=\"float:right\">[source]</a>\\'\\n'\n",
      " '    title_level = title_level or (default_cls_level if inspect.isclass(elt) '\n",
      " 'else 4)\\n'\n",
      " '    doc =  f\\'<h{title_level} id=\"{qname}\" '\n",
      " 'class=\"doc_header\">{name}{source_link}</h{title_level}>\\'\\n'\n",
      " \"    doc += f'\\\\n\\\\n> {args}\\\\n\\\\n' if len(args) > 0 else '\\\\n\\\\n'\\n\"\n",
      " '    if doc_string and inspect.getdoc(elt):\\n'\n",
      " '        s = inspect.getdoc(elt)\\n'\n",
      " '        # show_doc is used by doc so should not rely on Config\\n'\n",
      " \"        try: monospace = (Config().get('monospace_docstrings') == 'True')\\n\"\n",
      " '        except: monospace = False\\n'\n",
      " \"        # doc links don't work inside markdown pre/code blocks\\n\"\n",
      " \"        s = f'```\\\\n{s}\\\\n```' if monospace else add_doc_links(s, elt)\\n\"\n",
      " '        doc += s\\n'\n",
      " '    if disp: display(Markdown(doc))\\n'\n",
      " '    else: return doc')\n",
      "code_lines: ['def md2html(md):',\n",
      " '    \"Convert markdown `md` to HTML code\"',\n",
      " '    import nbconvert',\n",
      " \"    if nbconvert.__version__ < '5.5.0': return \"\n",
      " 'HTMLExporter().markdown2html(md)',\n",
      " '    else: return '\n",
      " 'HTMLExporter().markdown2html(collections.defaultdict(lambda: '\n",
      " 'collections.defaultdict(dict)), md)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def md2html(md):\\n'\n",
      " '    \"Convert markdown `md` to HTML code\"\\n'\n",
      " '    import nbconvert\\n'\n",
      " \"    if nbconvert.__version__ < '5.5.0': return \"\n",
      " 'HTMLExporter().markdown2html(md)\\n'\n",
      " '    else: return '\n",
      " 'HTMLExporter().markdown2html(collections.defaultdict(lambda: '\n",
      " 'collections.defaultdict(dict)), md)')\n",
      "code_lines: ['def get_doc_link(func):',\n",
      " '    mod = inspect.getmodule(func)',\n",
      " \"    module = mod.__name__.replace('.', '/') + '.py'\",\n",
      " '    try:',\n",
      " \"        nbdev_mod = importlib.import_module(mod.__package__.split('.')[0] + \"\n",
      " \"'._nbdev')\",\n",
      " '        try_pack = source_nb(func, mod=nbdev_mod)',\n",
      " '        if try_pack:',\n",
      " \"            page = '.'.join(try_pack.partition('_')[-1:]).replace('.ipynb', \"\n",
      " \"'')\",\n",
      " \"            return f'{nbdev_mod.doc_url}{page}#{qual_name(func)}'\",\n",
      " '    except: return None']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def get_doc_link(func):\\n'\n",
      " '    mod = inspect.getmodule(func)\\n'\n",
      " \"    module = mod.__name__.replace('.', '/') + '.py'\\n\"\n",
      " '    try:\\n'\n",
      " \"        nbdev_mod = importlib.import_module(mod.__package__.split('.')[0] + \"\n",
      " \"'._nbdev')\\n\"\n",
      " '        try_pack = source_nb(func, mod=nbdev_mod)\\n'\n",
      " '        if try_pack:\\n'\n",
      " \"            page = '.'.join(try_pack.partition('_')[-1:]).replace('.ipynb', \"\n",
      " \"'')\\n\"\n",
      " \"            return f'{nbdev_mod.doc_url}{page}#{qual_name(func)}'\\n\"\n",
      " '    except: return None')\n",
      "code_lines: ['def doc(elt):',\n",
      " '    \"Show `show_doc` info in preview window when used in a notebook\"',\n",
      " '    md = show_doc(elt, disp=False)',\n",
      " '    doc_link = get_doc_link(elt)',\n",
      " '    if doc_link is not None:',\n",
      " '        md += f\\'\\\\n\\\\n<a href=\"{doc_link}\" target=\"_blank\" rel=\"noreferrer '\n",
      " 'noopener\">Show in docs</a>\\'',\n",
      " '    output = md2html(md)',\n",
      " \"    if IN_COLAB: get_ipython().run_cell_magic(u'html', u'', output)\",\n",
      " '    else:',\n",
      " \"        try: page.page({'text/html': output})\",\n",
      " '        except: display(Markdown(md))']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def doc(elt):\\n'\n",
      " '    \"Show `show_doc` info in preview window when used in a notebook\"\\n'\n",
      " '    md = show_doc(elt, disp=False)\\n'\n",
      " '    doc_link = get_doc_link(elt)\\n'\n",
      " '    if doc_link is not None:\\n'\n",
      " '        md += f\\'\\\\n\\\\n<a href=\"{doc_link}\" target=\"_blank\" rel=\"noreferrer '\n",
      " 'noopener\">Show in docs</a>\\'\\n'\n",
      " '    output = md2html(md)\\n'\n",
      " \"    if IN_COLAB: get_ipython().run_cell_magic(u'html', u'', output)\\n\"\n",
      " '    else:\\n'\n",
      " \"        try: page.page({'text/html': output})\\n\"\n",
      " '        except: display(Markdown(md))')\n",
      "Converted 02_showdoc.ipynb.\n",
      "code_lines: ['from .imports import *',\n",
      " 'from .sync import *',\n",
      " 'from .export import *',\n",
      " 'from .export import _mk_flag_re',\n",
      " 'from .showdoc import *',\n",
      " 'from .template import *',\n",
      " 'from fastcore.foundation import *',\n",
      " 'from fastcore.script import *',\n",
      " '',\n",
      " 'from html.parser import HTMLParser',\n",
      " 'from nbconvert.preprocessors import ExecutePreprocessor, Preprocessor',\n",
      " 'from nbconvert import HTMLExporter,MarkdownExporter',\n",
      " 'import traitlets',\n",
      " 'import nbformat']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'from .imports import *\\n'\n",
      " 'from .sync import *\\n'\n",
      " 'from .export import *\\n'\n",
      " 'from .export import _mk_flag_re\\n'\n",
      " 'from .showdoc import *\\n'\n",
      " 'from .template import *\\n'\n",
      " 'from fastcore.foundation import *\\n'\n",
      " 'from fastcore.script import *\\n'\n",
      " '\\n'\n",
      " 'from html.parser import HTMLParser\\n'\n",
      " 'from nbconvert.preprocessors import ExecutePreprocessor, Preprocessor\\n'\n",
      " 'from nbconvert import HTMLExporter,MarkdownExporter\\n'\n",
      " 'import traitlets\\n'\n",
      " 'import nbformat')\n",
      "code_lines: ['class HTMLParseAttrs(HTMLParser):',\n",
      " '    \"Simple HTML parser which stores any attributes in `attrs` dict\"',\n",
      " '    def handle_starttag(self, tag, attrs): self.tag,self.attrs = '\n",
      " 'tag,dict(attrs)',\n",
      " '',\n",
      " '    def attrs2str(self):',\n",
      " '        \"Attrs as string\"',\n",
      " '        return \\' \\'.join([f\\'{k}=\"{v}\"\\' for k,v in self.attrs.items()])',\n",
      " '',\n",
      " '    def show(self):',\n",
      " '        \"Tag with updated attrs\"',\n",
      " \"        return f'<{self.tag} {self.attrs2str()} />'\",\n",
      " '',\n",
      " '    def __call__(self, s):',\n",
      " '        \"Parse `s` and store attrs\"',\n",
      " '        self.feed(s)',\n",
      " '        return self.attrs']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'class HTMLParseAttrs(HTMLParser):\\n'\n",
      " '    \"Simple HTML parser which stores any attributes in `attrs` dict\"\\n'\n",
      " '    def handle_starttag(self, tag, attrs): self.tag,self.attrs = '\n",
      " 'tag,dict(attrs)\\n'\n",
      " '\\n'\n",
      " '    def attrs2str(self):\\n'\n",
      " '        \"Attrs as string\"\\n'\n",
      " '        return \\' \\'.join([f\\'{k}=\"{v}\"\\' for k,v in self.attrs.items()])\\n'\n",
      " '\\n'\n",
      " '    def show(self):\\n'\n",
      " '        \"Tag with updated attrs\"\\n'\n",
      " \"        return f'<{self.tag} {self.attrs2str()} />'\\n\"\n",
      " '\\n'\n",
      " '    def __call__(self, s):\\n'\n",
      " '        \"Parse `s` and store attrs\"\\n'\n",
      " '        self.feed(s)\\n'\n",
      " '        return self.attrs')\n",
      "code_lines: ['def remove_widget_state(cell):',\n",
      " '    \"Remove widgets in the output of `cells`\"',\n",
      " \"    if cell['cell_type'] == 'code' and 'outputs' in cell:\",\n",
      " \"        cell['outputs'] = [l for l in cell['outputs']\",\n",
      " \"                           if not ('data' in l and \"\n",
      " \"'application/vnd.jupyter.widget-view+json' in l.data)]\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def remove_widget_state(cell):\\n'\n",
      " '    \"Remove widgets in the output of `cells`\"\\n'\n",
      " \"    if cell['cell_type'] == 'code' and 'outputs' in cell:\\n\"\n",
      " \"        cell['outputs'] = [l for l in cell['outputs']\\n\"\n",
      " \"                           if not ('data' in l and \"\n",
      " \"'application/vnd.jupyter.widget-view+json' in l.data)]\\n\"\n",
      " '    return cell')\n",
      "code_lines: [\"# Note: `_re_show_doc` will catch show_doc even if it's commented out etc\",\n",
      " '_re_show_doc = re.compile(r\"\"\"',\n",
      " '# Catches any show_doc and get the first argument in group 1',\n",
      " '^\\\\s*show_doc # line can start with any amount of whitespace followed by '\n",
      " 'show_doc',\n",
      " '\\\\s*\\\\(\\\\s*     # Any number of whitespace, opening (, any number of '\n",
      " 'whitespace',\n",
      " '([^,\\\\)\\\\s]*)  # Catching group for any character but a comma, a closing ) '\n",
      " 'or a whitespace',\n",
      " '[,\\\\)\\\\s]      # A comma, a closing ) or a whitespace',\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)',\n",
      " '',\n",
      " '_re_hide_input = [',\n",
      " '    _mk_flag_re(\\'export\\', (0,1), \"Cell that has `#export\"),',\n",
      " '    _mk_flag_re(\\'(hide_input|hide-input)\\', 0, \"Cell that has `#hide_input` '\n",
      " 'or `#hide-input`\")]',\n",
      " '',\n",
      " '_re_hide_output = _mk_flag_re(\\'(hide_output|hide-output)\\', 0, \"Cell that '\n",
      " 'has `#hide_output` or `#hide-output`\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"# Note: `_re_show_doc` will catch show_doc even if it's commented out etc\\n\"\n",
      " '_re_show_doc = re.compile(r\"\"\"\\n'\n",
      " '# Catches any show_doc and get the first argument in group 1\\n'\n",
      " '^\\\\s*show_doc # line can start with any amount of whitespace followed by '\n",
      " 'show_doc\\n'\n",
      " '\\\\s*\\\\(\\\\s*     # Any number of whitespace, opening (, any number of '\n",
      " 'whitespace\\n'\n",
      " '([^,\\\\)\\\\s]*)  # Catching group for any character but a comma, a closing ) '\n",
      " 'or a whitespace\\n'\n",
      " '[,\\\\)\\\\s]      # A comma, a closing ) or a whitespace\\n'\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)\\n'\n",
      " '\\n'\n",
      " '_re_hide_input = [\\n'\n",
      " '    _mk_flag_re(\\'export\\', (0,1), \"Cell that has `#export\"),\\n'\n",
      " '    _mk_flag_re(\\'(hide_input|hide-input)\\', 0, \"Cell that has `#hide_input` '\n",
      " 'or `#hide-input`\")]\\n'\n",
      " '\\n'\n",
      " '_re_hide_output = _mk_flag_re(\\'(hide_output|hide-output)\\', 0, \"Cell that '\n",
      " 'has `#hide_output` or `#hide-output`\")')\n",
      "code_lines: ['def upd_metadata(cell, key, value=True):',\n",
      " '    \"Sets `key` to `value` on the `metadata` of `cell` without replacing '\n",
      " 'metadata\"',\n",
      " \"    cell.setdefault('metadata',{})[key] = value\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def upd_metadata(cell, key, value=True):\\n'\n",
      " '    \"Sets `key` to `value` on the `metadata` of `cell` without replacing '\n",
      " 'metadata\"\\n'\n",
      " \"    cell.setdefault('metadata',{})[key] = value\")\n",
      "code_lines: ['def hide_cells(cell):',\n",
      " '    \"Hide inputs of `cell` that need to be hidden\"',\n",
      " '    if check_re_multi(cell, [_re_show_doc, *_re_hide_input]): '\n",
      " \"upd_metadata(cell, 'hide_input')\",\n",
      " \"    elif check_re(cell, _re_hide_output): upd_metadata(cell, 'hide_output')\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def hide_cells(cell):\\n'\n",
      " '    \"Hide inputs of `cell` that need to be hidden\"\\n'\n",
      " '    if check_re_multi(cell, [_re_show_doc, *_re_hide_input]): '\n",
      " \"upd_metadata(cell, 'hide_input')\\n\"\n",
      " \"    elif check_re(cell, _re_hide_output): upd_metadata(cell, 'hide_output')\\n\"\n",
      " '    return cell')\n",
      "code_lines: ['def clean_exports(cell):',\n",
      " '    \"Remove all flags from code `cell`s\"',\n",
      " \"    if cell['cell_type'] == 'code': cell['source'] = \"\n",
      " 'split_flags_and_code(cell, str)[1]',\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def clean_exports(cell):\\n'\n",
      " '    \"Remove all flags from code `cell`s\"\\n'\n",
      " \"    if cell['cell_type'] == 'code': cell['source'] = \"\n",
      " 'split_flags_and_code(cell, str)[1]\\n'\n",
      " '    return cell')\n",
      "code_lines: ['def treat_backticks(cell):',\n",
      " '    \"Add links to backticks words in `cell`\"',\n",
      " \"    if cell['cell_type'] == 'markdown': cell['source'] = \"\n",
      " \"add_doc_links(cell['source'])\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def treat_backticks(cell):\\n'\n",
      " '    \"Add links to backticks words in `cell`\"\\n'\n",
      " \"    if cell['cell_type'] == 'markdown': cell['source'] = \"\n",
      " \"add_doc_links(cell['source'])\\n\"\n",
      " '    return cell')\n",
      "code_lines: ['_re_nb_link = re.compile(r\"\"\"',\n",
      " '# Catches any link to a local notebook and keeps the title in group 1, the '\n",
      " 'link without .ipynb in group 2',\n",
      " '\\\\[          # Opening [',\n",
      " '([^\\\\]]*)    # Catching group for any character except ]',\n",
      " '\\\\]\\\\(        # Closing ], opening (',\n",
      " '([^http]    # Catching group that must not begin by html (local notebook)',\n",
      " '[^\\\\)]*)     # and containing anything but )',\n",
      " '.ipynb\\\\)    # .ipynb and closing )',\n",
      " '\"\"\", re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_nb_link = re.compile(r\"\"\"\\n'\n",
      " '# Catches any link to a local notebook and keeps the title in group 1, the '\n",
      " 'link without .ipynb in group 2\\n'\n",
      " '\\\\[          # Opening [\\n'\n",
      " '([^\\\\]]*)    # Catching group for any character except ]\\n'\n",
      " '\\\\]\\\\(        # Closing ], opening (\\n'\n",
      " '([^http]    # Catching group that must not begin by html (local notebook)\\n'\n",
      " '[^\\\\)]*)     # and containing anything but )\\n'\n",
      " '.ipynb\\\\)    # .ipynb and closing )\\n'\n",
      " '\"\"\", re.VERBOSE)')\n",
      "code_lines: ['_re_block_notes = re.compile(r\"\"\"',\n",
      " '# Catches any pattern > Title: content with title in group 1 and content in '\n",
      " 'group 2',\n",
      " '^\\\\s*>\\\\s*     # > followed by any number of whitespace',\n",
      " '([^:]*)      # Catching group for any character but :',\n",
      " ':\\\\s*         # : then any number of whitespace',\n",
      " '([^\\\\n]*)     # Catching group for anything but a new line character',\n",
      " '(?:\\\\n|$)     # Non-catching group for either a new line or the end of the '\n",
      " 'text',\n",
      " '\"\"\", re.VERBOSE | re.MULTILINE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_block_notes = re.compile(r\"\"\"\\n'\n",
      " '# Catches any pattern > Title: content with title in group 1 and content in '\n",
      " 'group 2\\n'\n",
      " '^\\\\s*>\\\\s*     # > followed by any number of whitespace\\n'\n",
      " '([^:]*)      # Catching group for any character but :\\n'\n",
      " ':\\\\s*         # : then any number of whitespace\\n'\n",
      " '([^\\\\n]*)     # Catching group for anything but a new line character\\n'\n",
      " '(?:\\\\n|$)     # Non-catching group for either a new line or the end of the '\n",
      " 'text\\n'\n",
      " '\"\"\", re.VERBOSE | re.MULTILINE)')\n",
      "code_lines: ['def _to_html(text):', '    return text.replace(\"\\'\", \"&#8217;\")']\n",
      "code: '\\n\\n# Cell\\ndef _to_html(text):\\n    return text.replace(\"\\'\", \"&#8217;\")'\n",
      "code_lines: ['def add_jekyll_notes(cell):',\n",
      " '    \"Convert block quotes to jekyll notes in `cell`\"',\n",
      " \"    styles = Config().get('jekyll_styles', \"\n",
      " \"'note,warning,tip,important').split(',')\",\n",
      " '    def _inner(m):',\n",
      " '        title,text = m.groups()',\n",
      " '        if title.lower() not in styles: return f\"> {title}:{text}\"',\n",
      " '        return \\'{% include \\'+title.lower()+\".html '\n",
      " 'content=\\\\\\'\"+_to_html(text)+\"\\\\\\' %}\"',\n",
      " \"    if cell['cell_type'] == 'markdown':\",\n",
      " \"        cell['source'] = _re_block_notes.sub(_inner, cell['source'])\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def add_jekyll_notes(cell):\\n'\n",
      " '    \"Convert block quotes to jekyll notes in `cell`\"\\n'\n",
      " \"    styles = Config().get('jekyll_styles', \"\n",
      " \"'note,warning,tip,important').split(',')\\n\"\n",
      " '    def _inner(m):\\n'\n",
      " '        title,text = m.groups()\\n'\n",
      " '        if title.lower() not in styles: return f\"> {title}:{text}\"\\n'\n",
      " '        return \\'{% include \\'+title.lower()+\".html '\n",
      " 'content=\\\\\\'\"+_to_html(text)+\"\\\\\\' %}\"\\n'\n",
      " \"    if cell['cell_type'] == 'markdown':\\n\"\n",
      " \"        cell['source'] = _re_block_notes.sub(_inner, cell['source'])\\n\"\n",
      " '    return cell')\n",
      "code_lines: ['_re_image = re.compile(r\"\"\"',\n",
      " '# Catches any image file used, either with `![alt](image_file)` or `<img '\n",
      " 'src=\"image_file\">`',\n",
      " '^(!\\\\[           #   Beginning of line (since re.MULTILINE is passed) '\n",
      " 'followed by ![ in a catching group',\n",
      " '[^\\\\]]*          #   Anything but ]',\n",
      " '\\\\]\\\\()           #   Closing ] and opening (, end of the first catching '\n",
      " 'group',\n",
      " '[ \\\\t]*          #   Whitespace before the image path',\n",
      " '([^\\\\) \\\\t]*)     #   Catching block with any character that is not ) or '\n",
      " 'whitespace',\n",
      " '(\\\\)| |\\\\t)       #   Catching group with closing ) or whitespace',\n",
      " '|               # OR',\n",
      " '^(<img\\\\ [^>]*>) #   Catching group with <img some_html_code>',\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_image = re.compile(r\"\"\"\\n'\n",
      " '# Catches any image file used, either with `![alt](image_file)` or `<img '\n",
      " 'src=\"image_file\">`\\n'\n",
      " '^(!\\\\[           #   Beginning of line (since re.MULTILINE is passed) '\n",
      " 'followed by ![ in a catching group\\n'\n",
      " '[^\\\\]]*          #   Anything but ]\\n'\n",
      " '\\\\]\\\\()           #   Closing ] and opening (, end of the first catching '\n",
      " 'group\\n'\n",
      " '[ \\\\t]*          #   Whitespace before the image path\\n'\n",
      " '([^\\\\) \\\\t]*)     #   Catching block with any character that is not ) or '\n",
      " 'whitespace\\n'\n",
      " '(\\\\)| |\\\\t)       #   Catching group with closing ) or whitespace\\n'\n",
      " '|               # OR\\n'\n",
      " '^(<img\\\\ [^>]*>) #   Catching group with <img some_html_code>\\n'\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)')\n",
      "code_lines: ['def _img2jkl(d, h, jekyll=True):',\n",
      " '    if d.get(\"src\",\"\").startswith(\"http\"): jekyll=False',\n",
      " '    if jekyll:',\n",
      " \"        if 'width' in d: d['max-width'] = d.get('width')\",\n",
      " '    else:',\n",
      " '        if \\'width\\' in d: d[\\'style\\'] = f\\'max-width: {d.get(\"width\")}px\\'',\n",
      " \"        d.pop('align','')\",\n",
      " \"        return '<img ' + h.attrs2str() + '>'\",\n",
      " \"    if 'src' in d:   d['file'] = d.pop('src')\",\n",
      " \"    return '{% include image.html ' + h.attrs2str() + ' %}'\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _img2jkl(d, h, jekyll=True):\\n'\n",
      " '    if d.get(\"src\",\"\").startswith(\"http\"): jekyll=False\\n'\n",
      " '    if jekyll:\\n'\n",
      " \"        if 'width' in d: d['max-width'] = d.get('width')\\n\"\n",
      " '    else:\\n'\n",
      " \"        if 'width' in d: d['style'] = f'max-width: \"\n",
      " '{d.get(\"width\")}px\\'\\n'\n",
      " \"        d.pop('align','')\\n\"\n",
      " \"        return '<img ' + h.attrs2str() + '>'\\n\"\n",
      " \"    if 'src' in d:   d['file'] = d.pop('src')\\n\"\n",
      " \"    return '{% include image.html ' + h.attrs2str() + ' %}'\")\n",
      "code_lines: ['def _is_real_image(src):',\n",
      " \"    return not (src.startswith('http://') or src.startswith('https://') or \"\n",
      " \"src.startswith('data:image/') or src.startswith('attachment:'))\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _is_real_image(src):\\n'\n",
      " \"    return not (src.startswith('http://') or src.startswith('https://') or \"\n",
      " \"src.startswith('data:image/') or src.startswith('attachment:'))\")\n",
      "code_lines: ['def copy_images(cell, fname, dest, jekyll=True):',\n",
      " '    \"Copy images referenced in `cell` from `fname` parent folder to `dest` '\n",
      " 'folder\"',\n",
      " '    def _rep_src(m):',\n",
      " '        grps = m.groups()',\n",
      " '        if grps[3] is not None:',\n",
      " '            h = HTMLParseAttrs()',\n",
      " '            dic = h(grps[3])',\n",
      " \"            src = dic['src']\",\n",
      " '        else: src = grps[1]',\n",
      " '        if _is_real_image(src):',\n",
      " '            os.makedirs((Path(dest)/src).parent, exist_ok=True)',\n",
      " '            shutil.copy(Path(fname).parent/src, Path(dest)/src)',\n",
      " '            src = Config().doc_baseurl + src',\n",
      " '        if grps[3] is not None:',\n",
      " \"            dic['src'] = src\",\n",
      " '            return _img2jkl(dic, h, jekyll=jekyll)',\n",
      " '        else: return f\"{grps[0]}{src}{grps[2]}\"',\n",
      " \"    if cell['cell_type'] == 'markdown': cell['source'] = \"\n",
      " \"_re_image.sub(_rep_src, cell['source'])\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def copy_images(cell, fname, dest, jekyll=True):\\n'\n",
      " '    \"Copy images referenced in `cell` from `fname` parent folder to `dest` '\n",
      " 'folder\"\\n'\n",
      " '    def _rep_src(m):\\n'\n",
      " '        grps = m.groups()\\n'\n",
      " '        if grps[3] is not None:\\n'\n",
      " '            h = HTMLParseAttrs()\\n'\n",
      " '            dic = h(grps[3])\\n'\n",
      " \"            src = dic['src']\\n\"\n",
      " '        else: src = grps[1]\\n'\n",
      " '        if _is_real_image(src):\\n'\n",
      " '            os.makedirs((Path(dest)/src).parent, exist_ok=True)\\n'\n",
      " '            shutil.copy(Path(fname).parent/src, Path(dest)/src)\\n'\n",
      " '            src = Config().doc_baseurl + src\\n'\n",
      " '        if grps[3] is not None:\\n'\n",
      " \"            dic['src'] = src\\n\"\n",
      " '            return _img2jkl(dic, h, jekyll=jekyll)\\n'\n",
      " '        else: return f\"{grps[0]}{src}{grps[2]}\"\\n'\n",
      " \"    if cell['cell_type'] == 'markdown': cell['source'] = \"\n",
      " \"_re_image.sub(_rep_src, cell['source'])\\n\"\n",
      " '    return cell')\n",
      "code_lines: ['def _relative_to(path1, path2):',\n",
      " '    p1,p2 = Path(path1).absolute().parts,Path(path2).absolute().parts',\n",
      " '    i=0',\n",
      " '    while i <len(p1) and i<len(p2) and p1[i] == p2[i]: i+=1',\n",
      " '    p1,p2 = p1[i:],p2[i:]',\n",
      " \"    return os.path.sep.join(['..' for _ in p2] + list(p1))\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _relative_to(path1, path2):\\n'\n",
      " '    p1,p2 = Path(path1).absolute().parts,Path(path2).absolute().parts\\n'\n",
      " '    i=0\\n'\n",
      " '    while i <len(p1) and i<len(p2) and p1[i] == p2[i]: i+=1\\n'\n",
      " '    p1,p2 = p1[i:],p2[i:]\\n'\n",
      " \"    return os.path.sep.join(['..' for _ in p2] + list(p1))\")\n",
      "code_lines: ['def adapt_img_path(cell, fname, dest, jekyll=True):',\n",
      " '    \"Adapt path of images referenced in `cell` from `fname` to work in '\n",
      " 'folder `dest`\"',\n",
      " '    def _rep(m):',\n",
      " '        gps = m.groups()',\n",
      " '        if gps[0] is not None:',\n",
      " '            start,img,end = gps[:3]',\n",
      " \"            if not (img.startswith('http:/') or img.startswith('https:/')):\",\n",
      " '                img = _relative_to(fname.parent/img, dest)',\n",
      " \"            return f'{start}{img}{end}'\",\n",
      " '        else:',\n",
      " '            h = HTMLParseAttrs()',\n",
      " '            dic = h(gps[3])',\n",
      " \"            if not (dic['src'].startswith('http:/') or \"\n",
      " \"dic['src'].startswith('https:/')):\",\n",
      " \"                dic['src'] = _relative_to(fname.parent/dic['src'], dest)\",\n",
      " '            return _img2jkl(dic, h, jekyll=jekyll)',\n",
      " \"    if cell['cell_type'] == 'markdown': cell['source'] = _re_image.sub(_rep, \"\n",
      " \"cell['source'])\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def adapt_img_path(cell, fname, dest, jekyll=True):\\n'\n",
      " '    \"Adapt path of images referenced in `cell` from `fname` to work in '\n",
      " 'folder `dest`\"\\n'\n",
      " '    def _rep(m):\\n'\n",
      " '        gps = m.groups()\\n'\n",
      " '        if gps[0] is not None:\\n'\n",
      " '            start,img,end = gps[:3]\\n'\n",
      " \"            if not (img.startswith('http:/') or img.startswith('https:/')):\\n\"\n",
      " '                img = _relative_to(fname.parent/img, dest)\\n'\n",
      " \"            return f'{start}{img}{end}'\\n\"\n",
      " '        else:\\n'\n",
      " '            h = HTMLParseAttrs()\\n'\n",
      " '            dic = h(gps[3])\\n'\n",
      " \"            if not (dic['src'].startswith('http:/') or \"\n",
      " \"dic['src'].startswith('https:/')):\\n\"\n",
      " \"                dic['src'] = _relative_to(fname.parent/dic['src'], dest)\\n\"\n",
      " '            return _img2jkl(dic, h, jekyll=jekyll)\\n'\n",
      " \"    if cell['cell_type'] == 'markdown': cell['source'] = _re_image.sub(_rep, \"\n",
      " \"cell['source'])\\n\"\n",
      " '    return cell')\n",
      "code_lines: [\"_re_latex = re.compile(r'^(\\\\$\\\\$.*\\\\$\\\\$)$', re.MULTILINE)\"]\n",
      "code: \"\\n\\n# Cell\\n_re_latex = re.compile(r'^(\\\\$\\\\$.*\\\\$\\\\$)$', re.MULTILINE)\"\n",
      "code_lines: ['def escape_latex(cell):',\n",
      " \"    if cell['cell_type'] != 'markdown': return cell\",\n",
      " \"    cell['source'] = _re_latex.sub(r'{% raw %}\\\\n\\\\1\\\\n{% endraw %}', \"\n",
      " \"cell['source'])\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def escape_latex(cell):\\n'\n",
      " \"    if cell['cell_type'] != 'markdown': return cell\\n\"\n",
      " \"    cell['source'] = _re_latex.sub(r'{% raw %}\\\\n\\\\1\\\\n{% endraw %}', \"\n",
      " \"cell['source'])\\n\"\n",
      " '    return cell')\n",
      "code_lines: ['_re_cell_to_collapse_closed = '\n",
      " '_mk_flag_re(\\'(collapse|collapse_hide|collapse-hide)\\', 0, \"Cell with '\n",
      " '#collapse or #collapse_hide\")',\n",
      " \"_re_cell_to_collapse_open = _mk_flag_re('(collapse_show|collapse-show)', 0, \"\n",
      " '\"Cell with #collapse_show\")',\n",
      " '_re_cell_to_collapse_output = '\n",
      " '_mk_flag_re(\\'(collapse_output|collapse-output)\\', 0, \"Cell with '\n",
      " '#collapse_output\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_cell_to_collapse_closed = '\n",
      " '_mk_flag_re(\\'(collapse|collapse_hide|collapse-hide)\\', 0, \"Cell with '\n",
      " '#collapse or #collapse_hide\")\\n'\n",
      " \"_re_cell_to_collapse_open = _mk_flag_re('(collapse_show|collapse-show)', 0, \"\n",
      " '\"Cell with #collapse_show\")\\n'\n",
      " '_re_cell_to_collapse_output = '\n",
      " '_mk_flag_re(\\'(collapse_output|collapse-output)\\', 0, \"Cell with '\n",
      " '#collapse_output\")')\n",
      "code_lines: ['def collapse_cells(cell):',\n",
      " '    \"Add a collapse button to inputs or outputs of `cell` in either the open '\n",
      " 'or closed position\"',\n",
      " '    if check_re(cell, _re_cell_to_collapse_closed): '\n",
      " \"upd_metadata(cell,'collapse_hide')\",\n",
      " '    elif check_re(cell, _re_cell_to_collapse_open): '\n",
      " \"upd_metadata(cell,'collapse_show')\",\n",
      " '    elif check_re(cell, _re_cell_to_collapse_output): '\n",
      " \"upd_metadata(cell,'collapse_output')\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def collapse_cells(cell):\\n'\n",
      " '    \"Add a collapse button to inputs or outputs of `cell` in either the open '\n",
      " 'or closed position\"\\n'\n",
      " '    if check_re(cell, _re_cell_to_collapse_closed): '\n",
      " \"upd_metadata(cell,'collapse_hide')\\n\"\n",
      " '    elif check_re(cell, _re_cell_to_collapse_open): '\n",
      " \"upd_metadata(cell,'collapse_show')\\n\"\n",
      " '    elif check_re(cell, _re_cell_to_collapse_output): '\n",
      " \"upd_metadata(cell,'collapse_output')\\n\"\n",
      " '    return cell')\n",
      "code_lines: [\"_re_hide = _mk_flag_re('hide', 0, 'Cell with #hide')\",\n",
      " \"_re_cell_to_remove = _mk_flag_re('(default_exp|exporti)', (0,1), 'Cell with \"\n",
      " \"#default_exp or #exporti')\",\n",
      " '_re_default_cls_lvl = _mk_flag_re(\\'default_cls_lvl\\', 1, \"Cell with '\n",
      " '#default_cls_lvl\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_re_hide = _mk_flag_re('hide', 0, 'Cell with #hide')\\n\"\n",
      " \"_re_cell_to_remove = _mk_flag_re('(default_exp|exporti)', (0,1), 'Cell with \"\n",
      " \"#default_exp or #exporti')\\n\"\n",
      " '_re_default_cls_lvl = _mk_flag_re(\\'default_cls_lvl\\', 1, \"Cell with '\n",
      " '#default_cls_lvl\")')\n",
      "code_lines: ['def remove_hidden(cells):',\n",
      " '    \"Remove in `cells` the ones with a flag `#hide`, `#default_exp`, '\n",
      " '`#default_cls_lvl` or `#exporti`\"',\n",
      " '    _hidden = lambda c: check_re(c, _re_hide, code_only=False) or '\n",
      " 'check_re(c, _re_cell_to_remove)',\n",
      " '    return L(cells).filter(_hidden, negate=True)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def remove_hidden(cells):\\n'\n",
      " '    \"Remove in `cells` the ones with a flag `#hide`, `#default_exp`, '\n",
      " '`#default_cls_lvl` or `#exporti`\"\\n'\n",
      " '    _hidden = lambda c: check_re(c, _re_hide, code_only=False) or '\n",
      " 'check_re(c, _re_cell_to_remove)\\n'\n",
      " '    return L(cells).filter(_hidden, negate=True)')\n",
      "code_lines: ['def find_default_level(cells):',\n",
      " '    \"Find in `cells` the default class level.\"',\n",
      " '    res = L(cells).map_first(check_re_multi, pats=_re_default_cls_lvl)',\n",
      " '    return int(res.groups()[0]) if res else 2']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def find_default_level(cells):\\n'\n",
      " '    \"Find in `cells` the default class level.\"\\n'\n",
      " '    res = L(cells).map_first(check_re_multi, pats=_re_default_cls_lvl)\\n'\n",
      " '    return int(res.groups()[0]) if res else 2')\n",
      "code_lines: ['_re_export = _mk_flag_re(\"exports?\", (0,1), \"Line with #export or #exports '\n",
      " 'with or without module name\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_export = _mk_flag_re(\"exports?\", (0,1), \"Line with #export or #exports '\n",
      " 'with or without module name\")')\n",
      "code_lines: ['def nb_code_cell(source):',\n",
      " '    \"A code cell (as a dict) containing `source`\"',\n",
      " \"    return {'cell_type': 'code', 'execution_count': None, 'metadata': {}, \"\n",
      " \"'outputs': [], 'source': source}\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def nb_code_cell(source):\\n'\n",
      " '    \"A code cell (as a dict) containing `source`\"\\n'\n",
      " \"    return {'cell_type': 'code', 'execution_count': None, 'metadata': {}, \"\n",
      " \"'outputs': [], 'source': source}\")\n",
      "code_lines: ['def _show_doc_cell(name, cls_lvl=None):',\n",
      " '    return nb_code_cell(f\"show_doc({name}{\\'\\' if cls_lvl is None else f\\', '\n",
      " 'default_cls_level={cls_lvl}\\'})\")',\n",
      " '',\n",
      " 'def add_show_docs(cells, cls_lvl=None):',\n",
      " '    \"Add `show_doc` for each exported function or class\"',\n",
      " '    documented = L(cells).map(check_re, '\n",
      " 'pat=_re_show_doc).filter().map(Self.group(1))',\n",
      " '    res = []',\n",
      " '    for cell in cells:',\n",
      " '        res.append(cell)',\n",
      " '        if check_re(cell, _re_export):',\n",
      " \"            for n in export_names(cell['source'], func_only=True):\",\n",
      " '                if not n in documented: res.insert(len(res)-1, '\n",
      " '_show_doc_cell(n, cls_lvl=cls_lvl))',\n",
      " '    return res']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _show_doc_cell(name, cls_lvl=None):\\n'\n",
      " '    return nb_code_cell(f\"show_doc({name}{\\'\\' if cls_lvl is None else f\\', '\n",
      " 'default_cls_level={cls_lvl}\\'})\")\\n'\n",
      " '\\n'\n",
      " 'def add_show_docs(cells, cls_lvl=None):\\n'\n",
      " '    \"Add `show_doc` for each exported function or class\"\\n'\n",
      " '    documented = L(cells).map(check_re, '\n",
      " 'pat=_re_show_doc).filter().map(Self.group(1))\\n'\n",
      " '    res = []\\n'\n",
      " '    for cell in cells:\\n'\n",
      " '        res.append(cell)\\n'\n",
      " '        if check_re(cell, _re_export):\\n'\n",
      " \"            for n in export_names(cell['source'], func_only=True):\\n\"\n",
      " '                if not n in documented: res.insert(len(res)-1, '\n",
      " '_show_doc_cell(n, cls_lvl=cls_lvl))\\n'\n",
      " '    return res')\n",
      "code_lines: ['_re_fake_header = re.compile(r\"\"\"',\n",
      " '# Matches any fake header (one that ends with -)',\n",
      " '\\\\#+    # One or more #',\n",
      " '\\\\s+    # One or more of whitespace',\n",
      " '.*     # Any char',\n",
      " '-\\\\s*   # A dash followed by any number of white space',\n",
      " '$      # End of text',\n",
      " '\"\"\", re.VERBOSE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_fake_header = re.compile(r\"\"\"\\n'\n",
      " '# Matches any fake header (one that ends with -)\\n'\n",
      " '\\\\#+    # One or more #\\n'\n",
      " '\\\\s+    # One or more of whitespace\\n'\n",
      " '.*     # Any char\\n'\n",
      " '-\\\\s*   # A dash followed by any number of white space\\n'\n",
      " '$      # End of text\\n'\n",
      " '\"\"\", re.VERBOSE)')\n",
      "code_lines: ['def remove_fake_headers(cells):',\n",
      " '    \"Remove in `cells` the fake header\"',\n",
      " \"    return [c for c in cells if c['cell_type']=='code' or \"\n",
      " \"_re_fake_header.search(c['source']) is None]\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def remove_fake_headers(cells):\\n'\n",
      " '    \"Remove in `cells` the fake header\"\\n'\n",
      " \"    return [c for c in cells if c['cell_type']=='code' or \"\n",
      " \"_re_fake_header.search(c['source']) is None]\")\n",
      "code_lines: ['def remove_empty(cells):',\n",
      " '    \"Remove in `cells` the empty cells\"',\n",
      " \"    return [c for c in cells if len(c['source']) >0]\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def remove_empty(cells):\\n'\n",
      " '    \"Remove in `cells` the empty cells\"\\n'\n",
      " \"    return [c for c in cells if len(c['source']) >0]\")\n",
      "code_lines: ['_re_title_summary = re.compile(r\"\"\"',\n",
      " '# Catches the title and summary of the notebook, presented as # Title > '\n",
      " 'summary, with title in group 1 and summary in group 2',\n",
      " '^\\\\s*       # Beginning of text followed by any number of whitespace',\n",
      " '\\\\#\\\\s+      # # followed by one or more of whitespace',\n",
      " '([^\\\\n]*)   # Catching group for any character except a new line',\n",
      " '\\\\n+        # One or more new lines',\n",
      " '>[ ]*       # > followed by any number of whitespace',\n",
      " '([^\\\\n]*)   # Catching group for any character except a new line',\n",
      " '\"\"\", re.VERBOSE)',\n",
      " '',\n",
      " '_re_title_only = re.compile(r\"\"\"',\n",
      " '# Catches the title presented as # Title without a summary',\n",
      " '^\\\\s*       # Beginning of text followed by any number of whitespace',\n",
      " '\\\\#\\\\s+      # # followed by one or more of whitespace',\n",
      " '([^\\\\n]*)   # Catching group for any character except a new line',\n",
      " '(?:\\\\n|$)    # New line or end of text',\n",
      " '\"\"\", re.VERBOSE)',\n",
      " '',\n",
      " '_re_properties = re.compile(r\"\"\"',\n",
      " '^-\\\\s+      # Beginning of a line followed by - and at least one space',\n",
      " '(.*?)      # Any pattern (shortest possible)',\n",
      " '\\\\s*:\\\\s*    # Any number of whitespace, :, any number of whitespace',\n",
      " '(.*?)$     # Any pattern (shortest possible) then end of line',\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)',\n",
      " '',\n",
      " '_re_mdlinks = re.compile(r\"\\\\[(.+)]\\\\((.+)\\\\)\", re.MULTILINE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_title_summary = re.compile(r\"\"\"\\n'\n",
      " '# Catches the title and summary of the notebook, presented as # Title > '\n",
      " 'summary, with title in group 1 and summary in group 2\\n'\n",
      " '^\\\\s*       # Beginning of text followed by any number of whitespace\\n'\n",
      " '\\\\#\\\\s+      # # followed by one or more of whitespace\\n'\n",
      " '([^\\\\n]*)   # Catching group for any character except a new line\\n'\n",
      " '\\\\n+        # One or more new lines\\n'\n",
      " '>[ ]*       # > followed by any number of whitespace\\n'\n",
      " '([^\\\\n]*)   # Catching group for any character except a new line\\n'\n",
      " '\"\"\", re.VERBOSE)\\n'\n",
      " '\\n'\n",
      " '_re_title_only = re.compile(r\"\"\"\\n'\n",
      " '# Catches the title presented as # Title without a summary\\n'\n",
      " '^\\\\s*       # Beginning of text followed by any number of whitespace\\n'\n",
      " '\\\\#\\\\s+      # # followed by one or more of whitespace\\n'\n",
      " '([^\\\\n]*)   # Catching group for any character except a new line\\n'\n",
      " '(?:\\\\n|$)    # New line or end of text\\n'\n",
      " '\"\"\", re.VERBOSE)\\n'\n",
      " '\\n'\n",
      " '_re_properties = re.compile(r\"\"\"\\n'\n",
      " '^-\\\\s+      # Beginning of a line followed by - and at least one space\\n'\n",
      " '(.*?)      # Any pattern (shortest possible)\\n'\n",
      " '\\\\s*:\\\\s*    # Any number of whitespace, :, any number of whitespace\\n'\n",
      " '(.*?)$     # Any pattern (shortest possible) then end of line\\n'\n",
      " '\"\"\", re.MULTILINE | re.VERBOSE)\\n'\n",
      " '\\n'\n",
      " '_re_mdlinks = re.compile(r\"\\\\[(.+)]\\\\((.+)\\\\)\", re.MULTILINE)')\n",
      "code_lines: ['def _md2html_links(s):',\n",
      " \"    'Converts markdown links to html links'\",\n",
      " '    return _re_mdlinks.sub(r\"<a href=\\'\\\\2\\'>\\\\1</a>\", s)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _md2html_links(s):\\n'\n",
      " \"    'Converts markdown links to html links'\\n\"\n",
      " '    return _re_mdlinks.sub(r\"<a href=\\'\\\\2\\'>\\\\1</a>\", s)')\n",
      "code_lines: ['def get_metadata(cells):',\n",
      " '    \"Find the cell with title and summary in `cells`.\"',\n",
      " '    for i,cell in enumerate(cells):',\n",
      " \"        if cell['cell_type'] == 'markdown':\",\n",
      " \"            match = _re_title_summary.match(cell['source'])\",\n",
      " '            if match:',\n",
      " '                cells.pop(i)',\n",
      " '                attrs = {k:v for k,v in '\n",
      " \"_re_properties.findall(cell['source'])}\",\n",
      " \"                return {'keywords': 'fastai',\",\n",
      " \"                        'summary' : _md2html_links(match.groups()[1]),\",\n",
      " \"                        'title'   : match.groups()[0],\",\n",
      " '                        **attrs}',\n",
      " \"            elif _re_title_only.search(cell['source']) is not None:\",\n",
      " \"                title = _re_title_only.search(cell['source']).groups()[0]\",\n",
      " '                cells.pop(i)',\n",
      " '                attrs = {k:v for k,v in '\n",
      " \"_re_properties.findall(cell['source'])}\",\n",
      " \"                return {'keywords': 'fastai',\",\n",
      " \"                        'title'   : title,\",\n",
      " '                        **attrs}',\n",
      " '',\n",
      " \"    return {'keywords': 'fastai',\",\n",
      " \"            'title'   : 'Title'}\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def get_metadata(cells):\\n'\n",
      " '    \"Find the cell with title and summary in `cells`.\"\\n'\n",
      " '    for i,cell in enumerate(cells):\\n'\n",
      " \"        if cell['cell_type'] == 'markdown':\\n\"\n",
      " \"            match = _re_title_summary.match(cell['source'])\\n\"\n",
      " '            if match:\\n'\n",
      " '                cells.pop(i)\\n'\n",
      " '                attrs = {k:v for k,v in '\n",
      " \"_re_properties.findall(cell['source'])}\\n\"\n",
      " \"                return {'keywords': 'fastai',\\n\"\n",
      " \"                        'summary' : _md2html_links(match.groups()[1]),\\n\"\n",
      " \"                        'title'   : match.groups()[0],\\n\"\n",
      " '                        **attrs}\\n'\n",
      " \"            elif _re_title_only.search(cell['source']) is not None:\\n\"\n",
      " \"                title = _re_title_only.search(cell['source']).groups()[0]\\n\"\n",
      " '                cells.pop(i)\\n'\n",
      " '                attrs = {k:v for k,v in '\n",
      " \"_re_properties.findall(cell['source'])}\\n\"\n",
      " \"                return {'keywords': 'fastai',\\n\"\n",
      " \"                        'title'   : title,\\n\"\n",
      " '                        **attrs}\\n'\n",
      " '\\n'\n",
      " \"    return {'keywords': 'fastai',\\n\"\n",
      " \"            'title'   : 'Title'}\")\n",
      "code_lines: ['_re_mod_export = _mk_flag_re(\"export[s]?\", 1,',\n",
      " '    \"Matches any line with #export or #exports with a module name and '\n",
      " 'catches it in group 1\")',\n",
      " '',\n",
      " 'def _gather_export_mods(cells):',\n",
      " '    res = []',\n",
      " '    for cell in cells:',\n",
      " '        tst = check_re(cell, _re_mod_export)',\n",
      " '        if tst is not None: res.append(tst.groups()[0])',\n",
      " '    return res']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_mod_export = _mk_flag_re(\"export[s]?\", 1,\\n'\n",
      " '    \"Matches any line with #export or #exports with a module name and '\n",
      " 'catches it in group 1\")\\n'\n",
      " '\\n'\n",
      " 'def _gather_export_mods(cells):\\n'\n",
      " '    res = []\\n'\n",
      " '    for cell in cells:\\n'\n",
      " '        tst = check_re(cell, _re_mod_export)\\n'\n",
      " '        if tst is not None: res.append(tst.groups()[0])\\n'\n",
      " '    return res')\n",
      "code_lines: ['# match any cell containing a zero indented import from the current lib',\n",
      " '_re_lib_import = ReLibName(r\"^from LIB_NAME\\\\.\", re.MULTILINE)',\n",
      " '# match any cell containing a zero indented import',\n",
      " '_re_import = re.compile(r\"^from[ \\\\t]+\\\\S+[ \\\\t]+import|^import[ \\\\t]\", '\n",
      " 're.MULTILINE)',\n",
      " '# match any cell containing a zero indented call to notebook2script',\n",
      " '_re_notebook2script = re.compile(r\"^notebook2script\\\\(\", re.MULTILINE)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '# match any cell containing a zero indented import from the current lib\\n'\n",
      " '_re_lib_import = ReLibName(r\"^from LIB_NAME\\\\.\", re.MULTILINE)\\n'\n",
      " '# match any cell containing a zero indented import\\n'\n",
      " '_re_import = re.compile(r\"^from[ \\\\t]+\\\\S+[ \\\\t]+import|^import[ \\\\t]\", '\n",
      " 're.MULTILINE)\\n'\n",
      " '# match any cell containing a zero indented call to notebook2script\\n'\n",
      " '_re_notebook2script = re.compile(r\"^notebook2script\\\\(\", re.MULTILINE)')\n",
      "code_lines: ['def _non_comment_code(s):',\n",
      " \"    if re.match(r'\\\\s*#', s): return False\",\n",
      " '    if _re_import.findall(s) or _re_lib_import.re.findall(s): return False',\n",
      " \"    return re.match(r'\\\\s*\\\\w', s)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _non_comment_code(s):\\n'\n",
      " \"    if re.match(r'\\\\s*#', s): return False\\n\"\n",
      " '    if _re_import.findall(s) or _re_lib_import.re.findall(s): return False\\n'\n",
      " \"    return re.match(r'\\\\s*\\\\w', s)\")\n",
      "code_lines: ['class ExecuteShowDocPreprocessor(ExecutePreprocessor):',\n",
      " '    \"An `ExecutePreprocessor` that only executes `show_doc` and `import` '\n",
      " 'cells\"',\n",
      " '    def preprocess_cell(self, cell, resources, index):',\n",
      " '        if not check_re(cell, _re_notebook2script):',\n",
      " '            if check_re(cell, _re_show_doc):',\n",
      " '                return super().preprocess_cell(cell, resources, index)',\n",
      " '            elif check_re_multi(cell, [_re_import, _re_lib_import.re]):',\n",
      " \"                if check_re_multi(cell, [_re_export, 'show_doc', \"\n",
      " \"'^\\\\s*#\\\\s*import']):\",\n",
      " '#                     r = list(filter(_non_comment_code, '\n",
      " \"cell['source'].split('\\\\n')))\",\n",
      " '#                     if r: print(\"You have import statements mixed with '\n",
      " 'other code\", r)',\n",
      " '                    return super().preprocess_cell(cell, resources, index)',\n",
      " '#                 try: return super().preprocess_cell(cell, resources, '\n",
      " 'index)',\n",
      " '#                 except: pass',\n",
      " '        return cell, resources']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'class ExecuteShowDocPreprocessor(ExecutePreprocessor):\\n'\n",
      " '    \"An `ExecutePreprocessor` that only executes `show_doc` and `import` '\n",
      " 'cells\"\\n'\n",
      " '    def preprocess_cell(self, cell, resources, index):\\n'\n",
      " '        if not check_re(cell, _re_notebook2script):\\n'\n",
      " '            if check_re(cell, _re_show_doc):\\n'\n",
      " '                return super().preprocess_cell(cell, resources, index)\\n'\n",
      " '            elif check_re_multi(cell, [_re_import, _re_lib_import.re]):\\n'\n",
      " \"                if check_re_multi(cell, [_re_export, 'show_doc', \"\n",
      " \"'^\\\\s*#\\\\s*import']):\\n\"\n",
      " '#                     r = list(filter(_non_comment_code, '\n",
      " \"cell['source'].split('\\\\n')))\\n\"\n",
      " '#                     if r: print(\"You have import statements mixed with '\n",
      " 'other code\", r)\\n'\n",
      " '                    return super().preprocess_cell(cell, resources, index)\\n'\n",
      " '#                 try: return super().preprocess_cell(cell, resources, '\n",
      " 'index)\\n'\n",
      " '#                 except: pass\\n'\n",
      " '        return cell, resources')\n",
      "code_lines: ['def _import_show_doc_cell(mods=None):',\n",
      " '    \"Add an import show_doc cell.\"',\n",
      " '    source = f\"from nbdev.showdoc import show_doc\"',\n",
      " '    if mods is not None:',\n",
      " '        for mod in mods: source += f\"\\\\nfrom {Config().lib_name}.{mod} '\n",
      " 'import *\"',\n",
      " \"    return {'cell_type': 'code',\",\n",
      " \"            'execution_count': None,\",\n",
      " \"            'metadata': {'hide_input': True},\",\n",
      " \"            'outputs': [],\",\n",
      " \"            'source': source}\",\n",
      " '',\n",
      " 'def execute_nb(nb, mod=None, metadata=None, show_doc_only=True):',\n",
      " '    \"Execute `nb` (or only the `show_doc` cells) with `metadata`\"',\n",
      " \"    mods = ([] if mod is None else [mod]) + _gather_export_mods(nb['cells'])\",\n",
      " \"    nb['cells'].insert(0, _import_show_doc_cell(mods))\",\n",
      " '    ep_cls = ExecuteShowDocPreprocessor if show_doc_only else '\n",
      " 'ExecutePreprocessor',\n",
      " \"    ep = ep_cls(timeout=600, kernel_name='python3')\",\n",
      " '    metadata = metadata or {}',\n",
      " '    pnb = nbformat.from_dict(nb)',\n",
      " '    ep.preprocess(pnb, metadata)',\n",
      " '    return pnb']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _import_show_doc_cell(mods=None):\\n'\n",
      " '    \"Add an import show_doc cell.\"\\n'\n",
      " '    source = f\"from nbdev.showdoc import show_doc\"\\n'\n",
      " '    if mods is not None:\\n'\n",
      " '        for mod in mods: source += f\"\\\\nfrom {Config().lib_name}.{mod} '\n",
      " 'import *\"\\n'\n",
      " \"    return {'cell_type': 'code',\\n\"\n",
      " \"            'execution_count': None,\\n\"\n",
      " \"            'metadata': {'hide_input': True},\\n\"\n",
      " \"            'outputs': [],\\n\"\n",
      " \"            'source': source}\\n\"\n",
      " '\\n'\n",
      " 'def execute_nb(nb, mod=None, metadata=None, show_doc_only=True):\\n'\n",
      " '    \"Execute `nb` (or only the `show_doc` cells) with `metadata`\"\\n'\n",
      " '    mods = ([] if mod is None else [mod]) + '\n",
      " \"_gather_export_mods(nb['cells'])\\n\"\n",
      " \"    nb['cells'].insert(0, _import_show_doc_cell(mods))\\n\"\n",
      " '    ep_cls = ExecuteShowDocPreprocessor if show_doc_only else '\n",
      " 'ExecutePreprocessor\\n'\n",
      " \"    ep = ep_cls(timeout=600, kernel_name='python3')\\n\"\n",
      " '    metadata = metadata or {}\\n'\n",
      " '    pnb = nbformat.from_dict(nb)\\n'\n",
      " '    ep.preprocess(pnb, metadata)\\n'\n",
      " '    return pnb')\n",
      "code_lines: ['_re_cite = re.compile(r\"(\\\\\\\\cite{)([^}]*)(})\", re.MULTILINE | re.VERBOSE) # '\n",
      " 'Catches citations used with `\\\\cite{}`']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_re_cite = re.compile(r\"(\\\\\\\\cite{)([^}]*)(})\", re.MULTILINE | re.VERBOSE) # '\n",
      " 'Catches citations used with `\\\\cite{}`')\n",
      "code_lines: ['def _textcite2link(text):',\n",
      " '    citations = _re_cite.finditer(text)',\n",
      " '    out = []',\n",
      " '    start_pos = 0',\n",
      " '    for cit_group in citations:',\n",
      " '        cit_pos_st =  cit_group.span()[0]',\n",
      " '        cit_pos_fin =  cit_group.span()[1]',\n",
      " '        out.append(text[start_pos:cit_pos_st])',\n",
      " \"        out.append('[')\",\n",
      " \"        cit_group = cit_group[2].split(',')\",\n",
      " '        for i, cit in enumerate(cit_group):',\n",
      " '            cit=cit.strip()',\n",
      " '            out.append(f\"\"\"<a class=\"latex_cit\" id=\"call-{cit}\" '\n",
      " 'href=\"#cit-{cit}\">{cit}</a>\"\"\")',\n",
      " '            if i != len(cit_group) - 1:',\n",
      " \"                out.append(',')\",\n",
      " \"        out.append(']')\",\n",
      " '        start_pos = cit_pos_fin',\n",
      " '    out.append(text[start_pos:])',\n",
      " \"    return ''.join(out)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _textcite2link(text):\\n'\n",
      " '    citations = _re_cite.finditer(text)\\n'\n",
      " '    out = []\\n'\n",
      " '    start_pos = 0\\n'\n",
      " '    for cit_group in citations:\\n'\n",
      " '        cit_pos_st =  cit_group.span()[0]\\n'\n",
      " '        cit_pos_fin =  cit_group.span()[1]\\n'\n",
      " '        out.append(text[start_pos:cit_pos_st])\\n'\n",
      " \"        out.append('[')\\n\"\n",
      " \"        cit_group = cit_group[2].split(',')\\n\"\n",
      " '        for i, cit in enumerate(cit_group):\\n'\n",
      " '            cit=cit.strip()\\n'\n",
      " '            out.append(f\"\"\"<a class=\"latex_cit\" id=\"call-{cit}\" '\n",
      " 'href=\"#cit-{cit}\">{cit}</a>\"\"\")\\n'\n",
      " '            if i != len(cit_group) - 1:\\n'\n",
      " \"                out.append(',')\\n\"\n",
      " \"        out.append(']')\\n\"\n",
      " '        start_pos = cit_pos_fin\\n'\n",
      " '    out.append(text[start_pos:])\\n'\n",
      " \"    return ''.join(out)\")\n",
      "code_lines: ['def cite2link(cell):',\n",
      " \"    '''Creates links from \\\\cite{} to Reference section generated by \"\n",
      " \"jupyter_latex_envs'''\",\n",
      " \"    if cell['cell_type'] == 'markdown': cell['source'] = \"\n",
      " \"_textcite2link(cell['source'])\",\n",
      " '    return cell']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def cite2link(cell):\\n'\n",
      " \"    '''Creates links from \\\\cite{} to Reference section generated by \"\n",
      " \"jupyter_latex_envs'''\\n\"\n",
      " \"    if cell['cell_type'] == 'markdown': cell['source'] = \"\n",
      " \"_textcite2link(cell['source'])\\n\"\n",
      " '    return cell')\n",
      "code_lines: ['def write_tmpl(tmpl, nms, cfg, dest):',\n",
      " '    \"Write `tmpl` to `dest` (if missing) filling in `nms` in template using '\n",
      " 'dict `cfg`\"',\n",
      " '    if dest.exists(): return',\n",
      " '    vs = {o:cfg.d[o] for o in nms.split()}',\n",
      " '    outp = tmpl.format(**vs)',\n",
      " '    dest.mk_write(outp)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def write_tmpl(tmpl, nms, cfg, dest):\\n'\n",
      " '    \"Write `tmpl` to `dest` (if missing) filling in `nms` in template using '\n",
      " 'dict `cfg`\"\\n'\n",
      " '    if dest.exists(): return\\n'\n",
      " '    vs = {o:cfg.d[o] for o in nms.split()}\\n'\n",
      " '    outp = tmpl.format(**vs)\\n'\n",
      " '    dest.mk_write(outp)')\n",
      "code_lines: ['def write_tmpls():',\n",
      " '    \"Write out _config.yml and _data/topnav.yml using templates\"',\n",
      " '    cfg = Config()',\n",
      " '    path = Path(cfg.get(\\'doc_src_path\\', cfg.path(\"doc_path\")))',\n",
      " \"    write_tmpl(config_tmpl, 'user lib_name title copyright description \"\n",
      " \"recursive', cfg, path/'_config.yml')\",\n",
      " \"    write_tmpl(topnav_tmpl, 'host git_url', cfg, path/'_data'/'topnav.yml')\",\n",
      " \"    write_tmpl(makefile_tmpl, 'nbs_path lib_name', cfg, \"\n",
      " \"cfg.config_file.parent/'Makefile')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def write_tmpls():\\n'\n",
      " '    \"Write out _config.yml and _data/topnav.yml using templates\"\\n'\n",
      " '    cfg = Config()\\n'\n",
      " '    path = Path(cfg.get(\\'doc_src_path\\', cfg.path(\"doc_path\")))\\n'\n",
      " \"    write_tmpl(config_tmpl, 'user lib_name title copyright description \"\n",
      " \"recursive', cfg, path/'_config.yml')\\n\"\n",
      " \"    write_tmpl(topnav_tmpl, 'host git_url', cfg, path/'_data'/'topnav.yml')\\n\"\n",
      " \"    write_tmpl(makefile_tmpl, 'nbs_path lib_name', cfg, \"\n",
      " \"cfg.config_file.parent/'Makefile')\")\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_build_lib(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,',\n",
      " '                    bare:Param(\"Omit nbdev annotation comments (may break '\n",
      " 'some functionality).\", store_true)=False):',\n",
      " '    \"Export notebooks matching `fname` to python modules\"',\n",
      " '    write_tmpls()',\n",
      " '    notebook2script(fname=fname, bare=bare)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_build_lib(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,\\n'\n",
      " '                    bare:Param(\"Omit nbdev annotation comments (may break '\n",
      " 'some functionality).\", store_true)=False):\\n'\n",
      " '    \"Export notebooks matching `fname` to python modules\"\\n'\n",
      " '    write_tmpls()\\n'\n",
      " '    notebook2script(fname=fname, bare=bare)')\n",
      "code_lines: ['def nbdev_exporter(cls=HTMLExporter, template_file=None):',\n",
      " '    cfg = traitlets.config.Config()',\n",
      " '    exporter = cls(cfg)',\n",
      " '    exporter.exclude_input_prompt=True',\n",
      " '    exporter.exclude_output_prompt=True',\n",
      " \"    exporter.anchor_link_text = ' '\",\n",
      " \"    exporter.template_file = 'jekyll.tpl' if template_file is None else \"\n",
      " 'template_file',\n",
      " \"    exporter.template_path.append(str(Path(__file__).parent/'templates'))\",\n",
      " '    return exporter']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def nbdev_exporter(cls=HTMLExporter, template_file=None):\\n'\n",
      " '    cfg = traitlets.config.Config()\\n'\n",
      " '    exporter = cls(cfg)\\n'\n",
      " '    exporter.exclude_input_prompt=True\\n'\n",
      " '    exporter.exclude_output_prompt=True\\n'\n",
      " \"    exporter.anchor_link_text = ' '\\n\"\n",
      " \"    exporter.template_file = 'jekyll.tpl' if template_file is None else \"\n",
      " 'template_file\\n'\n",
      " \"    exporter.template_path.append(str(Path(__file__).parent/'templates'))\\n\"\n",
      " '    return exporter')\n",
      "code_lines: ['process_cells = [remove_fake_headers, remove_hidden, remove_empty]',\n",
      " 'process_cell  = [hide_cells, collapse_cells, remove_widget_state, '\n",
      " 'add_jekyll_notes, escape_latex, cite2link]']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'process_cells = [remove_fake_headers, remove_hidden, remove_empty]\\n'\n",
      " 'process_cell  = [hide_cells, collapse_cells, remove_widget_state, '\n",
      " 'add_jekyll_notes, escape_latex, cite2link]')\n",
      "code_lines: ['def _nb2htmlfname(nb_path, dest=None):',\n",
      " '    if dest is None: dest = Config().path(\"doc_path\")',\n",
      " \"    return Path(dest)/re_digits_first.sub('', \"\n",
      " \"nb_path.with_suffix('.html').name)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _nb2htmlfname(nb_path, dest=None):\\n'\n",
      " '    if dest is None: dest = Config().path(\"doc_path\")\\n'\n",
      " \"    return Path(dest)/re_digits_first.sub('', \"\n",
      " \"nb_path.with_suffix('.html').name)\")\n",
      "code_lines: ['def convert_nb(fname, cls=HTMLExporter, template_file=None, exporter=None, '\n",
      " 'dest=None, execute=True):',\n",
      " '    \"Convert a notebook `fname` to html file in `dest_path`.\"',\n",
      " '    fname = Path(fname).absolute()',\n",
      " '    nb = read_nb(fname)',\n",
      " \"    meta_jekyll = get_metadata(nb['cells'])\",\n",
      " \"    meta_jekyll['nb_path'] = \"\n",
      " 'str(fname.relative_to(Config().path(\"lib_path\").parent))',\n",
      " \"    cls_lvl = find_default_level(nb['cells'])\",\n",
      " \"    mod = find_default_export(nb['cells'])\",\n",
      " \"    nb['cells'] = compose(*process_cells,partial(add_show_docs, \"\n",
      " \"cls_lvl=cls_lvl))(nb['cells'])\",\n",
      " '    _func = compose(partial(copy_images, fname=fname, '\n",
      " 'dest=Config().path(\"doc_path\")), *process_cell, treat_backticks)',\n",
      " \"    nb['cells'] = [_func(c) for c in nb['cells']]\",\n",
      " '    if execute: nb = execute_nb(nb, mod=mod)',\n",
      " \"    nb['cells'] = [clean_exports(c) for c in nb['cells']]\",\n",
      " '    if exporter is None: exporter = nbdev_exporter(cls=cls, '\n",
      " 'template_file=template_file)',\n",
      " \"    with open(_nb2htmlfname(fname, dest=dest),'w') as f:\",\n",
      " '        f.write(exporter.from_notebook_node(nb, resources=meta_jekyll)[0])']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def convert_nb(fname, cls=HTMLExporter, template_file=None, exporter=None, '\n",
      " 'dest=None, execute=True):\\n'\n",
      " '    \"Convert a notebook `fname` to html file in `dest_path`.\"\\n'\n",
      " '    fname = Path(fname).absolute()\\n'\n",
      " '    nb = read_nb(fname)\\n'\n",
      " \"    meta_jekyll = get_metadata(nb['cells'])\\n\"\n",
      " \"    meta_jekyll['nb_path'] = \"\n",
      " 'str(fname.relative_to(Config().path(\"lib_path\").parent))\\n'\n",
      " \"    cls_lvl = find_default_level(nb['cells'])\\n\"\n",
      " \"    mod = find_default_export(nb['cells'])\\n\"\n",
      " \"    nb['cells'] = compose(*process_cells,partial(add_show_docs, \"\n",
      " \"cls_lvl=cls_lvl))(nb['cells'])\\n\"\n",
      " '    _func = compose(partial(copy_images, fname=fname, '\n",
      " 'dest=Config().path(\"doc_path\")), *process_cell, treat_backticks)\\n'\n",
      " \"    nb['cells'] = [_func(c) for c in nb['cells']]\\n\"\n",
      " '    if execute: nb = execute_nb(nb, mod=mod)\\n'\n",
      " \"    nb['cells'] = [clean_exports(c) for c in nb['cells']]\\n\"\n",
      " '    if exporter is None: exporter = nbdev_exporter(cls=cls, '\n",
      " 'template_file=template_file)\\n'\n",
      " \"    with open(_nb2htmlfname(fname, dest=dest),'w') as f:\\n\"\n",
      " '        f.write(exporter.from_notebook_node(nb, resources=meta_jekyll)[0])')\n",
      "code_lines: ['def _notebook2html(fname, cls=HTMLExporter, template_file=None, '\n",
      " 'exporter=None, dest=None, execute=True):',\n",
      " '    time.sleep(random.random())',\n",
      " '    print(f\"converting: {fname}\")',\n",
      " '    try:',\n",
      " '        convert_nb(fname, cls=cls, template_file=template_file, '\n",
      " 'exporter=exporter, dest=dest, execute=execute)',\n",
      " '        return True',\n",
      " '    except Exception as e:',\n",
      " '        print(e)',\n",
      " '        return False']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _notebook2html(fname, cls=HTMLExporter, template_file=None, '\n",
      " 'exporter=None, dest=None, execute=True):\\n'\n",
      " '    time.sleep(random.random())\\n'\n",
      " '    print(f\"converting: {fname}\")\\n'\n",
      " '    try:\\n'\n",
      " '        convert_nb(fname, cls=cls, template_file=template_file, '\n",
      " 'exporter=exporter, dest=dest, execute=execute)\\n'\n",
      " '        return True\\n'\n",
      " '    except Exception as e:\\n'\n",
      " '        print(e)\\n'\n",
      " '        return False')\n",
      "code_lines: ['def notebook2html(fname=None, force_all=False, n_workers=None, '\n",
      " 'cls=HTMLExporter, template_file=None,',\n",
      " '                  exporter=None, dest=None, pause=0, execute=True):',\n",
      " '    \"Convert all notebooks matching `fname` to html files\"',\n",
      " '    files = nbglob(fname)',\n",
      " '    if len(files)==1:',\n",
      " '        force_all = True',\n",
      " '        if n_workers is None: n_workers=0',\n",
      " '    if not force_all:',\n",
      " '        # only rebuild modified files',\n",
      " '        files,_files = [],files.copy()',\n",
      " '        for fname in _files:',\n",
      " '            fname_out = _nb2htmlfname(Path(fname).absolute(), dest=dest)',\n",
      " '            if not fname_out.exists() or os.path.getmtime(fname) >= '\n",
      " 'os.path.getmtime(fname_out):',\n",
      " '                files.append(fname)',\n",
      " '    if len(files)==0: print(\"No notebooks were modified\")',\n",
      " '    else:',\n",
      " '        if sys.platform == \"win32\": n_workers = 0',\n",
      " '        passed = parallel(_notebook2html, files, n_workers=n_workers, '\n",
      " 'cls=cls,',\n",
      " '                          template_file=template_file, exporter=exporter, '\n",
      " 'dest=dest, pause=pause, execute=execute)',\n",
      " '        if not all(passed):',\n",
      " '            msg = \"Conversion failed on the following:\\\\n\"',\n",
      " \"            print(msg + '\\\\n'.join([f.name for p,f in zip(passed,files) if \"\n",
      " 'not p]))']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def notebook2html(fname=None, force_all=False, n_workers=None, '\n",
      " 'cls=HTMLExporter, template_file=None,\\n'\n",
      " '                  exporter=None, dest=None, pause=0, execute=True):\\n'\n",
      " '    \"Convert all notebooks matching `fname` to html files\"\\n'\n",
      " '    files = nbglob(fname)\\n'\n",
      " '    if len(files)==1:\\n'\n",
      " '        force_all = True\\n'\n",
      " '        if n_workers is None: n_workers=0\\n'\n",
      " '    if not force_all:\\n'\n",
      " '        # only rebuild modified files\\n'\n",
      " '        files,_files = [],files.copy()\\n'\n",
      " '        for fname in _files:\\n'\n",
      " '            fname_out = _nb2htmlfname(Path(fname).absolute(), dest=dest)\\n'\n",
      " '            if not fname_out.exists() or os.path.getmtime(fname) >= '\n",
      " 'os.path.getmtime(fname_out):\\n'\n",
      " '                files.append(fname)\\n'\n",
      " '    if len(files)==0: print(\"No notebooks were modified\")\\n'\n",
      " '    else:\\n'\n",
      " '        if sys.platform == \"win32\": n_workers = 0\\n'\n",
      " '        passed = parallel(_notebook2html, files, n_workers=n_workers, '\n",
      " 'cls=cls,\\n'\n",
      " '                          template_file=template_file, exporter=exporter, '\n",
      " 'dest=dest, pause=pause, execute=execute)\\n'\n",
      " '        if not all(passed):\\n'\n",
      " '            msg = \"Conversion failed on the following:\\\\n\"\\n'\n",
      " \"            print(msg + '\\\\n'.join([f.name for p,f in zip(passed,files) if \"\n",
      " 'not p]))')\n",
      "code_lines: [\"def convert_md(fname, dest_path, img_path='docs/images/', jekyll=True):\",\n",
      " '    \"Convert a notebook `fname` to a markdown file in `dest_path`.\"',\n",
      " '    fname = Path(fname).absolute()',\n",
      " \"    if not img_path: img_path = fname.stem + '_files/'\",\n",
      " '    Path(img_path).mkdir(exist_ok=True, parents=True)',\n",
      " '    nb = read_nb(fname)',\n",
      " \"    meta_jekyll = get_metadata(nb['cells'])\",\n",
      " \"    try: meta_jekyll['nb_path'] = \"\n",
      " 'str(fname.relative_to(Config().path(\"lib_path\").parent))',\n",
      " \"    except: meta_jekyll['nb_path'] = str(fname)\",\n",
      " \"    nb['cells'] = compose(*process_cells)(nb['cells'])\",\n",
      " \"    nb['cells'] = [compose(partial(adapt_img_path, fname=fname, \"\n",
      " 'dest=dest_path, jekyll=jekyll), *process_cell)(c)',\n",
      " \"                   for c in nb['cells']]\",\n",
      " '    fname = Path(fname).absolute()',\n",
      " \"    dest_name = fname.with_suffix('.md').name\",\n",
      " \"    exp = nbdev_exporter(cls=MarkdownExporter, template_file='jekyll-md.tpl' \"\n",
      " \"if jekyll else 'md.tpl')\",\n",
      " '    export = exp.from_notebook_node(nb, resources=meta_jekyll)',\n",
      " '    md = export[0]',\n",
      " \"    for ext in ['png', 'svg']:\",\n",
      " \"        md = re.sub(r'!\\\\['+ext+'\\\\]\\\\((.+)\\\\)', '!['+ext+'](' + img_path + \"\n",
      " \"'\\\\\\\\1)', md)\",\n",
      " \"    with (Path(dest_path)/dest_name).open('w') as f: f.write(md)\",\n",
      " \"    if hasattr(export[1]['outputs'], 'items'):\",\n",
      " \"        for n,o in export[1]['outputs'].items():\",\n",
      " \"            with open(Path(dest_path)/img_path/n, 'wb') as f: f.write(o)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"def convert_md(fname, dest_path, img_path='docs/images/', jekyll=True):\\n\"\n",
      " '    \"Convert a notebook `fname` to a markdown file in `dest_path`.\"\\n'\n",
      " '    fname = Path(fname).absolute()\\n'\n",
      " \"    if not img_path: img_path = fname.stem + '_files/'\\n\"\n",
      " '    Path(img_path).mkdir(exist_ok=True, parents=True)\\n'\n",
      " '    nb = read_nb(fname)\\n'\n",
      " \"    meta_jekyll = get_metadata(nb['cells'])\\n\"\n",
      " \"    try: meta_jekyll['nb_path'] = \"\n",
      " 'str(fname.relative_to(Config().path(\"lib_path\").parent))\\n'\n",
      " \"    except: meta_jekyll['nb_path'] = str(fname)\\n\"\n",
      " \"    nb['cells'] = compose(*process_cells)(nb['cells'])\\n\"\n",
      " \"    nb['cells'] = [compose(partial(adapt_img_path, fname=fname, \"\n",
      " 'dest=dest_path, jekyll=jekyll), *process_cell)(c)\\n'\n",
      " \"                   for c in nb['cells']]\\n\"\n",
      " '    fname = Path(fname).absolute()\\n'\n",
      " \"    dest_name = fname.with_suffix('.md').name\\n\"\n",
      " \"    exp = nbdev_exporter(cls=MarkdownExporter, template_file='jekyll-md.tpl' \"\n",
      " \"if jekyll else 'md.tpl')\\n\"\n",
      " '    export = exp.from_notebook_node(nb, resources=meta_jekyll)\\n'\n",
      " '    md = export[0]\\n'\n",
      " \"    for ext in ['png', 'svg']:\\n\"\n",
      " \"        md = re.sub(r'!\\\\['+ext+'\\\\]\\\\((.+)\\\\)', '!['+ext+'](' + img_path + \"\n",
      " \"'\\\\\\\\1)', md)\\n\"\n",
      " \"    with (Path(dest_path)/dest_name).open('w') as f: f.write(md)\\n\"\n",
      " \"    if hasattr(export[1]['outputs'], 'items'):\\n\"\n",
      " \"        for n,o in export[1]['outputs'].items():\\n\"\n",
      " \"            with open(Path(dest_path)/img_path/n, 'wb') as f: f.write(o)\")\n",
      "code_lines: [\"_re_att_ref = re.compile(r' *!\\\\[(.*)\\\\]\\\\(attachment:image.png(?: \"\n",
      " '\"(.*)\")?\\\\)\\')']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_re_att_ref = re.compile(r' *!\\\\[(.*)\\\\]\\\\(attachment:image.png(?: \"\n",
      " '\"(.*)\")?\\\\)\\')')\n",
      "code_lines: ['try: from PIL import Image',\n",
      " 'except: pass # Only required for _update_att_ref']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'try: from PIL import Image\\n'\n",
      " 'except: pass # Only required for _update_att_ref')\n",
      "code_lines: ['_tmpl_img = \\'<img alt=\"{title}\" width=\"{width}\" caption=\"{title}\" id=\"{id}\" '\n",
      " 'src=\"{name}\">\\'',\n",
      " '',\n",
      " 'def _update_att_ref(line, path, img):',\n",
      " '    m = _re_att_ref.match(line)',\n",
      " '    if not m: return line',\n",
      " '    alt,title = m.groups()',\n",
      " '    w = img.size[0]',\n",
      " \"    if alt=='screenshot': w //= 2\",\n",
      " '    if not title: title = \"TK: add title\"',\n",
      " \"    return _tmpl_img.format(title=title, width=str(w), id='TK: add it', \"\n",
      " 'name=str(path))']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_tmpl_img = \\'<img alt=\"{title}\" width=\"{width}\" caption=\"{title}\" id=\"{id}\" '\n",
      " 'src=\"{name}\">\\'\\n'\n",
      " '\\n'\n",
      " 'def _update_att_ref(line, path, img):\\n'\n",
      " '    m = _re_att_ref.match(line)\\n'\n",
      " '    if not m: return line\\n'\n",
      " '    alt,title = m.groups()\\n'\n",
      " '    w = img.size[0]\\n'\n",
      " \"    if alt=='screenshot': w //= 2\\n\"\n",
      " '    if not title: title = \"TK: add title\"\\n'\n",
      " \"    return _tmpl_img.format(title=title, width=str(w), id='TK: add it', \"\n",
      " 'name=str(path))')\n",
      "code_lines: ['def _nb_detach_cell(cell, dest, use_img):',\n",
      " \"    att,src = cell['attachments'],cell['source']\",\n",
      " '    mime,img = first(first(att.values()).items())',\n",
      " \"    ext = mime.split('/')[1]\",\n",
      " '    for i in range(99999):',\n",
      " \"        p = dest/(f'att_{i:05d}.{ext}')\",\n",
      " '        if not p.exists(): break',\n",
      " '    img = b64decode(img)',\n",
      " '    p.write_bytes(img)',\n",
      " \"    del(cell['attachments'])\",\n",
      " '    if use_img:  return [_update_att_ref(o,p,Image.open(p)) for o in src]',\n",
      " \"    else: return [o.replace('attachment:image.png', str(p)) for o in src]\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _nb_detach_cell(cell, dest, use_img):\\n'\n",
      " \"    att,src = cell['attachments'],cell['source']\\n\"\n",
      " '    mime,img = first(first(att.values()).items())\\n'\n",
      " \"    ext = mime.split('/')[1]\\n\"\n",
      " '    for i in range(99999):\\n'\n",
      " \"        p = dest/(f'att_{i:05d}.{ext}')\\n\"\n",
      " '        if not p.exists(): break\\n'\n",
      " '    img = b64decode(img)\\n'\n",
      " '    p.write_bytes(img)\\n'\n",
      " \"    del(cell['attachments'])\\n\"\n",
      " '    if use_img:  return [_update_att_ref(o,p,Image.open(p)) for o in src]\\n'\n",
      " \"    else: return [o.replace('attachment:image.png', str(p)) for o in src]\")\n",
      "code_lines: ['def _nbdev_detach(path_nb, dest=\"\", use_img=False, replace=True):',\n",
      " '    path_nb = Path(path_nb)',\n",
      " \"    if not dest: dest = f'{path_nb.stem}_files'\",\n",
      " '    dest = Path(dest)',\n",
      " '    dest.mkdir(exist_ok=True, parents=True)',\n",
      " '    j = json.load(path_nb.open())',\n",
      " \"    atts = [o for o in j['cells'] if 'attachments' in o]\",\n",
      " \"    for o in atts: o['source'] = _nb_detach_cell(o, dest, use_img)\",\n",
      " \"    if atts and replace: json.dump(j, path_nb.open('w'))\",\n",
      " '    if not replace: return j',\n",
      " '',\n",
      " '@call_parse',\n",
      " 'def nbdev_detach(path_nb:Param(\"Path to notebook\"),',\n",
      " '                 dest:Param(\"Destination folder\", str)=\"\",',\n",
      " '                 use_img:Param(\"Convert markdown images to img tags\", '\n",
      " 'bool_arg)=False,',\n",
      " '                 replace:Param(\"Write replacement notebook back to '\n",
      " '`path_bn`\", bool_arg)=True):',\n",
      " '    \"Export cell attachments to `dest` and update references\"',\n",
      " '    _nbdev_detach(path_nb, dest, use_img, replace)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _nbdev_detach(path_nb, dest=\"\", use_img=False, replace=True):\\n'\n",
      " '    path_nb = Path(path_nb)\\n'\n",
      " \"    if not dest: dest = f'{path_nb.stem}_files'\\n\"\n",
      " '    dest = Path(dest)\\n'\n",
      " '    dest.mkdir(exist_ok=True, parents=True)\\n'\n",
      " '    j = json.load(path_nb.open())\\n'\n",
      " \"    atts = [o for o in j['cells'] if 'attachments' in o]\\n\"\n",
      " \"    for o in atts: o['source'] = _nb_detach_cell(o, dest, use_img)\\n\"\n",
      " \"    if atts and replace: json.dump(j, path_nb.open('w'))\\n\"\n",
      " '    if not replace: return j\\n'\n",
      " '\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_detach(path_nb:Param(\"Path to notebook\"),\\n'\n",
      " '                 dest:Param(\"Destination folder\", str)=\"\",\\n'\n",
      " '                 use_img:Param(\"Convert markdown images to img tags\", '\n",
      " 'bool_arg)=False,\\n'\n",
      " '                 replace:Param(\"Write replacement notebook back to '\n",
      " '`path_bn`\", bool_arg)=True):\\n'\n",
      " '    \"Export cell attachments to `dest` and update references\"\\n'\n",
      " '    _nbdev_detach(path_nb, dest, use_img, replace)')\n",
      "code_lines: [\"_re_index = re.compile(r'^(?:\\\\d*_|)index\\\\.ipynb$')\"]\n",
      "code: \"\\n\\n# Cell\\n_re_index = re.compile(r'^(?:\\\\d*_|)index\\\\.ipynb$')\"\n",
      "code_lines: ['def make_readme():',\n",
      " '    \"Convert the index notebook to README.md\"',\n",
      " '    index_fn = None',\n",
      " '    for f in Config().path(\"nbs_path\").glob(\\'*.ipynb\\'):',\n",
      " '        if _re_index.match(f.name): index_fn = f',\n",
      " '    assert index_fn is not None, \"Could not locate index notebook\"',\n",
      " '    print(f\"converting {index_fn} to README.md\")',\n",
      " '    convert_md(index_fn, Config().config_file.parent, jekyll=False)',\n",
      " \"    n = Config().config_file.parent/index_fn.with_suffix('.md').name\",\n",
      " \"    shutil.move(n, Config().config_file.parent/'README.md')\",\n",
      " \"    if Path(Config().config_file.parent/'PRE_README.md').is_file():\",\n",
      " \"        with open(Config().config_file.parent/'README.md', 'r') as f: readme \"\n",
      " '= f.read()',\n",
      " \"        with open(Config().config_file.parent/'PRE_README.md', 'r') as f: \"\n",
      " 'pre_readme = f.read()',\n",
      " \"        with open(Config().config_file.parent/'README.md', 'w') as f: \"\n",
      " \"f.write(f'{pre_readme}\\\\n{readme}')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def make_readme():\\n'\n",
      " '    \"Convert the index notebook to README.md\"\\n'\n",
      " '    index_fn = None\\n'\n",
      " '    for f in Config().path(\"nbs_path\").glob(\\'*.ipynb\\'):\\n'\n",
      " '        if _re_index.match(f.name): index_fn = f\\n'\n",
      " '    assert index_fn is not None, \"Could not locate index notebook\"\\n'\n",
      " '    print(f\"converting {index_fn} to README.md\")\\n'\n",
      " '    convert_md(index_fn, Config().config_file.parent, jekyll=False)\\n'\n",
      " \"    n = Config().config_file.parent/index_fn.with_suffix('.md').name\\n\"\n",
      " \"    shutil.move(n, Config().config_file.parent/'README.md')\\n\"\n",
      " \"    if Path(Config().config_file.parent/'PRE_README.md').is_file():\\n\"\n",
      " \"        with open(Config().config_file.parent/'README.md', 'r') as f: readme \"\n",
      " '= f.read()\\n'\n",
      " \"        with open(Config().config_file.parent/'PRE_README.md', 'r') as f: \"\n",
      " 'pre_readme = f.read()\\n'\n",
      " \"        with open(Config().config_file.parent/'README.md', 'w') as f: \"\n",
      " \"f.write(f'{pre_readme}\\\\n{readme}')\")\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_build_docs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,',\n",
      " '                     force_all:Param(\"Rebuild even notebooks that haven\\'t '\n",
      " 'changed\", bool_arg)=False,',\n",
      " '                     mk_readme:Param(\"Also convert the index notebook to '\n",
      " 'README\", bool_arg)=True,',\n",
      " '                     n_workers:Param(\"Number of workers to use\", int)=None,',\n",
      " '                     pause:Param(\"Pause time (in secs) between notebooks to '\n",
      " 'avoid race conditions\", float)=0.5):',\n",
      " '    \"Build the documentation by converting notebooks matching `fname` to '\n",
      " 'html\"',\n",
      " '    notebook2html(fname=fname, force_all=force_all, n_workers=n_workers, '\n",
      " 'pause=pause)',\n",
      " '    if fname is None: make_sidebar()',\n",
      " '    if mk_readme: make_readme()']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_build_docs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,\\n'\n",
      " '                     force_all:Param(\"Rebuild even notebooks that haven\\'t '\n",
      " 'changed\", bool_arg)=False,\\n'\n",
      " '                     mk_readme:Param(\"Also convert the index notebook to '\n",
      " 'README\", bool_arg)=True,\\n'\n",
      " '                     n_workers:Param(\"Number of workers to use\", int)=None,\\n'\n",
      " '                     pause:Param(\"Pause time (in secs) between notebooks to '\n",
      " 'avoid race conditions\", float)=0.5):\\n'\n",
      " '    \"Build the documentation by converting notebooks matching `fname` to '\n",
      " 'html\"\\n'\n",
      " '    notebook2html(fname=fname, force_all=force_all, n_workers=n_workers, '\n",
      " 'pause=pause)\\n'\n",
      " '    if fname is None: make_sidebar()\\n'\n",
      " '    if mk_readme: make_readme()')\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_nb2md(fname:Param(\"A notebook file name to convert\", str),',\n",
      " '                dest:Param(\"The destination folder\", str)=\\'.\\',',\n",
      " '                img_path:Param(\"Folder to export images to\")=\"\",',\n",
      " '                jekyll:Param(\"To use jekyll metadata for your markdown file '\n",
      " 'or not\", bool_arg)=False,):',\n",
      " '    \"Convert the notebook in `fname` to a markdown file\"',\n",
      " '    _nbdev_detach(fname, dest=img_path)',\n",
      " '    convert_md(fname, dest, jekyll=jekyll, img_path=img_path)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_nb2md(fname:Param(\"A notebook file name to convert\", str),\\n'\n",
      " '                dest:Param(\"The destination folder\", str)=\\'.\\',\\n'\n",
      " '                img_path:Param(\"Folder to export images to\")=\"\",\\n'\n",
      " '                jekyll:Param(\"To use jekyll metadata for your markdown file '\n",
      " 'or not\", bool_arg)=False,):\\n'\n",
      " '    \"Convert the notebook in `fname` to a markdown file\"\\n'\n",
      " '    _nbdev_detach(fname, dest=img_path)\\n'\n",
      " '    convert_md(fname, dest, jekyll=jekyll, img_path=img_path)')\n",
      "code_lines: ['import time,random,warnings']\n",
      "code: '\\n\\n# Cell\\nimport time,random,warnings'\n",
      "code_lines: ['def _leaf(k,v):',\n",
      " '    url = \\'external_url\\' if \"http\" in v else \\'url\\'',\n",
      " \"    #if url=='url': v=v+'.html'\",\n",
      " \"    return {'title':k, url:v, 'output':'web,pdf'}\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _leaf(k,v):\\n'\n",
      " '    url = \\'external_url\\' if \"http\" in v else \\'url\\'\\n'\n",
      " \"    #if url=='url': v=v+'.html'\\n\"\n",
      " \"    return {'title':k, url:v, 'output':'web,pdf'}\")\n",
      "code_lines: [\"_k_names = ['folders', 'folderitems', 'subfolders', 'subfolderitems']\",\n",
      " 'def _side_dict(title, data, level=0):',\n",
      " '    k_name = _k_names[level]',\n",
      " '    level += 1',\n",
      " '    res = [(_side_dict(k, v, level) if isinstance(v,dict) else _leaf(k,v))',\n",
      " '        for k,v in data.items()]',\n",
      " '    return ({k_name:res} if not title',\n",
      " \"            else res if title.startswith('empty')\",\n",
      " \"            else {'title': title, 'output':'web', k_name: res})\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_k_names = ['folders', 'folderitems', 'subfolders', 'subfolderitems']\\n\"\n",
      " 'def _side_dict(title, data, level=0):\\n'\n",
      " '    k_name = _k_names[level]\\n'\n",
      " '    level += 1\\n'\n",
      " '    res = [(_side_dict(k, v, level) if isinstance(v,dict) else _leaf(k,v))\\n'\n",
      " '        for k,v in data.items()]\\n'\n",
      " '    return ({k_name:res} if not title\\n'\n",
      " \"            else res if title.startswith('empty')\\n\"\n",
      " \"            else {'title': title, 'output':'web', k_name: res})\")\n",
      "code_lines: [\"_re_catch_title = re.compile('^title\\\\s*:\\\\s*(\\\\S+.*)$', re.MULTILINE)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"_re_catch_title = re.compile('^title\\\\s*:\\\\s*(\\\\S+.*)$', re.MULTILINE)\")\n",
      "code_lines: ['def _get_title(fname):',\n",
      " '    \"Grabs the title of html file `fname`\"',\n",
      " \"    with open(fname, 'r') as f: code = f.read()\",\n",
      " '    src =  _re_catch_title.search(code)',\n",
      " '    return fname.stem if src is None else src.groups()[0]']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _get_title(fname):\\n'\n",
      " '    \"Grabs the title of html file `fname`\"\\n'\n",
      " \"    with open(fname, 'r') as f: code = f.read()\\n\"\n",
      " '    src =  _re_catch_title.search(code)\\n'\n",
      " '    return fname.stem if src is None else src.groups()[0]')\n",
      "code_lines: ['def _create_default_sidebar():',\n",
      " '    \"Create the default sidebar for the docs website\"',\n",
      " '    dic = {\"Overview\": \"/\"}',\n",
      " '    files = nbglob()',\n",
      " '    fnames = [_nb2htmlfname(f) for f in sorted(files)]',\n",
      " \"    titles = [_get_title(f) for f in fnames if f.stem!='index']\",\n",
      " '    if len(titles) > len(set(titles)): print(f\"Warning: Some of your '\n",
      " 'Notebooks use the same title ({titles}).\")',\n",
      " \"    dic.update({_get_title(f):f.name if Config().host=='github' else \"\n",
      " \"f.with_suffix('').name for f in fnames if f.stem!='index'})\",\n",
      " '    return dic']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _create_default_sidebar():\\n'\n",
      " '    \"Create the default sidebar for the docs website\"\\n'\n",
      " '    dic = {\"Overview\": \"/\"}\\n'\n",
      " '    files = nbglob()\\n'\n",
      " '    fnames = [_nb2htmlfname(f) for f in sorted(files)]\\n'\n",
      " \"    titles = [_get_title(f) for f in fnames if f.stem!='index']\\n\"\n",
      " '    if len(titles) > len(set(titles)): print(f\"Warning: Some of your '\n",
      " 'Notebooks use the same title ({titles}).\")\\n'\n",
      " \"    dic.update({_get_title(f):f.name if Config().host=='github' else \"\n",
      " \"f.with_suffix('').name for f in fnames if f.stem!='index'})\\n\"\n",
      " '    return dic')\n",
      "code_lines: ['def create_default_sidebar():',\n",
      " '    \"Create the default sidebar for the docs website\"',\n",
      " '    dic = {Config().lib_name: _create_default_sidebar()}',\n",
      " '    json.dump(dic, open(Config().path(\"doc_path\")/\\'sidebar.json\\', \\'w\\'), '\n",
      " 'indent=2)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def create_default_sidebar():\\n'\n",
      " '    \"Create the default sidebar for the docs website\"\\n'\n",
      " '    dic = {Config().lib_name: _create_default_sidebar()}\\n'\n",
      " '    json.dump(dic, open(Config().path(\"doc_path\")/\\'sidebar.json\\', \\'w\\'), '\n",
      " 'indent=2)')\n",
      "code_lines: ['def make_sidebar():',\n",
      " '    \"Making sidebar for the doc website form the content of '\n",
      " '`doc_folder/sidebar.json`\"',\n",
      " '    cfg = Config()',\n",
      " '    if not (cfg.path(\"doc_path\")/\\'sidebar.json\\').exists() or '\n",
      " \"cfg.get('custom_sidebar', 'False') == 'False':\",\n",
      " '        create_default_sidebar()',\n",
      " '    sidebar_d = json.load(open(cfg.path(\"doc_path\")/\\'sidebar.json\\', '\n",
      " \"'r'))\",\n",
      " \"    res = _side_dict('Sidebar', sidebar_d)\",\n",
      " \"    res = {'entries': [res]}\",\n",
      " '    res_s = yaml.dump(res, default_flow_style=False)',\n",
      " \"    res_s = res_s.replace('- subfolders:', '  subfolders:').replace(' - - ', \"\n",
      " \"'   - ')\",\n",
      " '    res_s = f\"\"\"',\n",
      " '#################################################',\n",
      " '### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###',\n",
      " '#################################################',\n",
      " \"# Instead edit {'../../sidebar.json'}\",\n",
      " '\"\"\"+res_s',\n",
      " '    pth = cfg.path(\"doc_path\")/\\'_data/sidebars/home_sidebar.yml\\'',\n",
      " '    pth.mk_write(res_s)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def make_sidebar():\\n'\n",
      " '    \"Making sidebar for the doc website form the content of '\n",
      " '`doc_folder/sidebar.json`\"\\n'\n",
      " '    cfg = Config()\\n'\n",
      " '    if not (cfg.path(\"doc_path\")/\\'sidebar.json\\').exists() or '\n",
      " \"cfg.get('custom_sidebar', 'False') == 'False':\\n\"\n",
      " '        create_default_sidebar()\\n'\n",
      " '    sidebar_d = json.load(open(cfg.path(\"doc_path\")/\\'sidebar.json\\', '\n",
      " \"'r'))\\n\"\n",
      " \"    res = _side_dict('Sidebar', sidebar_d)\\n\"\n",
      " \"    res = {'entries': [res]}\\n\"\n",
      " '    res_s = yaml.dump(res, default_flow_style=False)\\n'\n",
      " \"    res_s = res_s.replace('- subfolders:', '  subfolders:').replace(' - - ', \"\n",
      " \"'   - ')\\n\"\n",
      " '    res_s = f\"\"\"\\n'\n",
      " '#################################################\\n'\n",
      " '### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\\n'\n",
      " '#################################################\\n'\n",
      " \"# Instead edit {'../../sidebar.json'}\\n\"\n",
      " '\"\"\"+res_s\\n'\n",
      " '    pth = cfg.path(\"doc_path\")/\\'_data/sidebars/home_sidebar.yml\\'\\n'\n",
      " '    pth.mk_write(res_s)')\n",
      "Converted 03_export2html.ipynb.\n",
      "code_lines: ['from .imports import *',\n",
      " 'from .sync import *',\n",
      " 'from .export import *',\n",
      " 'from .export import _mk_flag_re',\n",
      " 'from .export2html import _re_notebook2script',\n",
      " 'from fastcore.script import *',\n",
      " '',\n",
      " 'from nbconvert.preprocessors import ExecutePreprocessor',\n",
      " 'import nbformat']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'from .imports import *\\n'\n",
      " 'from .sync import *\\n'\n",
      " 'from .export import *\\n'\n",
      " 'from .export import _mk_flag_re\\n'\n",
      " 'from .export2html import _re_notebook2script\\n'\n",
      " 'from fastcore.script import *\\n'\n",
      " '\\n'\n",
      " 'from nbconvert.preprocessors import ExecutePreprocessor\\n'\n",
      " 'import nbformat')\n",
      "code_lines: ['class _ReTstFlags():',\n",
      " '    \"Test flag matching regular expressions\"',\n",
      " '    def __init__(self, all_flag):',\n",
      " '        \"match flags applied to all cells?\"',\n",
      " '        self.all_flag = all_flag',\n",
      " '',\n",
      " '    def _deferred_init(self):',\n",
      " '        \"Compile at first use but not before since patterns need '\n",
      " '`Config().tst_flags`\"',\n",
      " \"        if hasattr(self, '_re'): return\",\n",
      " \"        tst_flags = Config().get('tst_flags', '')\",\n",
      " \"        tst_flags += f'|skip' if tst_flags else 'skip'\",\n",
      " \"        _re_all = 'all_' if self.all_flag else ''\",\n",
      " '        self._re = _mk_flag_re(f\"{_re_all}({tst_flags})\", 0, \"Any line with '\n",
      " 'a test flag\")',\n",
      " '',\n",
      " '    def findall(self, source):',\n",
      " '        self._deferred_init()',\n",
      " '        return self._re.findall(source)',\n",
      " '',\n",
      " '    def search(self, source):',\n",
      " '        self._deferred_init()',\n",
      " '        return self._re.search(source)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'class _ReTstFlags():\\n'\n",
      " '    \"Test flag matching regular expressions\"\\n'\n",
      " '    def __init__(self, all_flag):\\n'\n",
      " '        \"match flags applied to all cells?\"\\n'\n",
      " '        self.all_flag = all_flag\\n'\n",
      " '\\n'\n",
      " '    def _deferred_init(self):\\n'\n",
      " '        \"Compile at first use but not before since patterns need '\n",
      " '`Config().tst_flags`\"\\n'\n",
      " \"        if hasattr(self, '_re'): return\\n\"\n",
      " \"        tst_flags = Config().get('tst_flags', '')\\n\"\n",
      " \"        tst_flags += f'|skip' if tst_flags else 'skip'\\n\"\n",
      " \"        _re_all = 'all_' if self.all_flag else ''\\n\"\n",
      " '        self._re = _mk_flag_re(f\"{_re_all}({tst_flags})\", 0, \"Any line with '\n",
      " 'a test flag\")\\n'\n",
      " '\\n'\n",
      " '    def findall(self, source):\\n'\n",
      " '        self._deferred_init()\\n'\n",
      " '        return self._re.findall(source)\\n'\n",
      " '\\n'\n",
      " '    def search(self, source):\\n'\n",
      " '        self._deferred_init()\\n'\n",
      " '        return self._re.search(source)')\n",
      "code_lines: ['_re_all_flag = _ReTstFlags(True)']\n",
      "code: '\\n\\n# Cell\\n_re_all_flag = _ReTstFlags(True)'\n",
      "code_lines: ['def get_all_flags(cells):',\n",
      " '    \"Check for all test flags in `cells`\"',\n",
      " '    result = []',\n",
      " '    for cell in cells:',\n",
      " \"        if cell['cell_type'] == 'code': \"\n",
      " \"result.extend(_re_all_flag.findall(cell['source']))\",\n",
      " '    return set(result)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def get_all_flags(cells):\\n'\n",
      " '    \"Check for all test flags in `cells`\"\\n'\n",
      " '    result = []\\n'\n",
      " '    for cell in cells:\\n'\n",
      " \"        if cell['cell_type'] == 'code': \"\n",
      " \"result.extend(_re_all_flag.findall(cell['source']))\\n\"\n",
      " '    return set(result)')\n",
      "code_lines: ['_re_flags = _ReTstFlags(False)']\n",
      "code: '\\n\\n# Cell\\n_re_flags = _ReTstFlags(False)'\n",
      "code_lines: ['def get_cell_flags(cell):',\n",
      " '    \"Check for any special test flag in `cell`\"',\n",
      " \"    if cell['cell_type'] != 'code' or len(Config().get('tst_flags',''))==0: \"\n",
      " 'return []',\n",
      " \"    return _re_flags.findall(cell['source'])\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def get_cell_flags(cell):\\n'\n",
      " '    \"Check for any special test flag in `cell`\"\\n'\n",
      " \"    if cell['cell_type'] != 'code' or len(Config().get('tst_flags',''))==0: \"\n",
      " 'return []\\n'\n",
      " \"    return _re_flags.findall(cell['source'])\")\n",
      "code_lines: ['class NoExportPreprocessor(ExecutePreprocessor):',\n",
      " '    \"An `ExecutePreprocessor` that executes cells that don\\'t have a flag in '\n",
      " '`flags`\"',\n",
      " '    def __init__(self, flags, **kwargs):',\n",
      " '        self.flags = flags',\n",
      " '        super().__init__(**kwargs)',\n",
      " '',\n",
      " '    def preprocess_cell(self, cell, resources, index):',\n",
      " '        if \\'source\\' not in cell or cell[\\'cell_type\\'] != \"code\": return '\n",
      " 'cell, resources',\n",
      " '        for f in get_cell_flags(cell):',\n",
      " '            if f not in self.flags: return cell, resources',\n",
      " '        if check_re(cell, _re_notebook2script): return cell, resources',\n",
      " '        return super().preprocess_cell(cell, resources, index)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'class NoExportPreprocessor(ExecutePreprocessor):\\n'\n",
      " '    \"An `ExecutePreprocessor` that executes cells that don\\'t have a flag in '\n",
      " '`flags`\"\\n'\n",
      " '    def __init__(self, flags, **kwargs):\\n'\n",
      " '        self.flags = flags\\n'\n",
      " '        super().__init__(**kwargs)\\n'\n",
      " '\\n'\n",
      " '    def preprocess_cell(self, cell, resources, index):\\n'\n",
      " '        if \\'source\\' not in cell or cell[\\'cell_type\\'] != \"code\": return '\n",
      " 'cell, resources\\n'\n",
      " '        for f in get_cell_flags(cell):\\n'\n",
      " '            if f not in self.flags: return cell, resources\\n'\n",
      " '        if check_re(cell, _re_notebook2script): return cell, resources\\n'\n",
      " '        return super().preprocess_cell(cell, resources, index)')\n",
      "code_lines: ['def test_nb(fn, flags=None):',\n",
      " '    \"Execute tests in notebook in `fn` with `flags`\"',\n",
      " '    os.environ[\"IN_TEST\"] = \\'1\\'',\n",
      " '    if flags is None: flags = []',\n",
      " '    try:',\n",
      " '        nb = read_nb(fn)',\n",
      " \"        for f in get_all_flags(nb['cells']):\",\n",
      " '            if f not in flags: return',\n",
      " \"        ep = NoExportPreprocessor(flags, timeout=600, kernel_name='python3')\",\n",
      " '        pnb = nbformat.from_dict(nb)',\n",
      " '        ep.preprocess(pnb)',\n",
      " '    finally: os.environ.pop(\"IN_TEST\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def test_nb(fn, flags=None):\\n'\n",
      " '    \"Execute tests in notebook in `fn` with `flags`\"\\n'\n",
      " '    os.environ[\"IN_TEST\"] = \\'1\\'\\n'\n",
      " '    if flags is None: flags = []\\n'\n",
      " '    try:\\n'\n",
      " '        nb = read_nb(fn)\\n'\n",
      " \"        for f in get_all_flags(nb['cells']):\\n\"\n",
      " '            if f not in flags: return\\n'\n",
      " '        ep = NoExportPreprocessor(flags, timeout=600, '\n",
      " \"kernel_name='python3')\\n\"\n",
      " '        pnb = nbformat.from_dict(nb)\\n'\n",
      " '        ep.preprocess(pnb)\\n'\n",
      " '    finally: os.environ.pop(\"IN_TEST\")')\n",
      "code_lines: ['def _test_one(fname, flags=None, verbose=True):',\n",
      " '    print(f\"testing {fname}\")',\n",
      " '    start = time.time()',\n",
      " '    try:',\n",
      " '        test_nb(fname, flags=flags)',\n",
      " '        return True,time.time()-start',\n",
      " '    except Exception as e:',\n",
      " '        if \"ZMQError\" in str(e): _test_one(item, flags=flags, '\n",
      " 'verbose=verbose)',\n",
      " \"        if verbose: print(f'Error in {fname}:\\\\n{e}')\",\n",
      " '        return False,time.time()-start']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _test_one(fname, flags=None, verbose=True):\\n'\n",
      " '    print(f\"testing {fname}\")\\n'\n",
      " '    start = time.time()\\n'\n",
      " '    try:\\n'\n",
      " '        test_nb(fname, flags=flags)\\n'\n",
      " '        return True,time.time()-start\\n'\n",
      " '    except Exception as e:\\n'\n",
      " '        if \"ZMQError\" in str(e): _test_one(item, flags=flags, '\n",
      " 'verbose=verbose)\\n'\n",
      " \"        if verbose: print(f'Error in {fname}:\\\\n{e}')\\n\"\n",
      " '        return False,time.time()-start')\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_test_nbs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,',\n",
      " '                   flags:Param(\"Space separated list of flags\", str)=None,',\n",
      " '                   n_workers:Param(\"Number of workers to use\", int)=None,',\n",
      " '                   verbose:Param(\"Print errors along the way\", bool)=True,',\n",
      " '                   timing:Param(\"Timing each notebook to see the ones are '\n",
      " 'slow\", bool)=False,',\n",
      " '                   pause:Param(\"Pause time (in secs) between notebooks to '\n",
      " 'avoid race conditions\", float)=0.5):',\n",
      " '    \"Test in parallel the notebooks matching `fname`, passing along `flags`\"',\n",
      " \"    if flags is not None: flags = flags.split(' ')\",\n",
      " '    files = nbglob(fname)',\n",
      " '    files = [Path(f).absolute() for f in sorted(files)]',\n",
      " '    assert len(files) > 0, \"No files to test found.\"',\n",
      " '    if n_workers is None: n_workers = 0 if len(files)==1 else '\n",
      " 'min(num_cpus(), 8)',\n",
      " '    # make sure we are inside the notebook folder of the project',\n",
      " '    os.chdir(Config().path(\"nbs_path\"))',\n",
      " '    results = parallel(_test_one, files, flags=flags, verbose=verbose, '\n",
      " 'n_workers=n_workers, pause=pause)',\n",
      " '    passed,times = [r[0] for r in results],[r[1] for r in results]',\n",
      " '    if all(passed): print(\"All tests are passing!\")',\n",
      " '    else:',\n",
      " '        msg = \"The following notebooks failed:\\\\n\"',\n",
      " \"        raise Exception(msg + '\\\\n'.join([f.name for p,f in \"\n",
      " 'zip(passed,files) if not p]))',\n",
      " '    if timing:',\n",
      " '        for i,t in sorted(enumerate(times), key=lambda o:o[1], '\n",
      " 'reverse=True):',\n",
      " '            print(f\"Notebook {files[i].name} took {int(t)} seconds\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_test_nbs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,\\n'\n",
      " '                   flags:Param(\"Space separated list of flags\", str)=None,\\n'\n",
      " '                   n_workers:Param(\"Number of workers to use\", int)=None,\\n'\n",
      " '                   verbose:Param(\"Print errors along the way\", bool)=True,\\n'\n",
      " '                   timing:Param(\"Timing each notebook to see the ones are '\n",
      " 'slow\", bool)=False,\\n'\n",
      " '                   pause:Param(\"Pause time (in secs) between notebooks to '\n",
      " 'avoid race conditions\", float)=0.5):\\n'\n",
      " '    \"Test in parallel the notebooks matching `fname`, passing along '\n",
      " '`flags`\"\\n'\n",
      " \"    if flags is not None: flags = flags.split(' ')\\n\"\n",
      " '    files = nbglob(fname)\\n'\n",
      " '    files = [Path(f).absolute() for f in sorted(files)]\\n'\n",
      " '    assert len(files) > 0, \"No files to test found.\"\\n'\n",
      " '    if n_workers is None: n_workers = 0 if len(files)==1 else '\n",
      " 'min(num_cpus(), 8)\\n'\n",
      " '    # make sure we are inside the notebook folder of the project\\n'\n",
      " '    os.chdir(Config().path(\"nbs_path\"))\\n'\n",
      " '    results = parallel(_test_one, files, flags=flags, verbose=verbose, '\n",
      " 'n_workers=n_workers, pause=pause)\\n'\n",
      " '    passed,times = [r[0] for r in results],[r[1] for r in results]\\n'\n",
      " '    if all(passed): print(\"All tests are passing!\")\\n'\n",
      " '    else:\\n'\n",
      " '        msg = \"The following notebooks failed:\\\\n\"\\n'\n",
      " \"        raise Exception(msg + '\\\\n'.join([f.name for p,f in \"\n",
      " 'zip(passed,files) if not p]))\\n'\n",
      " '    if timing:\\n'\n",
      " '        for i,t in sorted(enumerate(times), key=lambda o:o[1], '\n",
      " 'reverse=True):\\n'\n",
      " '            print(f\"Notebook {files[i].name} took {int(t)} seconds\")')\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_read_nbs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None):',\n",
      " '    \"Check all notebooks matching `fname` can be opened\"',\n",
      " '    files = nbglob(fname)',\n",
      " '    for nb in files:',\n",
      " '        try: _ = read_nb(nb)',\n",
      " '        except Exception as e:',\n",
      " '            print(f\"{nb} is corrupted and can\\'t be opened.\")',\n",
      " '            raise e']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_read_nbs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None):\\n'\n",
      " '    \"Check all notebooks matching `fname` can be opened\"\\n'\n",
      " '    files = nbglob(fname)\\n'\n",
      " '    for nb in files:\\n'\n",
      " '        try: _ = read_nb(nb)\\n'\n",
      " '        except Exception as e:\\n'\n",
      " '            print(f\"{nb} is corrupted and can\\'t be opened.\")\\n'\n",
      " '            raise e')\n",
      "Converted 04_test.ipynb.\n",
      "code_lines: ['from .imports import *', 'from fastcore.script import *']\n",
      "code: '\\n\\n# Cell\\nfrom .imports import *\\nfrom fastcore.script import *'\n",
      "code_lines: ['def extract_cells(raw_txt):',\n",
      " '    \"Manually extract cells in potential broken json `raw_txt`\"',\n",
      " \"    lines = raw_txt.split('\\\\n')\",\n",
      " '    cells = []',\n",
      " '    i = 0',\n",
      " '    while not lines[i].startswith(\\' \"cells\"\\'): i+=1',\n",
      " '    i += 1',\n",
      " \"    start = '\\\\n'.join(lines[:i])\",\n",
      " \"    while lines[i] != ' ],':\",\n",
      " \"        while lines[i] != '  {': i+=1\",\n",
      " '        j = i',\n",
      " \"        while not lines[j].startswith('  }'): j+=1\",\n",
      " \"        c = '\\\\n'.join(lines[i:j+1])\",\n",
      " \"        if not c.endswith(','): c = c + ','\",\n",
      " '        cells.append(c)',\n",
      " '        i = j+1',\n",
      " \"    end = '\\\\n'.join(lines[i:])\",\n",
      " '    return start,cells,end']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def extract_cells(raw_txt):\\n'\n",
      " '    \"Manually extract cells in potential broken json `raw_txt`\"\\n'\n",
      " \"    lines = raw_txt.split('\\\\n')\\n\"\n",
      " '    cells = []\\n'\n",
      " '    i = 0\\n'\n",
      " '    while not lines[i].startswith(\\' \"cells\"\\'): i+=1\\n'\n",
      " '    i += 1\\n'\n",
      " \"    start = '\\\\n'.join(lines[:i])\\n\"\n",
      " \"    while lines[i] != ' ],':\\n\"\n",
      " \"        while lines[i] != '  {': i+=1\\n\"\n",
      " '        j = i\\n'\n",
      " \"        while not lines[j].startswith('  }'): j+=1\\n\"\n",
      " \"        c = '\\\\n'.join(lines[i:j+1])\\n\"\n",
      " \"        if not c.endswith(','): c = c + ','\\n\"\n",
      " '        cells.append(c)\\n'\n",
      " '        i = j+1\\n'\n",
      " \"    end = '\\\\n'.join(lines[i:])\\n\"\n",
      " '    return start,cells,end')\n",
      "code_lines: ['def get_md_cell(txt):',\n",
      " '    \"A markdown cell with `txt`\"',\n",
      " \"    return '''  {\",\n",
      " '   \"cell_type\": \"markdown\",',\n",
      " '   \"metadata\": {},',\n",
      " '   \"source\": [',\n",
      " '    \"\\'\\'\\' + txt + \\'\\'\\'\"',\n",
      " '   ]',\n",
      " \"  },'''\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def get_md_cell(txt):\\n'\n",
      " '    \"A markdown cell with `txt`\"\\n'\n",
      " \"    return '''  {\\n\"\n",
      " '   \"cell_type\": \"markdown\",\\n'\n",
      " '   \"metadata\": {},\\n'\n",
      " '   \"source\": [\\n'\n",
      " '    \"\\'\\'\\' + txt + \\'\\'\\'\"\\n'\n",
      " '   ]\\n'\n",
      " \"  },'''\")\n",
      "code_lines: [\"conflicts = '<<<<<<< ======= >>>>>>>'.split()\"]\n",
      "code: \"\\n\\n# Cell\\nconflicts = '<<<<<<< ======= >>>>>>>'.split()\"\n",
      "code_lines: ['def _split_cell(cell, cf, names):',\n",
      " '    \"Split `cell` between `conflicts` given state in `cf`, save `names` of '\n",
      " 'branches if seen\"',\n",
      " '    res1,res2 = [],[]',\n",
      " \"    for line in cell.split('\\\\n'):\",\n",
      " '        if line.startswith(conflicts[cf]):',\n",
      " '            if names[cf//2] is None: names[cf//2] = line[8:]',\n",
      " '            cf = (cf+1)%3',\n",
      " '            continue',\n",
      " '        if cf<2:    res1.append(line)',\n",
      " '        if cf%2==0: res2.append(line)',\n",
      " \"    return '\\\\n'.join(res1),'\\\\n'.join(res2),cf,names\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _split_cell(cell, cf, names):\\n'\n",
      " '    \"Split `cell` between `conflicts` given state in `cf`, save `names` of '\n",
      " 'branches if seen\"\\n'\n",
      " '    res1,res2 = [],[]\\n'\n",
      " \"    for line in cell.split('\\\\n'):\\n\"\n",
      " '        if line.startswith(conflicts[cf]):\\n'\n",
      " '            if names[cf//2] is None: names[cf//2] = line[8:]\\n'\n",
      " '            cf = (cf+1)%3\\n'\n",
      " '            continue\\n'\n",
      " '        if cf<2:    res1.append(line)\\n'\n",
      " '        if cf%2==0: res2.append(line)\\n'\n",
      " \"    return '\\\\n'.join(res1),'\\\\n'.join(res2),cf,names\")\n",
      "code_lines: [\"_re_conflict = re.compile(r'^<<<<<<<', re.MULTILINE)\"]\n",
      "code: \"\\n\\n# Cell\\n_re_conflict = re.compile(r'^<<<<<<<', re.MULTILINE)\"\n",
      "code_lines: ['def same_inputs(t1, t2):',\n",
      " '    \"Test if the cells described in `t1` and `t2` have the same inputs\"',\n",
      " '    if len(t1)==0 or len(t2)==0: return False',\n",
      " '    try:',\n",
      " '        c1,c2 = json.loads(t1[:-1]),json.loads(t2[:-1])',\n",
      " \"        return c1['source']==c2['source']\",\n",
      " '    except Exception as e: return False']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def same_inputs(t1, t2):\\n'\n",
      " '    \"Test if the cells described in `t1` and `t2` have the same inputs\"\\n'\n",
      " '    if len(t1)==0 or len(t2)==0: return False\\n'\n",
      " '    try:\\n'\n",
      " '        c1,c2 = json.loads(t1[:-1]),json.loads(t2[:-1])\\n'\n",
      " \"        return c1['source']==c2['source']\\n\"\n",
      " '    except Exception as e: return False')\n",
      "code_lines: ['def analyze_cell(cell, cf, names, prev=None, added=False, fast=True, '\n",
      " 'trust_us=True):',\n",
      " '    \"Analyze and solve conflicts in `cell`\"',\n",
      " '    if cf==0 and _re_conflict.search(cell) is None: return '\n",
      " 'cell,cf,names,prev,added',\n",
      " '    old_cf = cf',\n",
      " '    v1,v2,cf,names = _split_cell(cell, cf, names)',\n",
      " '    if fast and same_inputs(v1,v2):',\n",
      " '        if old_cf==0 and cf==0: return (v2 if trust_us else '\n",
      " 'v1),cf,names,prev,added',\n",
      " '        v1,v2 = (v2,v2) if trust_us else (v1,v1)',\n",
      " '    res = []',\n",
      " '    if old_cf == 0:',\n",
      " '        added=True',\n",
      " \"        res.append(get_md_cell(f'`{conflicts[0]} {names[0]}`'))\",\n",
      " '    res.append(v1)',\n",
      " '    if cf ==0:',\n",
      " \"        res.append(get_md_cell(f'`{conflicts[1]}`'))\",\n",
      " '        if prev is not None: res += prev',\n",
      " '        res.append(v2)',\n",
      " \"        res.append(get_md_cell(f'`{conflicts[2]} {names[1]}`'))\",\n",
      " '        prev = None',\n",
      " '    else: prev = [v2] if prev is None else prev + [v2]',\n",
      " \"    return '\\\\n'.join([r for r in res if len(r) > 0]),cf,names,prev,added\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def analyze_cell(cell, cf, names, prev=None, added=False, fast=True, '\n",
      " 'trust_us=True):\\n'\n",
      " '    \"Analyze and solve conflicts in `cell`\"\\n'\n",
      " '    if cf==0 and _re_conflict.search(cell) is None: return '\n",
      " 'cell,cf,names,prev,added\\n'\n",
      " '    old_cf = cf\\n'\n",
      " '    v1,v2,cf,names = _split_cell(cell, cf, names)\\n'\n",
      " '    if fast and same_inputs(v1,v2):\\n'\n",
      " '        if old_cf==0 and cf==0: return (v2 if trust_us else '\n",
      " 'v1),cf,names,prev,added\\n'\n",
      " '        v1,v2 = (v2,v2) if trust_us else (v1,v1)\\n'\n",
      " '    res = []\\n'\n",
      " '    if old_cf == 0:\\n'\n",
      " '        added=True\\n'\n",
      " \"        res.append(get_md_cell(f'`{conflicts[0]} {names[0]}`'))\\n\"\n",
      " '    res.append(v1)\\n'\n",
      " '    if cf ==0:\\n'\n",
      " \"        res.append(get_md_cell(f'`{conflicts[1]}`'))\\n\"\n",
      " '        if prev is not None: res += prev\\n'\n",
      " '        res.append(v2)\\n'\n",
      " \"        res.append(get_md_cell(f'`{conflicts[2]} {names[1]}`'))\\n\"\n",
      " '        prev = None\\n'\n",
      " '    else: prev = [v2] if prev is None else prev + [v2]\\n'\n",
      " \"    return '\\\\n'.join([r for r in res if len(r) > 0]),cf,names,prev,added\")\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_fix_merge(fname:Param(\"A notebook filename to fix\", str),',\n",
      " '                    fast:Param(\"Fast fix: automatically fix the merge '\n",
      " 'conflicts in outputs or metadata\", bool)=True,',\n",
      " '                    trust_us:Param(\"Use local outputs/metadata when fast '\n",
      " 'merging\", bool)=True):',\n",
      " '    \"Fix merge conflicts in notebook `fname`\"',\n",
      " '    fname=Path(fname)',\n",
      " \"    shutil.copy(fname, fname.with_suffix('.ipynb.bak'))\",\n",
      " \"    with open(fname, 'r') as f: raw_text = f.read()\",\n",
      " '    start,cells,end = extract_cells(raw_text)',\n",
      " '    res = [start]',\n",
      " '    cf,names,prev,added = 0,[None,None],None,False',\n",
      " '    for cell in cells:',\n",
      " '        c,cf,names,prev,added = analyze_cell(cell, cf, names, prev, added, '\n",
      " 'fast=fast, trust_us=trust_us)',\n",
      " '        res.append(c)',\n",
      " \"    if res[-1].endswith(','): res[-1] = res[-1][:-1]\",\n",
      " \"    with open(f'{fname}', 'w') as f: f.write('\\\\n'.join([r for r in \"\n",
      " 'res+[end] if len(r) > 0]))',\n",
      " '    if fast and not added: print(\"Successfully merged conflicts!\")',\n",
      " '    else: print(\"One or more conflict remains in the notebook, please '\n",
      " 'inspect manually.\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_fix_merge(fname:Param(\"A notebook filename to fix\", str),\\n'\n",
      " '                    fast:Param(\"Fast fix: automatically fix the merge '\n",
      " 'conflicts in outputs or metadata\", bool)=True,\\n'\n",
      " '                    trust_us:Param(\"Use local outputs/metadata when fast '\n",
      " 'merging\", bool)=True):\\n'\n",
      " '    \"Fix merge conflicts in notebook `fname`\"\\n'\n",
      " '    fname=Path(fname)\\n'\n",
      " \"    shutil.copy(fname, fname.with_suffix('.ipynb.bak'))\\n\"\n",
      " \"    with open(fname, 'r') as f: raw_text = f.read()\\n\"\n",
      " '    start,cells,end = extract_cells(raw_text)\\n'\n",
      " '    res = [start]\\n'\n",
      " '    cf,names,prev,added = 0,[None,None],None,False\\n'\n",
      " '    for cell in cells:\\n'\n",
      " '        c,cf,names,prev,added = analyze_cell(cell, cf, names, prev, added, '\n",
      " 'fast=fast, trust_us=trust_us)\\n'\n",
      " '        res.append(c)\\n'\n",
      " \"    if res[-1].endswith(','): res[-1] = res[-1][:-1]\\n\"\n",
      " \"    with open(f'{fname}', 'w') as f: f.write('\\\\n'.join([r for r in \"\n",
      " 'res+[end] if len(r) > 0]))\\n'\n",
      " '    if fast and not added: print(\"Successfully merged conflicts!\")\\n'\n",
      " '    else: print(\"One or more conflict remains in the notebook, please '\n",
      " 'inspect manually.\")')\n",
      "Converted 05_merge.ipynb.\n",
      "code_lines: ['from .imports import *',\n",
      " 'from .export import *',\n",
      " 'from .sync import *',\n",
      " 'from .merge import *',\n",
      " 'from .export2html import *',\n",
      " 'from .clean import *',\n",
      " 'from .test import *',\n",
      " 'from fastcore.script import *',\n",
      " 'from ghapi.all import GhApi',\n",
      " 'from urllib.error import HTTPError',\n",
      " '']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'from .imports import *\\n'\n",
      " 'from .export import *\\n'\n",
      " 'from .sync import *\\n'\n",
      " 'from .merge import *\\n'\n",
      " 'from .export2html import *\\n'\n",
      " 'from .clean import *\\n'\n",
      " 'from .test import *\\n'\n",
      " 'from fastcore.script import *\\n'\n",
      " 'from ghapi.all import GhApi\\n'\n",
      " 'from urllib.error import HTTPError\\n')\n",
      "code_lines: ['def bump_version(version, part=2):',\n",
      " \"    version = version.split('.')\",\n",
      " '    version[part] = str(int(version[part]) + 1)',\n",
      " \"    for i in range(part+1, 3): version[i] = '0'\",\n",
      " \"    return '.'.join(version)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def bump_version(version, part=2):\\n'\n",
      " \"    version = version.split('.')\\n\"\n",
      " '    version[part] = str(int(version[part]) + 1)\\n'\n",
      " \"    for i in range(part+1, 3): version[i] = '0'\\n\"\n",
      " \"    return '.'.join(version)\")\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_bump_version(part:Param(\"Part of version to bump\", int)=2):',\n",
      " '    \"Increment version in `settings.py` by one\"',\n",
      " '    cfg = Config()',\n",
      " \"    print(f'Old version: {cfg.version}')\",\n",
      " \"    cfg.d['version'] = bump_version(Config().version, part)\",\n",
      " '    cfg.save()',\n",
      " '    update_version()',\n",
      " \"    print(f'New version: {cfg.version}')\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_bump_version(part:Param(\"Part of version to bump\", int)=2):\\n'\n",
      " '    \"Increment version in `settings.py` by one\"\\n'\n",
      " '    cfg = Config()\\n'\n",
      " \"    print(f'Old version: {cfg.version}')\\n\"\n",
      " \"    cfg.d['version'] = bump_version(Config().version, part)\\n\"\n",
      " '    cfg.save()\\n'\n",
      " '    update_version()\\n'\n",
      " \"    print(f'New version: {cfg.version}')\")\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_install_git_hooks():',\n",
      " '    \"Install git hooks to clean/trust notebooks automatically\"',\n",
      " '    try: path = Config().config_file.parent',\n",
      " '    except: path = Path.cwd()',\n",
      " \"    hook_path = path/'.git'/'hooks'\",\n",
      " \"    fn = hook_path/'post-merge'\",\n",
      " '    hook_path.mkdir(parents=True, exist_ok=True)',\n",
      " '    #Trust notebooks after merge',\n",
      " '    fn.write_text(\"#!/bin/bash\\\\necho \\'Trusting '\n",
      " 'notebooks\\'\\\\nnbdev_trust_nbs\")',\n",
      " '    os.chmod(fn, os.stat(fn).st_mode | stat.S_IEXEC)',\n",
      " '    #Clean notebooks on commit/diff',\n",
      " '    (path/\\'.gitconfig\\').write_text(\"\"\"# Generated by '\n",
      " 'nbdev_install_git_hooks',\n",
      " '#',\n",
      " '# If you need to disable this instrumentation do:',\n",
      " '#   git config --local --unset include.path',\n",
      " '#',\n",
      " '# To restore the filter',\n",
      " '#   git config --local include.path .gitconfig',\n",
      " '#',\n",
      " '# If you see notebooks not stripped, checked the filters are applied in '\n",
      " '.gitattributes',\n",
      " '#',\n",
      " '[filter \"clean-nbs\"]',\n",
      " '        clean = nbdev_clean_nbs --read_input_stream True',\n",
      " '        smudge = cat',\n",
      " '        required = true',\n",
      " '[diff \"ipynb\"]',\n",
      " '        textconv = nbdev_clean_nbs --disp True --fname',\n",
      " '\"\"\")',\n",
      " '    cmd = \"git config --local include.path ../.gitconfig\"',\n",
      " '    print(f\"Executing: {cmd}\")',\n",
      " '    run(cmd)',\n",
      " '    print(\"Success: hooks are installed and repo\\'s .gitconfig is now '\n",
      " 'trusted\")',\n",
      " '    try: nb_path = Config().path(\"nbs_path\")',\n",
      " '    except: nb_path = Path.cwd()',\n",
      " '    (nb_path/\\'.gitattributes\\').write_text(\"**/*.ipynb '\n",
      " 'filter=clean-nbs\\\\n**/*.ipynb diff=ipynb\\\\n\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_install_git_hooks():\\n'\n",
      " '    \"Install git hooks to clean/trust notebooks automatically\"\\n'\n",
      " '    try: path = Config().config_file.parent\\n'\n",
      " '    except: path = Path.cwd()\\n'\n",
      " \"    hook_path = path/'.git'/'hooks'\\n\"\n",
      " \"    fn = hook_path/'post-merge'\\n\"\n",
      " '    hook_path.mkdir(parents=True, exist_ok=True)\\n'\n",
      " '    #Trust notebooks after merge\\n'\n",
      " '    fn.write_text(\"#!/bin/bash\\\\necho \\'Trusting '\n",
      " 'notebooks\\'\\\\nnbdev_trust_nbs\")\\n'\n",
      " '    os.chmod(fn, os.stat(fn).st_mode | stat.S_IEXEC)\\n'\n",
      " '    #Clean notebooks on commit/diff\\n'\n",
      " '    (path/\\'.gitconfig\\').write_text(\"\"\"# Generated by '\n",
      " 'nbdev_install_git_hooks\\n'\n",
      " '#\\n'\n",
      " '# If you need to disable this instrumentation do:\\n'\n",
      " '#   git config --local --unset include.path\\n'\n",
      " '#\\n'\n",
      " '# To restore the filter\\n'\n",
      " '#   git config --local include.path .gitconfig\\n'\n",
      " '#\\n'\n",
      " '# If you see notebooks not stripped, checked the filters are applied in '\n",
      " '.gitattributes\\n'\n",
      " '#\\n'\n",
      " '[filter \"clean-nbs\"]\\n'\n",
      " '        clean = nbdev_clean_nbs --read_input_stream True\\n'\n",
      " '        smudge = cat\\n'\n",
      " '        required = true\\n'\n",
      " '[diff \"ipynb\"]\\n'\n",
      " '        textconv = nbdev_clean_nbs --disp True --fname\\n'\n",
      " '\"\"\")\\n'\n",
      " '    cmd = \"git config --local include.path ../.gitconfig\"\\n'\n",
      " '    print(f\"Executing: {cmd}\")\\n'\n",
      " '    run(cmd)\\n'\n",
      " '    print(\"Success: hooks are installed and repo\\'s .gitconfig is now '\n",
      " 'trusted\")\\n'\n",
      " '    try: nb_path = Config().path(\"nbs_path\")\\n'\n",
      " '    except: nb_path = Path.cwd()\\n'\n",
      " '    (nb_path/\\'.gitattributes\\').write_text(\"**/*.ipynb '\n",
      " 'filter=clean-nbs\\\\n**/*.ipynb diff=ipynb\\\\n\")')\n",
      "code_lines: ['_template_git_repo = \"https://github.com/fastai/nbdev_template.git\"']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '_template_git_repo = \"https://github.com/fastai/nbdev_template.git\"')\n",
      "code_lines: ['import tarfile']\n",
      "code: '\\n\\n# Cell\\nimport tarfile'\n",
      "code_lines: [\"def extract_tgz(url, dest='.'):\",\n",
      " \"    with urlopen(url) as u: tarfile.open(mode='r:gz', \"\n",
      " 'fileobj=u).extractall(dest)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " \"def extract_tgz(url, dest='.'):\\n\"\n",
      " \"    with urlopen(url) as u: tarfile.open(mode='r:gz', \"\n",
      " 'fileobj=u).extractall(dest)')\n",
      "code_lines: ['#hide',\n",
      " \"def _get_branch(owner, repo, default='main'):\",\n",
      " \"    api = GhApi(owner=owner, repo=repo, token=os.getenv('GITHUB_TOKEN'))\",\n",
      " '    try: return api.repos.get().default_branch',\n",
      " '    except HTTPError: ',\n",
      " '        msg= [f\"Could not access repo: {owner}/{repo} to find your default '\n",
      " 'branch - `{default} assumed.\\\\n\",',\n",
      " '              \"Edit `settings.ini` if this is incorrect.\\\\n\"',\n",
      " '              \"In the future, you can allow nbdev to see private repos by '\n",
      " 'setting the environment variable GITHUB_TOKEN as described here: '\n",
      " 'https://nbdev.fast.ai/cli.html#Using-nbdev_new-with-private-repos '\n",
      " '\\\\n\",         ]',\n",
      " \"        print(''.join(msg))\",\n",
      " '        return default']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '#hide\\n'\n",
      " \"def _get_branch(owner, repo, default='main'):\\n\"\n",
      " \"    api = GhApi(owner=owner, repo=repo, token=os.getenv('GITHUB_TOKEN'))\\n\"\n",
      " '    try: return api.repos.get().default_branch\\n'\n",
      " '    except HTTPError: \\n'\n",
      " '        msg= [f\"Could not access repo: {owner}/{repo} to find your default '\n",
      " 'branch - `{default} assumed.\\\\n\",\\n'\n",
      " '              \"Edit `settings.ini` if this is incorrect.\\\\n\"\\n'\n",
      " '              \"In the future, you can allow nbdev to see private repos by '\n",
      " 'setting the environment variable GITHUB_TOKEN as described here: '\n",
      " 'https://nbdev.fast.ai/cli.html#Using-nbdev_new-with-private-repos '\n",
      " '\\\\n\",         ]\\n'\n",
      " \"        print(''.join(msg))\\n\"\n",
      " '        return default')\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_new():',\n",
      " '    \"Create a new nbdev project from the current git repo\"',\n",
      " \"    url = run('git config --get remote.origin.url')\",\n",
      " \"    if not url: raise Exception('This does not appear to be a cloned git \"\n",
      " \"directory with a remote')\",\n",
      " \"    author = run('git config --get user.name').strip()\",\n",
      " \"    email = run('git config --get user.email').strip()\",\n",
      " \"    if not (author and email): raise Exception('User name and email not \"\n",
      " \"configured in git')\",\n",
      " '',\n",
      " '    # download and untar template, and optionally notebooks',\n",
      " '    tgnm = '\n",
      " \"urljson('https://api.github.com/repos/fastai/nbdev_template/releases/latest')['tag_name']\",\n",
      " '    FILES_URL = '\n",
      " 'f\"https://github.com/fastai/nbdev_template/archive/{tgnm}.tar.gz\"',\n",
      " '    extract_tgz(FILES_URL)',\n",
      " '    path = Path()',\n",
      " \"    nbexists = True if first(path.glob('*.ipynb')) else False\",\n",
      " \"    for o in (path/f'nbdev_template-{tgnm}').ls(): \",\n",
      " \"        if o.name == '00_core.ipynb':\",\n",
      " \"            if not nbexists: shutil.move(str(o), './')\",\n",
      " \"        elif not Path(f'./{o.name}').exists(): shutil.move(str(o), './') \",\n",
      " \"    shutil.rmtree(f'nbdev_template-{tgnm}')\",\n",
      " '',\n",
      " '    # auto-config settings.ini from git',\n",
      " \"    settings_path = Path('settings.ini')\",\n",
      " '    settings = settings_path.read_text()',\n",
      " '    owner,repo = repo_details(url)',\n",
      " '    branch = _get_branch(owner, repo)',\n",
      " '    settings = settings.format(lib_name=repo, user=owner, author=author, '\n",
      " 'author_email=email, branch=branch)',\n",
      " '    settings_path.write_text(settings)    ',\n",
      " '    nbdev_install_git_hooks()']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_new():\\n'\n",
      " '    \"Create a new nbdev project from the current git repo\"\\n'\n",
      " \"    url = run('git config --get remote.origin.url')\\n\"\n",
      " \"    if not url: raise Exception('This does not appear to be a cloned git \"\n",
      " \"directory with a remote')\\n\"\n",
      " \"    author = run('git config --get user.name').strip()\\n\"\n",
      " \"    email = run('git config --get user.email').strip()\\n\"\n",
      " \"    if not (author and email): raise Exception('User name and email not \"\n",
      " \"configured in git')\\n\"\n",
      " '\\n'\n",
      " '    # download and untar template, and optionally notebooks\\n'\n",
      " '    tgnm = '\n",
      " \"urljson('https://api.github.com/repos/fastai/nbdev_template/releases/latest')['tag_name']\\n\"\n",
      " '    FILES_URL = '\n",
      " 'f\"https://github.com/fastai/nbdev_template/archive/{tgnm}.tar.gz\"\\n'\n",
      " '    extract_tgz(FILES_URL)\\n'\n",
      " '    path = Path()\\n'\n",
      " \"    nbexists = True if first(path.glob('*.ipynb')) else False\\n\"\n",
      " \"    for o in (path/f'nbdev_template-{tgnm}').ls(): \\n\"\n",
      " \"        if o.name == '00_core.ipynb':\\n\"\n",
      " \"            if not nbexists: shutil.move(str(o), './')\\n\"\n",
      " \"        elif not Path(f'./{o.name}').exists(): shutil.move(str(o), './') \\n\"\n",
      " \"    shutil.rmtree(f'nbdev_template-{tgnm}')\\n\"\n",
      " '\\n'\n",
      " '    # auto-config settings.ini from git\\n'\n",
      " \"    settings_path = Path('settings.ini')\\n\"\n",
      " '    settings = settings_path.read_text()\\n'\n",
      " '    owner,repo = repo_details(url)\\n'\n",
      " '    branch = _get_branch(owner, repo)\\n'\n",
      " '    settings = settings.format(lib_name=repo, user=owner, author=author, '\n",
      " 'author_email=email, branch=branch)\\n'\n",
      " '    settings_path.write_text(settings)    \\n'\n",
      " '    nbdev_install_git_hooks()')\n",
      "Converted 06_cli.ipynb.\n",
      "code_lines: ['import io,sys,json,glob,re',\n",
      " 'from fastcore.script import call_parse,Param',\n",
      " 'from fastcore.utils import ifnone',\n",
      " 'from .imports import Config',\n",
      " 'from .export import nbglob',\n",
      " 'from pathlib import Path']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'import io,sys,json,glob,re\\n'\n",
      " 'from fastcore.script import call_parse,Param\\n'\n",
      " 'from fastcore.utils import ifnone\\n'\n",
      " 'from .imports import Config\\n'\n",
      " 'from .export import nbglob\\n'\n",
      " 'from pathlib import Path')\n",
      "code_lines: ['def rm_execution_count(o):',\n",
      " '    \"Remove execution count in `o`\"',\n",
      " \"    if 'execution_count' in o: o['execution_count'] = None\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def rm_execution_count(o):\\n'\n",
      " '    \"Remove execution count in `o`\"\\n'\n",
      " \"    if 'execution_count' in o: o['execution_count'] = None\")\n",
      "code_lines: ['colab_json = \"application/vnd.google.colaboratory.intrinsic+json\"',\n",
      " 'def clean_output_data_vnd(o):',\n",
      " '    \"Remove `application/vnd.google.colaboratory.intrinsic+json` in data '\n",
      " 'entries\"',\n",
      " \"    if 'data' in o:\",\n",
      " \"        data = o['data']\",\n",
      " '        if colab_json in data:',\n",
      " '            new_data = {k:v for k,v in data.items() if k != colab_json}',\n",
      " \"            o['data'] = new_data\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'colab_json = \"application/vnd.google.colaboratory.intrinsic+json\"\\n'\n",
      " 'def clean_output_data_vnd(o):\\n'\n",
      " '    \"Remove `application/vnd.google.colaboratory.intrinsic+json` in data '\n",
      " 'entries\"\\n'\n",
      " \"    if 'data' in o:\\n\"\n",
      " \"        data = o['data']\\n\"\n",
      " '        if colab_json in data:\\n'\n",
      " '            new_data = {k:v for k,v in data.items() if k != colab_json}\\n'\n",
      " \"            o['data'] = new_data\")\n",
      "code_lines: ['def clean_cell_output(cell):',\n",
      " '    \"Remove execution count in `cell`\"',\n",
      " \"    if 'outputs' in cell:\",\n",
      " \"        for o in cell['outputs']:\",\n",
      " '            rm_execution_count(o)',\n",
      " '            clean_output_data_vnd(o)',\n",
      " \"            o.get('metadata', o).pop('tags', None)\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def clean_cell_output(cell):\\n'\n",
      " '    \"Remove execution count in `cell`\"\\n'\n",
      " \"    if 'outputs' in cell:\\n\"\n",
      " \"        for o in cell['outputs']:\\n\"\n",
      " '            rm_execution_count(o)\\n'\n",
      " '            clean_output_data_vnd(o)\\n'\n",
      " \"            o.get('metadata', o).pop('tags', None)\")\n",
      "code_lines: ['cell_metadata_keep = [\"hide_input\"]',\n",
      " 'nb_metadata_keep   = [\"kernelspec\", \"jekyll\", \"jupytext\", \"doc\"]']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'cell_metadata_keep = [\"hide_input\"]\\n'\n",
      " 'nb_metadata_keep   = [\"kernelspec\", \"jekyll\", \"jupytext\", \"doc\"]')\n",
      "code_lines: ['def clean_cell(cell, clear_all=False):',\n",
      " '    \"Clean `cell` by removing superfluous metadata or everything except the '\n",
      " 'input if `clear_all`\"',\n",
      " '    rm_execution_count(cell)',\n",
      " \"    if 'outputs' in cell:\",\n",
      " \"        if clear_all: cell['outputs'] = []\",\n",
      " '        else:         clean_cell_output(cell)',\n",
      " \"    if cell['source'] == ['']: cell['source'] = []\",\n",
      " \"    cell['metadata'] = {} if clear_all else {k:v for k,v in \"\n",
      " \"cell['metadata'].items() if k in cell_metadata_keep}\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def clean_cell(cell, clear_all=False):\\n'\n",
      " '    \"Clean `cell` by removing superfluous metadata or everything except the '\n",
      " 'input if `clear_all`\"\\n'\n",
      " '    rm_execution_count(cell)\\n'\n",
      " \"    if 'outputs' in cell:\\n\"\n",
      " \"        if clear_all: cell['outputs'] = []\\n\"\n",
      " '        else:         clean_cell_output(cell)\\n'\n",
      " \"    if cell['source'] == ['']: cell['source'] = []\\n\"\n",
      " \"    cell['metadata'] = {} if clear_all else {k:v for k,v in \"\n",
      " \"cell['metadata'].items() if k in cell_metadata_keep}\")\n",
      "code_lines: ['def clean_nb(nb, clear_all=False):',\n",
      " '    \"Clean `nb` from superfluous metadata, passing `clear_all` to '\n",
      " '`clean_cell`\"',\n",
      " \"    for c in nb['cells']: clean_cell(c, clear_all=clear_all)\",\n",
      " \"    nb['metadata'] = {k:v for k,v in nb['metadata'].items() if k in \"\n",
      " 'nb_metadata_keep }']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def clean_nb(nb, clear_all=False):\\n'\n",
      " '    \"Clean `nb` from superfluous metadata, passing `clear_all` to '\n",
      " '`clean_cell`\"\\n'\n",
      " \"    for c in nb['cells']: clean_cell(c, clear_all=clear_all)\\n\"\n",
      " \"    nb['metadata'] = {k:v for k,v in nb['metadata'].items() if k in \"\n",
      " 'nb_metadata_keep }')\n",
      "code_lines: ['def _print_output(nb):',\n",
      " '    \"Print `nb` in stdout for git things\"',\n",
      " \"    _output_stream = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\",\n",
      " '    x = json.dumps(nb, sort_keys=True, indent=1, ensure_ascii=False)',\n",
      " '    _output_stream.write(x)',\n",
      " '    _output_stream.write(\"\\\\n\")',\n",
      " '    _output_stream.flush()']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def _print_output(nb):\\n'\n",
      " '    \"Print `nb` in stdout for git things\"\\n'\n",
      " \"    _output_stream = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\\n\"\n",
      " '    x = json.dumps(nb, sort_keys=True, indent=1, ensure_ascii=False)\\n'\n",
      " '    _output_stream.write(x)\\n'\n",
      " '    _output_stream.write(\"\\\\n\")\\n'\n",
      " '    _output_stream.flush()')\n",
      "code_lines: ['@call_parse',\n",
      " 'def nbdev_clean_nbs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,',\n",
      " '                    clear_all:Param(\"Clean all metadata and outputs\", '\n",
      " 'bool)=False,',\n",
      " '                    disp:Param(\"Print the cleaned outputs\", bool)=False,',\n",
      " '                    read_input_stream:Param(\"Read input stram and not nb '\n",
      " 'folder\")=False):',\n",
      " '    \"Clean all notebooks in `fname` to avoid merge conflicts\"',\n",
      " '    #Git hooks will pass the notebooks in the stdin',\n",
      " '    if read_input_stream and sys.stdin:',\n",
      " \"        input_stream = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')\",\n",
      " '        nb = json.load(input_stream)',\n",
      " '        clean_nb(nb, clear_all=clear_all)',\n",
      " '        _print_output(nb)',\n",
      " '        return',\n",
      " '    path = None',\n",
      " '    if fname is None:',\n",
      " '        try: path = Config().path(\"nbs_path\")',\n",
      " '        except Exception as e: path = Path.cwd()',\n",
      " '    ',\n",
      " '    files = nbglob(fname=ifnone(fname,path))',\n",
      " '    for f in files:',\n",
      " \"        if not str(f).endswith('.ipynb'): continue\",\n",
      " \"        nb = json.loads(open(f, 'r', encoding='utf-8').read())\",\n",
      " '        clean_nb(nb, clear_all=clear_all)',\n",
      " '        if disp: _print_output(nb)',\n",
      " '        else:',\n",
      " '            x = json.dumps(nb, sort_keys=True, indent=1, ensure_ascii=False)',\n",
      " \"            with io.open(f, 'w', encoding='utf-8') as f:\",\n",
      " '                f.write(x)',\n",
      " '                f.write(\"\\\\n\")']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " '@call_parse\\n'\n",
      " 'def nbdev_clean_nbs(fname:Param(\"A notebook name or glob to convert\", '\n",
      " 'str)=None,\\n'\n",
      " '                    clear_all:Param(\"Clean all metadata and outputs\", '\n",
      " 'bool)=False,\\n'\n",
      " '                    disp:Param(\"Print the cleaned outputs\", bool)=False,\\n'\n",
      " '                    read_input_stream:Param(\"Read input stram and not nb '\n",
      " 'folder\")=False):\\n'\n",
      " '    \"Clean all notebooks in `fname` to avoid merge conflicts\"\\n'\n",
      " '    #Git hooks will pass the notebooks in the stdin\\n'\n",
      " '    if read_input_stream and sys.stdin:\\n'\n",
      " \"        input_stream = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')\\n\"\n",
      " '        nb = json.load(input_stream)\\n'\n",
      " '        clean_nb(nb, clear_all=clear_all)\\n'\n",
      " '        _print_output(nb)\\n'\n",
      " '        return\\n'\n",
      " '    path = None\\n'\n",
      " '    if fname is None:\\n'\n",
      " '        try: path = Config().path(\"nbs_path\")\\n'\n",
      " '        except Exception as e: path = Path.cwd()\\n'\n",
      " '    \\n'\n",
      " '    files = nbglob(fname=ifnone(fname,path))\\n'\n",
      " '    for f in files:\\n'\n",
      " \"        if not str(f).endswith('.ipynb'): continue\\n\"\n",
      " \"        nb = json.loads(open(f, 'r', encoding='utf-8').read())\\n\"\n",
      " '        clean_nb(nb, clear_all=clear_all)\\n'\n",
      " '        if disp: _print_output(nb)\\n'\n",
      " '        else:\\n'\n",
      " '            x = json.dumps(nb, sort_keys=True, indent=1, '\n",
      " 'ensure_ascii=False)\\n'\n",
      " \"            with io.open(f, 'w', encoding='utf-8') as f:\\n\"\n",
      " '                f.write(x)\\n'\n",
      " '                f.write(\"\\\\n\")')\n",
      "Converted 07_clean.ipynb.\n",
      "Converted 99_search.ipynb.\n",
      "Converted example.ipynb.\n",
      "Converted index.ipynb.\n",
      "code_lines: ['class S1():', '    def __init__(self, *args, **kwargs):', '        pass']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'class S1():\\n'\n",
      " '    def __init__(self, *args, **kwargs):\\n'\n",
      " '        pass')\n",
      "code_lines: ['class S2():', '    def __init__(self, *args, **kwargs):', '        pass']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'class S2():\\n'\n",
      " '    def __init__(self, *args, **kwargs):\\n'\n",
      " '        pass')\n",
      "code_lines: ['class S3():', '    def __init__(self, *args, **kwargs):', '        pass']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Internal Cell\\n'\n",
      " 'class S3():\\n'\n",
      " '    def __init__(self, *args, **kwargs):\\n'\n",
      " '        pass')\n",
      "Converted nbdev_comments.ipynb.\n",
      "code_lines: ['def say_hello(to):',\n",
      " '    \"Say hello to somebody\"',\n",
      " \"    return f'Hello {to}!'\"]\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'def say_hello(to):\\n'\n",
      " '    \"Say hello to somebody\"\\n'\n",
      " \"    return f'Hello {to}!'\")\n",
      "code_lines: ['class HelloSayer:',\n",
      " '    \"Say hello to `to` using `say_hello`\"',\n",
      " '    def __init__(self, to): self.to = to',\n",
      " '',\n",
      " '    def say(self):',\n",
      " '        \"Do the saying\"',\n",
      " '        return say_hello(self.to)']\n",
      "code: ('\\n'\n",
      " '\\n'\n",
      " '# Cell\\n'\n",
      " 'class HelloSayer:\\n'\n",
      " '    \"Say hello to `to` using `say_hello`\"\\n'\n",
      " '    def __init__(self, to): self.to = to\\n'\n",
      " '\\n'\n",
      " '    def say(self):\\n'\n",
      " '        \"Do the saying\"\\n'\n",
      " '        return say_hello(self.to)')\n",
      "Converted tutorial.ipynb.\n",
      "Converted tutorial_colab.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# #hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
